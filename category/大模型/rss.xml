<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>意大利炮打友军 • Posts by &#34;大模型&#34; category</title>
        <link>http://example.com</link>
        <description></description>
        <language>zh-CN</language>
        <pubDate>Sat, 30 Mar 2024 20:54:57 +0800</pubDate>
        <lastBuildDate>Sat, 30 Mar 2024 20:54:57 +0800</lastBuildDate>
        <category>随笔</category>
        <category>技术</category>
        <category>大模型训练</category>
        <category>课题组</category>
        <category>笔记</category>
        <category>博客</category>
        <category>markdown</category>
        <category>Linux</category>
        <category>月历</category>
        <category>写作</category>
        <category>科幻</category>
        <category>世界观</category>
        <category>python</category>
        <category>WSL</category>
        <category>编译</category>
        <category>通信</category>
        <category>操作系统</category>
        <category>电赛</category>
        <category>周报</category>
        <category>神经网络</category>
        <category>pytorch</category>
        <category>记录</category>
        <item>
            <guid isPermalink="true">http://example.com/2024/03/30/DeepSpeed%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%EF%BC%9Aelasticity/</guid>
            <title>DeepSpeed代码阅读笔记之：elasticity</title>
            <link>http://example.com/2024/03/30/DeepSpeed%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%EF%BC%9Aelasticity/</link>
            <category>技术</category>
            <category>大模型训练</category>
            <category>课题组</category>
            <category>笔记</category>
            <pubDate>Sat, 30 Mar 2024 20:54:57 +0800</pubDate>
            <description><![CDATA[ &lt;p&gt;本笔记是DeepSpeed代码阅读的第一篇笔记，本周的主要任务是阅读DeepSpeed python代码中的&lt;/p&gt;
&lt;h2 id=&#34;DeepSpeed-部署&#34;&gt;&lt;a href=&#34;#DeepSpeed-部署&#34; class=&#34;headerlink&#34; title=&#34;DeepSpeed 部署&#34;&gt;&lt;/a&gt;DeepSpeed 部署&lt;/h2&gt;&lt;p&gt;DeepSpeed 部署的过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;安装cuda与pytorch&lt;/li&gt;
&lt;li&gt;按照requirements文件夹安装依赖：&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&#34;highlight bash&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;div class=&#34;code-wrapper&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;code class=&#34;hljs bash&#34;&gt;pip install -r requirements/requirements-dev.txt &lt;br&gt;pip install -r requirements/requirements.txt&lt;br&gt;pip install -r requirements/requirements-sparse_attn.txt &lt;br&gt;pip install mpi4py&lt;br&gt;pip install --ignore-installed PyYAML&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;注意：attn文件里的triton 可能没有1.0版本&lt;/strong&gt;&lt;br&gt;&lt;strong&gt;mpi4py可能需要通过conda安装&lt;/strong&gt;&lt;br&gt;3. 安装DeepSpeed:运行install.sh&lt;br&gt;&lt;strong&gt;注意：deepspeed需要全目录有rw权限&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;至此，安装已完成，可以使用DeepSpeedExample目录下的例程来测试。&lt;/p&gt;
&lt;h2 id=&#34;elasticity目录代码&#34;&gt;&lt;a href=&#34;#elasticity目录代码&#34; class=&#34;headerlink&#34; title=&#34;elasticity目录代码&#34;&gt;&lt;/a&gt;elasticity目录代码&lt;/h2&gt;&lt;p&gt;init中说明了本目录下有如下几个文件：&lt;/p&gt;
&lt;figure class=&#34;highlight ada&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&#34;line&#34;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;code class=&#34;hljs ada&#34;&gt;&lt;span class=&#34;hljs-comment&#34;&gt;--elasticity&lt;/span&gt;&lt;br&gt;    |&lt;span class=&#34;hljs-comment&#34;&gt;-- __init__.py&lt;/span&gt;&lt;br&gt;    |&lt;span class=&#34;hljs-comment&#34;&gt;-- elasticity.py&lt;/span&gt;&lt;br&gt;    |&lt;span class=&#34;hljs-comment&#34;&gt;-- utils.py&lt;/span&gt;&lt;br&gt;    |&lt;span class=&#34;hljs-comment&#34;&gt;-- contants.py&lt;/span&gt;&lt;br&gt;    |&lt;span class=&#34;hljs-comment&#34;&gt;-- elastic_agent.py&lt;/span&gt;&lt;br&gt;    |&lt;span class=&#34;hljs-comment&#34;&gt;-- config.py&lt;/span&gt;&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h2 id=&#34;init-py&#34;&gt;&lt;a href=&#34;#init-py&#34; class=&#34;headerlink&#34; title=&#34;_init_.py&#34;&gt;&lt;/a&gt;_&lt;em&gt;init_&lt;/em&gt;.py&lt;/h2&gt;&lt;p&gt;这个代码主要是把目录下的文件中包含外部接口的文件进行引用，需要判断pytorch版本是否大于1.11，只有高于此版本才能使用DSElasticAgent类&lt;/p&gt;
&lt;h2 id=&#34;elasticity&#34;&gt;&lt;a href=&#34;#elasticity&#34; class=&#34;headerlink&#34; title=&#34;elasticity&#34;&gt;&lt;/a&gt;elasticity&lt;/h2&gt;&lt;p&gt;elasticity.py中给出了几个接口函数用来供外部调用&lt;/p&gt;
&lt;h3 id=&#34;compute-elastic-config&#34;&gt;&lt;a href=&#34;#compute-elastic-config&#34; class=&#34;headerlink&#34; title=&#34;compute_elastic_config&#34;&gt;&lt;/a&gt;compute_elastic_config&lt;/h3&gt;&lt;p&gt;调用弹性计算的核心代码，在DeepSpeedConfig类中会检查config是否有配置弹性计算，如果有会调用这个函数最终得到总batch——size和根据当前可用GPU数量得到的micro_batch(用于数据并行)（可选）&lt;/p&gt;
&lt;p&gt;elasticity 0.1版本和0.2版本分别调用不同的函数来得到final_batch_size。&lt;/p&gt;
&lt;p&gt;最后，通过检查micro_batch_size能否在数据并行中和batch_size 匹配(batch_size分在每个GPU上的大小能为micro_batch_size整倍)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;感觉这部分代码的去耦合做的很不好&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;elasticity-enabled&#34;&gt;&lt;a href=&#34;#elasticity-enabled&#34; class=&#34;headerlink&#34; title=&#34;elasticity_enabled&#34;&gt;&lt;/a&gt;elasticity_enabled&lt;/h3&gt;&lt;p&gt;检查ds_config的ELSASTICITY是否启用&lt;/p&gt;
&lt;h3 id=&#34;ensure-immutable-elastic-config&#34;&gt;&lt;a href=&#34;#ensure-immutable-elastic-config&#34; class=&#34;headerlink&#34; title=&#34;ensure_immutable_elastic_config&#34;&gt;&lt;/a&gt;ensure_immutable_elastic_config&lt;/h3&gt;&lt;p&gt;确保在资源管理器启用的情况下，根据环境变量中给Deepspeed的弹性配置和deepspeed自身的配置来检查是否匹配。&lt;/p&gt;
&lt;p&gt;除此之外，elasticity中内部还有关于micro_batch_size和total_batch_size计算实现的代码&lt;/p&gt;
&lt;h3 id=&#34;get-compatible-gpus-v01&#34;&gt;&lt;a href=&#34;#get-compatible-gpus-v01&#34; class=&#34;headerlink&#34; title=&#34;_get_compatible_gpus_v01&#34;&gt;&lt;/a&gt;_get_compatible_gpus_v01&lt;/h3&gt;&lt;p&gt;这个函数主要是得到batch_size和可用gpu数量。首先按照指定的micro_batches得到候选的batch_size。这个过程是给定的mrbs来找出最大合适的batch_size，存储在列表里。&lt;br&gt;在此之后，通过batch_sized候选列表中，按照偏好（大or小batch）得到最好的合适的（满足GPU数量和偏好）的batch_size。&lt;/p&gt;
&lt;figure class=&#34;highlight stata&#34;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&#34;gutter&#34;&gt;&lt;pre&gt;&lt;span class=&#34;line&#34;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&#34;code&#34;&gt;&lt;pre&gt;&lt;code class=&#34;hljs stata&#34;&gt;注意：这里满足GPU数量是指mrbs可以被&lt;span class=&#34;hljs-keyword&#34;&gt;bs&lt;/span&gt;整除，同时在给定最大or最小GPU数量中。&lt;br&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;h3 id=&#34;get-compatible-gpus-v02&#34;&gt;&lt;a href=&#34;#get-compatible-gpus-v02&#34; class=&#34;headerlink&#34; title=&#34;_get_compatible_gpus_v02&#34;&gt;&lt;/a&gt;_get_compatible_gpus_v02&lt;/h3&gt;&lt;p&gt;在v01函数的基础上，这个函数根据bs的大小和GPU，根据节点的GPU数量来调整mrbs数量。以及根据数据并行dpsz来得到bs&amp;#x3D;bs*dpsz。&lt;/p&gt;
&lt;h2 id=&#34;utils&#34;&gt;&lt;a href=&#34;#utils&#34; class=&#34;headerlink&#34; title=&#34;utils&#34;&gt;&lt;/a&gt;utils&lt;/h2&gt;&lt;p&gt;仅负责检查torch版本是否匹配&lt;/p&gt;
&lt;h2 id=&#34;constant&#34;&gt;&lt;a href=&#34;#constant&#34; class=&#34;headerlink&#34; title=&#34;constant&#34;&gt;&lt;/a&gt;constant&lt;/h2&gt;&lt;p&gt;存储了必需的常数，类似ENABLE，DS最低版本，环境变量名。默认bs等。&lt;/p&gt;
&lt;h2 id=&#34;elastic-agent&#34;&gt;&lt;a href=&#34;#elastic-agent&#34; class=&#34;headerlink&#34; title=&#34;elastic_agent&#34;&gt;&lt;/a&gt;elastic_agent&lt;/h2&gt;&lt;p&gt;实现了pytorch LocalElasticAgent的子类。&lt;/p&gt;
&lt;h3 id=&#34;set-master-addr-port&#34;&gt;&lt;a href=&#34;#set-master-addr-port&#34; class=&#34;headerlink&#34; title=&#34;_set_master_addr_port&#34;&gt;&lt;/a&gt;_set_master_addr_port&lt;/h3&gt;&lt;p&gt;这个方法检查主节点的地址（端口），如果没有会自动生成&lt;/p&gt;
&lt;h3 id=&#34;start-workers&#34;&gt;&lt;a href=&#34;#start-workers&#34; class=&#34;headerlink&#34; title=&#34;_start_workers&#34;&gt;&lt;/a&gt;_start_workers&lt;/h3&gt;&lt;p&gt;这个方法使用torch distributed的WorkerGroup类作为参数，给每个worker设定必要的环境变量后，给关于本地worker数量的环境变量进行更新。同时指定必要的参数后，启动workers的进程。&lt;/p&gt;
&lt;h3 id=&#34;invoke-run&#34;&gt;&lt;a href=&#34;#invoke-run&#34; class=&#34;headerlink&#34; title=&#34;_invoke_run&#34;&gt;&lt;/a&gt;_invoke_run&lt;/h3&gt;&lt;p&gt;这个方法在worker启动后，每隔一段时间监控当前workerGroup的状态。&lt;br&gt;可能会遇到节点工作失败的状况，则会选择进行重启worker或者在全部失效时进行报错推出&lt;br&gt;在遇到节点加入或退出时，会进行记录并重启workers。&lt;/p&gt;
&lt;h2 id=&#34;config-py&#34;&gt;&lt;a href=&#34;#config-py&#34; class=&#34;headerlink&#34; title=&#34;config.py&#34;&gt;&lt;/a&gt;config.py&lt;/h2&gt;&lt;p&gt;这个文件主要定义了和elasticity相关的错误抛出，以及对config从ds_config到elasticity_config参数的变换和类型检测。&lt;/p&gt;
&lt;h2 id=&#34;问题&#34;&gt;&lt;a href=&#34;#问题&#34; class=&#34;headerlink&#34; title=&#34;问题&#34;&gt;&lt;/a&gt;问题&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;为什么在elasticity文件中有预定义的HCN_LIST&lt;/li&gt;
&lt;li&gt;DS相比pytorch的Elasticity多了什么功能？&lt;/li&gt;
&lt;/ol&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">http://example.com/2024/03/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B02/</guid>
            <title>大模型通信笔记2</title>
            <link>http://example.com/2024/03/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B02/</link>
            <category>技术</category>
            <category>大模型训练</category>
            <category>博客</category>
            <category>通信</category>
            <pubDate>Tue, 26 Mar 2024 19:54:58 +0800</pubDate>
            <description><![CDATA[ &lt;h2 id=&#34;数据并行&#34;&gt;&lt;a href=&#34;#数据并行&#34; class=&#34;headerlink&#34; title=&#34;数据并行&#34;&gt;&lt;/a&gt;数据并行&lt;/h2&gt;&lt;p&gt;传统的数据并行是让每个GPU分别进行FWD和BWD，然后把梯度进行聚合操作，然后再下发给每个GPU，称为All Reduce。&lt;/p&gt;
&lt;h3 id=&#34;缺点&#34;&gt;&lt;a href=&#34;#缺点&#34; class=&#34;headerlink&#34; title=&#34;缺点&#34;&gt;&lt;/a&gt;缺点&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;存储开销大。每块GPU上都存了一份完整的模型，造成冗余&lt;/li&gt;
&lt;li&gt;通讯开销大。Server需要和每一个Worker进行梯度传输。当Server和Worker不在一台机器上时，Server的带宽将会成为整个系统的计算效率瓶颈。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;异步梯度更新&#34;&gt;&lt;a href=&#34;#异步梯度更新&#34; class=&#34;headerlink&#34; title=&#34;异步梯度更新&#34;&gt;&lt;/a&gt;异步梯度更新&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;Worker不等待梯度更新，用旧的参数进行下一轮训练，可能会延迟一步更新梯度，整体收敛速度变慢，但是提升通讯计算比。&lt;/li&gt;
&lt;li&gt;延迟步数会指定&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;分布式数据并行&#34;&gt;&lt;a href=&#34;#分布式数据并行&#34; class=&#34;headerlink&#34; title=&#34;分布式数据并行&#34;&gt;&lt;/a&gt;分布式数据并行&lt;/h3&gt;&lt;p&gt;核心目标是降低通信压力，因此要将Server的通信压力转到Worker上，最简单的就是Ring-AllReduce。&lt;/p&gt;
&lt;h4 id=&#34;Ring-Allreduce&#34;&gt;&lt;a href=&#34;#Ring-Allreduce&#34; class=&#34;headerlink&#34; title=&#34;Ring Allreduce&#34;&gt;&lt;/a&gt;Ring Allreduce&lt;/h4&gt;&lt;p&gt;核心思路是实现Reduce Scatter和All-Gather。GPU每次之和前后两个GPU通信，1卡给2卡发a号数据，2给3发b号，以此类推。三次更新后每张卡都有1个号的完整的数据。&lt;/p&gt;
&lt;p&gt;之后在进行All-Gather，依旧环形通信，把每个部分全聚合的都发给下一个，然后依此类推，3轮通信就可以覆盖所有。&lt;/p&gt;
&lt;h2 id=&#34;显存开销&#34;&gt;&lt;a href=&#34;#显存开销&#34; class=&#34;headerlink&#34; title=&#34;显存开销&#34;&gt;&lt;/a&gt;显存开销&lt;/h2&gt;&lt;p&gt;数据并行中，每个卡都存储了所有参数，怎么办？&lt;/p&gt;
&lt;p&gt;在实际存储中，分为两部分存储：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;模型状态：包括参数，优化器，梯度等&lt;/li&gt;
&lt;li&gt;驻留数据：包括activation，碎片内存和缓冲区等。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;优化措施&#34;&gt;&lt;a href=&#34;#优化措施&#34; class=&#34;headerlink&#34; title=&#34;优化措施&#34;&gt;&lt;/a&gt;优化措施&lt;/h2&gt;&lt;h3 id=&#34;混合精度训练&#34;&gt;&lt;a href=&#34;#混合精度训练&#34; class=&#34;headerlink&#34; title=&#34;混合精度训练&#34;&gt;&lt;/a&gt;混合精度训练&lt;/h3&gt;&lt;p&gt;对于参数，activation，梯度，都使用fp16，对于参数（多存一份）和优化器使用fp32。&lt;br&gt;模型必存数据为$K\phi$,那么最终总存储数据为$K\phi + 4\phi$&lt;br&gt;实际上，activation大小和batch有关，而且是可以抛弃的。&lt;/p&gt;
&lt;h3 id=&#34;ZeRO-DP&#34;&gt;&lt;a href=&#34;#ZeRO-DP&#34; class=&#34;headerlink&#34; title=&#34;ZeRO-DP&#34;&gt;&lt;/a&gt;ZeRO-DP&lt;/h3&gt;&lt;h4 id=&#34;第一步：优化器分割&#34;&gt;&lt;a href=&#34;#第一步：优化器分割&#34; class=&#34;headerlink&#34; title=&#34;第一步：优化器分割&#34;&gt;&lt;/a&gt;第一步：优化器分割&lt;/h4&gt;&lt;p&gt;每张卡只存储一部分优化器参数，在数据并行中，先通过AllReduce得到完整梯度，每个卡都更新自己的一部分梯度和参数，然后再AllGather。产生单卡通讯量$\phi$。&lt;/p&gt;
&lt;h4 id=&#34;第二步：梯度分割&#34;&gt;&lt;a href=&#34;#第二步：梯度分割&#34; class=&#34;headerlink&#34; title=&#34;第二步：梯度分割&#34;&gt;&lt;/a&gt;第二步：梯度分割&lt;/h4&gt;&lt;p&gt;经过FWD和BWD后，对梯度进行Reduce-Scatter，保证每张卡都有自己一份聚合梯度，用分割的优化器和梯度进行更新相应的W，然后再AllGather参数进行更新&lt;/p&gt;
&lt;h4 id=&#34;第三步：参数分割&#34;&gt;&lt;a href=&#34;#第三步：参数分割&#34; class=&#34;headerlink&#34; title=&#34;第三步：参数分割&#34;&gt;&lt;/a&gt;第三步：参数分割&lt;/h4&gt;&lt;p&gt;FWD时，先All Gather一次参数，用完即弃。&lt;br&gt;BWD时，再All Gather一次参数，用完即弃&lt;br&gt;用自己的梯度进行一次All Gather得到完整梯度&lt;br&gt;更新参数，无需通信。&lt;/p&gt;
&lt;h3 id=&#34;ZeRO-R&#34;&gt;&lt;a href=&#34;#ZeRO-R&#34; class=&#34;headerlink&#34; title=&#34;ZeRO-R&#34;&gt;&lt;/a&gt;ZeRO-R&lt;/h3&gt;&lt;p&gt;通过对驻留数据进行优化来实现显存使用减少和通信负载降低。&lt;/p&gt;
&lt;h4 id=&#34;activation&#34;&gt;&lt;a href=&#34;#activation&#34; class=&#34;headerlink&#34; title=&#34;activation&#34;&gt;&lt;/a&gt;activation&lt;/h4&gt;&lt;p&gt;每块GPU上只维护部分的activation，需要时再聚合。或者重新计算。&lt;/p&gt;
&lt;h4 id=&#34;Buffer&#34;&gt;&lt;a href=&#34;#Buffer&#34; class=&#34;headerlink&#34; title=&#34;Buffer&#34;&gt;&lt;/a&gt;Buffer&lt;/h4&gt;&lt;p&gt;通过使用固定大小的Buffer，降低通信次数，减少碎片信息发送，提高带宽利用率&lt;/p&gt;
&lt;h4 id=&#34;碎片内存整合&#34;&gt;&lt;a href=&#34;#碎片内存整合&#34; class=&#34;headerlink&#34; title=&#34;碎片内存整合&#34;&gt;&lt;/a&gt;碎片内存整合&lt;/h4&gt;&lt;h3 id=&#34;ZeRO-Offload&#34;&gt;&lt;a href=&#34;#ZeRO-Offload&#34; class=&#34;headerlink&#34; title=&#34;ZeRO-Offload&#34;&gt;&lt;/a&gt;ZeRO-Offload&lt;/h3&gt;&lt;p&gt;见论文，主要是把显存的优化器参数卸载到CPU内存。&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">http://example.com/2024/03/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B01/</guid>
            <title>大模型通信笔记1</title>
            <link>http://example.com/2024/03/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B01/</link>
            <category>技术</category>
            <category>大模型训练</category>
            <category>博客</category>
            <category>通信</category>
            <pubDate>Tue, 26 Mar 2024 17:38:32 +0800</pubDate>
            <description><![CDATA[ &lt;h2 id=&#34;流水线并行&#34;&gt;&lt;a href=&#34;#流水线并行&#34; class=&#34;headerlink&#34; title=&#34;流水线并行&#34;&gt;&lt;/a&gt;流水线并行&lt;/h2&gt;&lt;h3 id=&#34;朴素层并行&#34;&gt;&lt;a href=&#34;#朴素层并行&#34; class=&#34;headerlink&#34; title=&#34;朴素层并行&#34;&gt;&lt;/a&gt;朴素层并行&lt;/h3&gt;&lt;p&gt;朴素层并行，将模型拆分为多个层，放在不同的GPU上执行&lt;br&gt;但是问题很明显：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU利用率低：任意时刻只有一个GPU在工作，其他GPU都在等待结果&lt;/li&gt;
&lt;li&gt;计算和通信没有重叠&lt;/li&gt;
&lt;li&gt;显存占用高，GPU1需要保存所有激活。等待参数更新完成&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;GPipe&#34;&gt;&lt;a href=&#34;#GPipe&#34; class=&#34;headerlink&#34; title=&#34;GPipe&#34;&gt;&lt;/a&gt;GPipe&lt;/h3&gt;&lt;p&gt;Gpipe将整个&lt;strong&gt;minibatch分为4个microbatch&lt;/strong&gt;，然后由GPU0进行计算，之后每个microbatch计算完直接传递给GPU1，以此类推，进行整个前向、反向传播。&lt;br&gt;假设pipeline深度n，microbatch数量m，那么浪费的时间占比为：&lt;br&gt;$$&lt;br&gt;1-\frac{m}{m+n-1}&lt;br&gt;$$&lt;br&gt;所以需要增加microbatch数量m&lt;br&gt;Gpipe在计算过程中，把中间激活用完即弃，因此节省了显存，但是增加了计算代价。&lt;/p&gt;
&lt;h3 id=&#34;PipeDream&#34;&gt;&lt;a href=&#34;#PipeDream&#34; class=&#34;headerlink&#34; title=&#34;PipeDream&#34;&gt;&lt;/a&gt;PipeDream&lt;/h3&gt;&lt;p&gt;PipeDream在GPipe的基础上，在每个microbatch前向结束后就开始反向传播，节省了一些显存，bubble和Gpipe是一样的&lt;/p&gt;
&lt;h3 id=&#34;数据并行可以和流水线并行同时进行&#34;&gt;&lt;a href=&#34;#数据并行可以和流水线并行同时进行&#34; class=&#34;headerlink&#34; title=&#34;数据并行可以和流水线并行同时进行&#34;&gt;&lt;/a&gt;数据并行可以和流水线并行同时进行&lt;/h3&gt;&lt;p&gt;对任意给定GPU，有两个通信部份，一部分包含所有相同层GPU进行All_Reduce(数据并行)。另一部分和上下层进行通信（流水线）。&lt;/p&gt;
&lt;h2 id=&#34;张量并行&#34;&gt;&lt;a href=&#34;#张量并行&#34; class=&#34;headerlink&#34; title=&#34;张量并行&#34;&gt;&lt;/a&gt;张量并行&lt;/h2&gt;&lt;p&gt;张量并行分为两种情况：&lt;strong&gt;列划分&lt;/strong&gt;和&lt;strong&gt;行划分&lt;/strong&gt;&lt;br&gt;列划分：&lt;br&gt;$$&lt;br&gt;XA &amp;#x3D; X[A_1,A_2···A_n]&amp;#x3D;[XA_1,XA_2,···,XA_n]&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;行划分：&lt;/p&gt;
&lt;p&gt;$$&lt;br&gt;\mathbf{x}*A &amp;#x3D; \begin{bmatrix} x_1 &amp;amp; x_2 &amp;amp; \cdots &amp;amp; x_n \end{bmatrix} * \begin{bmatrix}A_1\A_2\A_3\··· \A_n\end{bmatrix}&amp;#x3D;X_1A_1+X_2A_2+X_3A_3···&lt;br&gt;$$&lt;/p&gt;
&lt;p&gt;对列并行来说，由于GeLU函数并不是线性的，因此需要在输出前进行一次通信来合并。&lt;/p&gt;
&lt;h3 id=&#34;2D并行&#34;&gt;&lt;a href=&#34;#2D并行&#34; class=&#34;headerlink&#34; title=&#34;2D并行&#34;&gt;&lt;/a&gt;2D并行&lt;/h3&gt;&lt;p&gt;具体来说，两个矩阵的结果仍然需要串行的计算。但是，单个矩阵中的4个子矩阵可以使用2*2的处理器来并行计算。&lt;/p&gt;
&lt;h3 id=&#34;2-5D并行&#34;&gt;&lt;a href=&#34;#2-5D并行&#34; class=&#34;headerlink&#34; title=&#34;2.5D并行&#34;&gt;&lt;/a&gt;2.5D并行&lt;/h3&gt;&lt;p&gt;这个就是在2D并行的基础上，左矩阵为两个2*2矩阵垂直拼接，那么这两个矩阵是可以分开计算的，所以可以8处理器并行计算。&lt;/p&gt;
&lt;h2 id=&#34;3D并行&#34;&gt;&lt;a href=&#34;#3D并行&#34; class=&#34;headerlink&#34; title=&#34;3D并行&#34;&gt;&lt;/a&gt;3D并行&lt;/h2&gt;&lt;p&gt;流水线+数据+张量并行&lt;/p&gt;
&lt;p&gt;首先，每个节点8个GPU，共两个节点&lt;/p&gt;
&lt;p&gt;8个GPU，分为两组，每组负责一个Layer，一共四个组进行流水线并行。&lt;br&gt;每个组内，用两张卡进行张量并行，一个组分为两个张量小组。一个张量小组负责一个具体的张量运算。&lt;br&gt;对于两个张量小组之间，分享同一个batch不同的数据，在计算结束后两个小组之间要进行all reduce通信。&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
