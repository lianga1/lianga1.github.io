{
    "version": "https://jsonfeed.org/version/1",
    "title": "意大利炮打友军 • All posts by \"技术\" category",
    "description": "",
    "home_page_url": "http://example.com",
    "items": [
        {
            "id": "http://example.com/2024/03/30/DeepSpeed%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%EF%BC%9Aelasticity/",
            "url": "http://example.com/2024/03/30/DeepSpeed%E4%BB%A3%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%E4%B9%8B%EF%BC%9Aelasticity/",
            "title": "DeepSpeed代码阅读笔记之：elasticity",
            "date_published": "2024-03-30T12:54:57.000Z",
            "content_html": "<p>本笔记是DeepSpeed代码阅读的第一篇笔记，本周的主要任务是阅读DeepSpeed python代码中的</p>\n<h2 id=\"DeepSpeed-部署\"><a href=\"#DeepSpeed-部署\" class=\"headerlink\" title=\"DeepSpeed 部署\"></a>DeepSpeed 部署</h2><p>DeepSpeed 部署的过程如下：</p>\n<ol>\n<li>安装cuda与pytorch</li>\n<li>按照requirements文件夹安装依赖：</li>\n</ol>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs bash\">pip install -r requirements/requirements-dev.txt <br>pip install -r requirements/requirements.txt<br>pip install -r requirements/requirements-sparse_attn.txt <br>pip install mpi4py<br>pip install --ignore-installed PyYAML<br></code></pre></td></tr></table></figure>\n<p><strong>注意：attn文件里的triton 可能没有1.0版本</strong><br><strong>mpi4py可能需要通过conda安装</strong><br>3. 安装DeepSpeed:运行install.sh<br><strong>注意：deepspeed需要全目录有rw权限</strong></p>\n<p>至此，安装已完成，可以使用DeepSpeedExample目录下的例程来测试。</p>\n<h2 id=\"elasticity目录代码\"><a href=\"#elasticity目录代码\" class=\"headerlink\" title=\"elasticity目录代码\"></a>elasticity目录代码</h2><p>init中说明了本目录下有如下几个文件：</p>\n<figure class=\"highlight ada\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ada\"><span class=\"hljs-comment\">--elasticity</span><br>    |<span class=\"hljs-comment\">-- __init__.py</span><br>    |<span class=\"hljs-comment\">-- elasticity.py</span><br>    |<span class=\"hljs-comment\">-- utils.py</span><br>    |<span class=\"hljs-comment\">-- contants.py</span><br>    |<span class=\"hljs-comment\">-- elastic_agent.py</span><br>    |<span class=\"hljs-comment\">-- config.py</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"init-py\"><a href=\"#init-py\" class=\"headerlink\" title=\"_init_.py\"></a>_<em>init_</em>.py</h2><p>这个代码主要是把目录下的文件中包含外部接口的文件进行引用，需要判断pytorch版本是否大于1.11，只有高于此版本才能使用DSElasticAgent类</p>\n<h2 id=\"elasticity\"><a href=\"#elasticity\" class=\"headerlink\" title=\"elasticity\"></a>elasticity</h2><p>elasticity.py中给出了几个接口函数用来供外部调用</p>\n<h3 id=\"compute-elastic-config\"><a href=\"#compute-elastic-config\" class=\"headerlink\" title=\"compute_elastic_config\"></a>compute_elastic_config</h3><p>调用弹性计算的核心代码，在DeepSpeedConfig类中会检查config是否有配置弹性计算，如果有会调用这个函数最终得到总batch——size和根据当前可用GPU数量得到的micro_batch(用于数据并行)（可选）</p>\n<p>elasticity 0.1版本和0.2版本分别调用不同的函数来得到final_batch_size。</p>\n<p>最后，通过检查micro_batch_size能否在数据并行中和batch_size 匹配(batch_size分在每个GPU上的大小能为micro_batch_size整倍)</p>\n<p><strong>感觉这部分代码的去耦合做的很不好</strong></p>\n<h3 id=\"elasticity-enabled\"><a href=\"#elasticity-enabled\" class=\"headerlink\" title=\"elasticity_enabled\"></a>elasticity_enabled</h3><p>检查ds_config的ELSASTICITY是否启用</p>\n<h3 id=\"ensure-immutable-elastic-config\"><a href=\"#ensure-immutable-elastic-config\" class=\"headerlink\" title=\"ensure_immutable_elastic_config\"></a>ensure_immutable_elastic_config</h3><p>确保在资源管理器启用的情况下，根据环境变量中给Deepspeed的弹性配置和deepspeed自身的配置来检查是否匹配。</p>\n<p>除此之外，elasticity中内部还有关于micro_batch_size和total_batch_size计算实现的代码</p>\n<h3 id=\"get-compatible-gpus-v01\"><a href=\"#get-compatible-gpus-v01\" class=\"headerlink\" title=\"_get_compatible_gpus_v01\"></a>_get_compatible_gpus_v01</h3><p>这个函数主要是得到batch_size和可用gpu数量。首先按照指定的micro_batches得到候选的batch_size。这个过程是给定的mrbs来找出最大合适的batch_size，存储在列表里。<br>在此之后，通过batch_sized候选列表中，按照偏好（大or小batch）得到最好的合适的（满足GPU数量和偏好）的batch_size。</p>\n<figure class=\"highlight stata\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stata\">注意：这里满足GPU数量是指mrbs可以被<span class=\"hljs-keyword\">bs</span>整除，同时在给定最大or最小GPU数量中。<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"get-compatible-gpus-v02\"><a href=\"#get-compatible-gpus-v02\" class=\"headerlink\" title=\"_get_compatible_gpus_v02\"></a>_get_compatible_gpus_v02</h3><p>在v01函数的基础上，这个函数根据bs的大小和GPU，根据节点的GPU数量来调整mrbs数量。以及根据数据并行dpsz来得到bs&#x3D;bs*dpsz。</p>\n<h2 id=\"utils\"><a href=\"#utils\" class=\"headerlink\" title=\"utils\"></a>utils</h2><p>仅负责检查torch版本是否匹配</p>\n<h2 id=\"constant\"><a href=\"#constant\" class=\"headerlink\" title=\"constant\"></a>constant</h2><p>存储了必需的常数，类似ENABLE，DS最低版本，环境变量名。默认bs等。</p>\n<h2 id=\"elastic-agent\"><a href=\"#elastic-agent\" class=\"headerlink\" title=\"elastic_agent\"></a>elastic_agent</h2><p>实现了pytorch LocalElasticAgent的子类。</p>\n<h3 id=\"set-master-addr-port\"><a href=\"#set-master-addr-port\" class=\"headerlink\" title=\"_set_master_addr_port\"></a>_set_master_addr_port</h3><p>这个方法检查主节点的地址（端口），如果没有会自动生成</p>\n<h3 id=\"start-workers\"><a href=\"#start-workers\" class=\"headerlink\" title=\"_start_workers\"></a>_start_workers</h3><p>这个方法使用torch distributed的WorkerGroup类作为参数，给每个worker设定必要的环境变量后，给关于本地worker数量的环境变量进行更新。同时指定必要的参数后，启动workers的进程。</p>\n<h3 id=\"invoke-run\"><a href=\"#invoke-run\" class=\"headerlink\" title=\"_invoke_run\"></a>_invoke_run</h3><p>这个方法在worker启动后，每隔一段时间监控当前workerGroup的状态。<br>可能会遇到节点工作失败的状况，则会选择进行重启worker或者在全部失效时进行报错推出<br>在遇到节点加入或退出时，会进行记录并重启workers。</p>\n<h2 id=\"config-py\"><a href=\"#config-py\" class=\"headerlink\" title=\"config.py\"></a>config.py</h2><p>这个文件主要定义了和elasticity相关的错误抛出，以及对config从ds_config到elasticity_config参数的变换和类型检测。</p>\n<h2 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h2><ol>\n<li>为什么在elasticity文件中有预定义的HCN_LIST</li>\n<li>DS相比pytorch的Elasticity多了什么功能？</li>\n</ol>\n",
            "tags": [
                "技术",
                "大模型训练",
                "课题组",
                "笔记"
            ]
        },
        {
            "id": "http://example.com/2024/03/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B02/",
            "url": "http://example.com/2024/03/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B02/",
            "title": "大模型通信笔记2",
            "date_published": "2024-03-26T11:54:58.000Z",
            "content_html": "<h2 id=\"数据并行\"><a href=\"#数据并行\" class=\"headerlink\" title=\"数据并行\"></a>数据并行</h2><p>传统的数据并行是让每个GPU分别进行FWD和BWD，然后把梯度进行聚合操作，然后再下发给每个GPU，称为All Reduce。</p>\n<h3 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点\"></a>缺点</h3><ul>\n<li>存储开销大。每块GPU上都存了一份完整的模型，造成冗余</li>\n<li>通讯开销大。Server需要和每一个Worker进行梯度传输。当Server和Worker不在一台机器上时，Server的带宽将会成为整个系统的计算效率瓶颈。</li>\n</ul>\n<h3 id=\"异步梯度更新\"><a href=\"#异步梯度更新\" class=\"headerlink\" title=\"异步梯度更新\"></a>异步梯度更新</h3><ul>\n<li>Worker不等待梯度更新，用旧的参数进行下一轮训练，可能会延迟一步更新梯度，整体收敛速度变慢，但是提升通讯计算比。</li>\n<li>延迟步数会指定</li>\n</ul>\n<h3 id=\"分布式数据并行\"><a href=\"#分布式数据并行\" class=\"headerlink\" title=\"分布式数据并行\"></a>分布式数据并行</h3><p>核心目标是降低通信压力，因此要将Server的通信压力转到Worker上，最简单的就是Ring-AllReduce。</p>\n<h4 id=\"Ring-Allreduce\"><a href=\"#Ring-Allreduce\" class=\"headerlink\" title=\"Ring Allreduce\"></a>Ring Allreduce</h4><p>核心思路是实现Reduce Scatter和All-Gather。GPU每次之和前后两个GPU通信，1卡给2卡发a号数据，2给3发b号，以此类推。三次更新后每张卡都有1个号的完整的数据。</p>\n<p>之后在进行All-Gather，依旧环形通信，把每个部分全聚合的都发给下一个，然后依此类推，3轮通信就可以覆盖所有。</p>\n<h2 id=\"显存开销\"><a href=\"#显存开销\" class=\"headerlink\" title=\"显存开销\"></a>显存开销</h2><p>数据并行中，每个卡都存储了所有参数，怎么办？</p>\n<p>在实际存储中，分为两部分存储：</p>\n<ul>\n<li>模型状态：包括参数，优化器，梯度等</li>\n<li>驻留数据：包括activation，碎片内存和缓冲区等。</li>\n</ul>\n<h2 id=\"优化措施\"><a href=\"#优化措施\" class=\"headerlink\" title=\"优化措施\"></a>优化措施</h2><h3 id=\"混合精度训练\"><a href=\"#混合精度训练\" class=\"headerlink\" title=\"混合精度训练\"></a>混合精度训练</h3><p>对于参数，activation，梯度，都使用fp16，对于参数（多存一份）和优化器使用fp32。<br>模型必存数据为$K\\phi$,那么最终总存储数据为$K\\phi + 4\\phi$<br>实际上，activation大小和batch有关，而且是可以抛弃的。</p>\n<h3 id=\"ZeRO-DP\"><a href=\"#ZeRO-DP\" class=\"headerlink\" title=\"ZeRO-DP\"></a>ZeRO-DP</h3><h4 id=\"第一步：优化器分割\"><a href=\"#第一步：优化器分割\" class=\"headerlink\" title=\"第一步：优化器分割\"></a>第一步：优化器分割</h4><p>每张卡只存储一部分优化器参数，在数据并行中，先通过AllReduce得到完整梯度，每个卡都更新自己的一部分梯度和参数，然后再AllGather。产生单卡通讯量$\\phi$。</p>\n<h4 id=\"第二步：梯度分割\"><a href=\"#第二步：梯度分割\" class=\"headerlink\" title=\"第二步：梯度分割\"></a>第二步：梯度分割</h4><p>经过FWD和BWD后，对梯度进行Reduce-Scatter，保证每张卡都有自己一份聚合梯度，用分割的优化器和梯度进行更新相应的W，然后再AllGather参数进行更新</p>\n<h4 id=\"第三步：参数分割\"><a href=\"#第三步：参数分割\" class=\"headerlink\" title=\"第三步：参数分割\"></a>第三步：参数分割</h4><p>FWD时，先All Gather一次参数，用完即弃。<br>BWD时，再All Gather一次参数，用完即弃<br>用自己的梯度进行一次All Gather得到完整梯度<br>更新参数，无需通信。</p>\n<h3 id=\"ZeRO-R\"><a href=\"#ZeRO-R\" class=\"headerlink\" title=\"ZeRO-R\"></a>ZeRO-R</h3><p>通过对驻留数据进行优化来实现显存使用减少和通信负载降低。</p>\n<h4 id=\"activation\"><a href=\"#activation\" class=\"headerlink\" title=\"activation\"></a>activation</h4><p>每块GPU上只维护部分的activation，需要时再聚合。或者重新计算。</p>\n<h4 id=\"Buffer\"><a href=\"#Buffer\" class=\"headerlink\" title=\"Buffer\"></a>Buffer</h4><p>通过使用固定大小的Buffer，降低通信次数，减少碎片信息发送，提高带宽利用率</p>\n<h4 id=\"碎片内存整合\"><a href=\"#碎片内存整合\" class=\"headerlink\" title=\"碎片内存整合\"></a>碎片内存整合</h4><h3 id=\"ZeRO-Offload\"><a href=\"#ZeRO-Offload\" class=\"headerlink\" title=\"ZeRO-Offload\"></a>ZeRO-Offload</h3><p>见论文，主要是把显存的优化器参数卸载到CPU内存。</p>\n",
            "tags": [
                "技术",
                "大模型训练",
                "博客",
                "通信"
            ]
        },
        {
            "id": "http://example.com/2024/03/26/linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03/",
            "url": "http://example.com/2024/03/26/linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B03/",
            "title": "linux学习笔记3",
            "date_published": "2024-03-26T11:14:15.000Z",
            "content_html": "",
            "tags": [
                "技术",
                "博客",
                "Linux"
            ]
        },
        {
            "id": "http://example.com/2024/03/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B01/",
            "url": "http://example.com/2024/03/26/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E9%80%9A%E4%BF%A1%E7%AC%94%E8%AE%B01/",
            "title": "大模型通信笔记1",
            "date_published": "2024-03-26T09:38:32.000Z",
            "content_html": "<h2 id=\"流水线并行\"><a href=\"#流水线并行\" class=\"headerlink\" title=\"流水线并行\"></a>流水线并行</h2><h3 id=\"朴素层并行\"><a href=\"#朴素层并行\" class=\"headerlink\" title=\"朴素层并行\"></a>朴素层并行</h3><p>朴素层并行，将模型拆分为多个层，放在不同的GPU上执行<br>但是问题很明显：</p>\n<ul>\n<li>GPU利用率低：任意时刻只有一个GPU在工作，其他GPU都在等待结果</li>\n<li>计算和通信没有重叠</li>\n<li>显存占用高，GPU1需要保存所有激活。等待参数更新完成</li>\n</ul>\n<h3 id=\"GPipe\"><a href=\"#GPipe\" class=\"headerlink\" title=\"GPipe\"></a>GPipe</h3><p>Gpipe将整个<strong>minibatch分为4个microbatch</strong>，然后由GPU0进行计算，之后每个microbatch计算完直接传递给GPU1，以此类推，进行整个前向、反向传播。<br>假设pipeline深度n，microbatch数量m，那么浪费的时间占比为：<br>$$<br>1-\\frac{m}{m+n-1}<br>$$<br>所以需要增加microbatch数量m<br>Gpipe在计算过程中，把中间激活用完即弃，因此节省了显存，但是增加了计算代价。</p>\n<h3 id=\"PipeDream\"><a href=\"#PipeDream\" class=\"headerlink\" title=\"PipeDream\"></a>PipeDream</h3><p>PipeDream在GPipe的基础上，在每个microbatch前向结束后就开始反向传播，节省了一些显存，bubble和Gpipe是一样的</p>\n<h3 id=\"数据并行可以和流水线并行同时进行\"><a href=\"#数据并行可以和流水线并行同时进行\" class=\"headerlink\" title=\"数据并行可以和流水线并行同时进行\"></a>数据并行可以和流水线并行同时进行</h3><p>对任意给定GPU，有两个通信部份，一部分包含所有相同层GPU进行All_Reduce(数据并行)。另一部分和上下层进行通信（流水线）。</p>\n<h2 id=\"张量并行\"><a href=\"#张量并行\" class=\"headerlink\" title=\"张量并行\"></a>张量并行</h2><p>张量并行分为两种情况：<strong>列划分</strong>和<strong>行划分</strong><br>列划分：<br>$$<br>XA &#x3D; X[A_1,A_2···A_n]&#x3D;[XA_1,XA_2,···,XA_n]<br>$$</p>\n<p>行划分：</p>\n<p>$$<br>\\mathbf{x}*A &#x3D; \\begin{bmatrix} x_1 &amp; x_2 &amp; \\cdots &amp; x_n \\end{bmatrix} * \\begin{bmatrix}A_1\\A_2\\A_3\\··· \\A_n\\end{bmatrix}&#x3D;X_1A_1+X_2A_2+X_3A_3···<br>$$</p>\n<p>对列并行来说，由于GeLU函数并不是线性的，因此需要在输出前进行一次通信来合并。</p>\n<h3 id=\"2D并行\"><a href=\"#2D并行\" class=\"headerlink\" title=\"2D并行\"></a>2D并行</h3><p>具体来说，两个矩阵的结果仍然需要串行的计算。但是，单个矩阵中的4个子矩阵可以使用2*2的处理器来并行计算。</p>\n<h3 id=\"2-5D并行\"><a href=\"#2-5D并行\" class=\"headerlink\" title=\"2.5D并行\"></a>2.5D并行</h3><p>这个就是在2D并行的基础上，左矩阵为两个2*2矩阵垂直拼接，那么这两个矩阵是可以分开计算的，所以可以8处理器并行计算。</p>\n<h2 id=\"3D并行\"><a href=\"#3D并行\" class=\"headerlink\" title=\"3D并行\"></a>3D并行</h2><p>流水线+数据+张量并行</p>\n<p>首先，每个节点8个GPU，共两个节点</p>\n<p>8个GPU，分为两组，每组负责一个Layer，一共四个组进行流水线并行。<br>每个组内，用两张卡进行张量并行，一个组分为两个张量小组。一个张量小组负责一个具体的张量运算。<br>对于两个张量小组之间，分享同一个batch不同的数据，在计算结束后两个小组之间要进行all reduce通信。</p>\n",
            "tags": [
                "技术",
                "大模型训练",
                "博客",
                "通信"
            ]
        },
        {
            "id": "http://example.com/2024/03/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/",
            "url": "http://example.com/2024/03/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/",
            "title": "操作系统学习笔记2：多线程",
            "date_published": "2024-03-22T09:44:11.000Z",
            "content_html": "<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>现代软件大多支持多线程，相比于进程切换，线程共享代码段，数据段以及其他系统资源，但是拥有单独的寄存器和堆栈。<br>服务器采用多线程，可以减少创建进程的资源消耗，同时处理多个并发请求。</p>\n<h3 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h3><ul>\n<li>响应性提高</li>\n<li>资源共享</li>\n<li>创建与切换更加经济</li>\n</ul>\n<h2 id=\"多核编程\"><a href=\"#多核编程\" class=\"headerlink\" title=\"多核编程\"></a>多核编程</h2><p>并行性 vs 并发性<br><strong>并行性</strong>：是同时执行多个任务<br><strong>并发性</strong>：是让每个任务都能取得进展，在单处理器上也能实现</p>\n<p>Amdahl定理：程序中只有S%可以串行执行时，优化比<br>$$\\eta \\leq \\frac{1}{S+\\frac{1-S}{N}}$$</p>\n<h3 id=\"挑战\"><a href=\"#挑战\" class=\"headerlink\" title=\"挑战\"></a>挑战</h3><ul>\n<li>分析一个任务是否可以多核</li>\n<li>平衡某些任务适合单独核心执行</li>\n<li>数据分割</li>\n<li>数据依赖，避免同步性受损</li>\n<li>调试程序</li>\n</ul>\n<h3 id=\"并行类型\"><a href=\"#并行类型\" class=\"headerlink\" title=\"并行类型\"></a>并行类型</h3>",
            "tags": [
                "技术",
                "博客",
                "操作系统"
            ]
        },
        {
            "id": "http://example.com/2024/03/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/",
            "url": "http://example.com/2024/03/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/",
            "title": "操作系统学习笔记1",
            "date_published": "2024-03-22T07:52:53.000Z",
            "content_html": "<h2 id=\"内核设计\"><a href=\"#内核设计\" class=\"headerlink\" title=\"内核设计\"></a>内核设计</h2><h3 id=\"微内核\"><a href=\"#微内核\" class=\"headerlink\" title=\"微内核\"></a>微内核</h3><p>微内核实现了一个功能较少，但是容易扩展的内核架构，客户程序和不同的功能之间提供<strong>消息传递</strong>功能。除了必须内核功能外，功能组件都作为用户程序来实现。</p>\n<h3 id=\"模块化\"><a href=\"#模块化\" class=\"headerlink\" title=\"模块化\"></a>模块化</h3><p>例如Solaris，有7种可以在运行时加载的模块。</p>\n<h3 id=\"混合架构例子\"><a href=\"#混合架构例子\" class=\"headerlink\" title=\"混合架构例子\"></a>混合架构例子</h3><ul>\n<li>MacOS X，其Mach内核提供了远程过程调用，进程间通信等功能。BSD内核提供了POSIX库和文件系统等功能。</li>\n<li>iOS基于MacOSX，在系统的顶层提供了媒体服务用来支持图形化，Cocoa Touch库提供了有触屏硬件支持的Objective-C API</li>\n<li>Android由Linux内核，增加了一套Dalvik虚拟机和核心库。采用基于Java的Android API用来进行Java开发。运行在Dalvik虚拟机。</li>\n</ul>\n<h2 id=\"调试\"><a href=\"#调试\" class=\"headerlink\" title=\"调试\"></a>调试</h2><h3 id=\"D-Trace\"><a href=\"#D-Trace\" class=\"headerlink\" title=\"D Trace\"></a>D Trace</h3><p>使用D语言</p>\n<p>这个工具可以动态探测运行系统。跟踪系统调用以及指令的运行环境（用户or内核）<br>DTrace提供内核探头，拥有内核运行的编译器，生成安全指令。通过调用创建的内核探头，执行<strong>启用控制块</strong>可以捕获一些数据。</p>\n<h2 id=\"操作系统生成\"><a href=\"#操作系统生成\" class=\"headerlink\" title=\"操作系统生成\"></a>操作系统生成</h2><p>SYSGEN程序用于配置和生成操作系统。系统安装可以有三种情况</p>\n<ul>\n<li>极端定制：修改源代码，重新编译系统生成</li>\n<li>极端通用：系统描述表已定义好安装的模块，直接激活</li>\n<li>折中：选择模块进行链接来生成</li>\n</ul>\n<h2 id=\"编程实例\"><a href=\"#编程实例\" class=\"headerlink\" title=\"编程实例\"></a>编程实例</h2><h3 id=\"基础\"><a href=\"#基础\" class=\"headerlink\" title=\"基础\"></a>基础</h3><p>头文件：</p>\n<ul>\n<li>linux&#x2F;init.h</li>\n<li>linux&#x2F;kernel.h</li>\n<li>linux.model.h</li>\n</ul>\n<p>重要函数：</p>\n<ul>\n<li>printk：存储到内核日志缓冲区，用dmesg访问，可以指定优先级</li>\n<li>module_init() &amp; module_exit():用于注册模块。</li>\n</ul>\n<p>编译好的内核模块，使用sudo insmod simple.ko来插入内核<br>使用sudo ramos simple来移除</p>\n<h3 id=\"数据结构\"><a href=\"#数据结构\" class=\"headerlink\" title=\"数据结构\"></a>数据结构</h3><p>kmalloc：分配内核内存 </p>\n<h1 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h1><h2 id=\"进程概念\"><a href=\"#进程概念\" class=\"headerlink\" title=\"进程概念\"></a>进程概念</h2><p>进程是一个活动实体，包含代码、程序计数器、堆栈等。</p>\n<h3 id=\"进程状态\"><a href=\"#进程状态\" class=\"headerlink\" title=\"进程状态\"></a>进程状态</h3><p>包括：</p>\n<ul>\n<li>新进程：创建进程</li>\n<li>运行中：指令执行中</li>\n<li>等待：进程等待某个信号</li>\n<li>就绪：等待分配处理器</li>\n<li>终止：进程已完成</li>\n</ul>\n<h3 id=\"进程控制块\"><a href=\"#进程控制块\" class=\"headerlink\" title=\"进程控制块\"></a>进程控制块</h3><p>存储了一个进程的相关信息：</p>\n<ul>\n<li>进程状态</li>\n<li>程序计数器</li>\n<li>CPU寄存器</li>\n<li>CPU调度信息</li>\n<li>内存管理信息</li>\n<li>记账信息</li>\n<li>IO状态信息</li>\n</ul>\n<p>信息采用task_struct来表示，位于&lt;linux&#x2F;sched.h&gt;<br>这个结构还存储了父进程、子进程等。<br>linux系统使用一个current_state结构来指向当前运行的进程。</p>\n<h2 id=\"进程调度\"><a href=\"#进程调度\" class=\"headerlink\" title=\"进程调度\"></a>进程调度</h2><p>被加载运行的进程，进入<strong>任务队列</strong>，在内存中等待运行的就是<strong>就绪队列</strong>，等待IO的进程就放在对应的<strong>设备队列</strong>。</p>\n<p>对于整个流程，进程首先被创建，加入到就绪队列，之后被分配到CPU执行时，会有几种可能：</p>\n<ul>\n<li>发出IO请求，进入IO队列</li>\n<li>创建子进程，等待进程执行结束</li>\n<li>中断产生，被放回就绪队列</li>\n</ul>\n<h3 id=\"调度程序\"><a href=\"#调度程序\" class=\"headerlink\" title=\"调度程序\"></a>调度程序</h3><p>调度程序分为短期调度程序和长期调度程序。</p>\n<ul>\n<li>短期调度程序针对的程序IO请求频繁，决策时间较短。</li>\n<li>长期调度程序的创建和杀死速度都较慢，因此有更多时间进行调度。</li>\n</ul>\n<p>长期调度程序应选择IO于CPU密集型程序并重的进程。</p>\n<h3 id=\"上下文切换\"><a href=\"#上下文切换\" class=\"headerlink\" title=\"上下文切换\"></a>上下文切换</h3><p>切换进程需要切换状态，典型时间为几毫秒。</p>\n<h2 id=\"进程运行\"><a href=\"#进程运行\" class=\"headerlink\" title=\"进程运行\"></a>进程运行</h2><p>进程可以产生子进程，因此其组织结构是“树”。init进程是pid为1的进程</p>\n<p>重要的init子进程：</p>\n<ul>\n<li>kthreadd：创建额外内核进程。</li>\n<li>sshd：创建ssh连接</li>\n</ul>\n<p>ps -el 列出进程</p>\n<p>fork（）函数创建一个子进程，子进程复制父进程的地址空间。它们都执行fork之后的内容。父进程fork（）返回子进程pid。子进程返回0。父进程可能会需要wait子进程。</p>\n<p>注意：windows的createProcess函数不继承父进程空间，而是需要制定一个特定程序。</p>\n<p>父进程可以调用wait，让子进程（僵尸进程）标识符得到释放。并且如果父进程先被终止，如果没有级连终止的要求下，init进程成为子进程的父。</p>\n<h2 id=\"进程间通信\"><a href=\"#进程间通信\" class=\"headerlink\" title=\"进程间通信\"></a>进程间通信</h2><p>进程和其他进程通信称为协作。进程间协作机制称为IPC，IPC有两种基本模型：<strong>共享内存</strong>和<strong>消息传递</strong></p>\n<p>目前，在多核系统上，共享内存机制由于高速缓存的不一致性，性能要差于消息传递。</p>\n<h3 id=\"共享内存\"><a href=\"#共享内存\" class=\"headerlink\" title=\"共享内存\"></a>共享内存</h3><p>共享内存区域驻留在创建共享内存段的进程内。并且负责确保内存不会被同时写入。<br>共享内存有一个循环数组，用于共享进程发送信息的缓冲。</p>\n<h3 id=\"消息传递\"><a href=\"#消息传递\" class=\"headerlink\" title=\"消息传递\"></a>消息传递</h3><p>消息传递需要至少提供send()和receive()两个操作。这样要考虑几个问题：</p>\n<ul>\n<li>直接or间接通信</li>\n<li>同步or异步</li>\n<li>自动or显式缓冲</li>\n</ul>\n<h4 id=\"通信的直接or间接\"><a href=\"#通信的直接or间接\" class=\"headerlink\" title=\"通信的直接or间接\"></a>通信的直接or间接</h4><p>采用直接通信的send()和receive()都需要直接指定接收方的地址，可能是对称或非对称的（非对称即接收方只能接受向其发送的进程信息）</p>\n<p>间接通信的方法则通过邮箱或端口来发送信息。通过把邮箱抽象为一个对象，这种方式有如下特点：</p>\n<ul>\n<li>共享邮箱才能建立链路</li>\n<li>一个链路与多个进程关联</li>\n<li>两个进程之间可以有多个链路<br>但是一个消息只能被一个进程接收<br>邮箱可以为系统或进程拥有，进程拥有的邮箱必须要确定所有者和使用者。所有者只能接受信息，使用者只能发送信息。<br>进程被终止后，邮箱将消失。操作系统的邮箱是独立存在的。操作系统提供机制允许进程进行创建、删除、使用邮箱。而且通过系统调用，邮箱的所有权可以传给其他进程。</li>\n</ul>\n<h4 id=\"同步\"><a href=\"#同步\" class=\"headerlink\" title=\"同步\"></a>同步</h4><p>关于消息传递的同步性，有以下四种可能：</p>\n<ul>\n<li>阻塞发送：发送消息后，直到被接收，进程都将阻塞</li>\n<li>非阻塞发送：发送后继续操作</li>\n<li>阻塞接收：阻塞进程，直到能接收信息</li>\n<li>非阻塞接收：接收进程收到有效信息或空信息</li>\n</ul>\n<h4 id=\"缓存\"><a href=\"#缓存\" class=\"headerlink\" title=\"缓存\"></a>缓存</h4><p>缓存有三种形式：</p>\n<ul>\n<li>零容量：要求发送者应当阻塞发送，因为消息队列不能等待。</li>\n<li>有限容量：最多n条消息可以等待，超过这个数量时进程将阻塞</li>\n<li>无限容量：进程不会阻塞发送</li>\n</ul>\n<h3 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h3><h4 id=\"posix\"><a href=\"#posix\" class=\"headerlink\" title=\"posix\"></a>posix</h4><p>posix通过内存映射文件共享内存，通过系统调用shm_open(name,O_CREAT|O_RDRW,0666)函数来创建共享内存对象。<br>创建成功后，函数ftruncate(shm_fd,4096)用于配置对象的大小（4096字节）<br>最后，mmap()函数用于将内存映射文件包含共享内存。返回ptr<br>使用sprintf()将message写入ptr。<br>最终消费者使用了共享内存后，调用shm_unlink()移除共享内存</p>\n<h4 id=\"Mach\"><a href=\"#Mach\" class=\"headerlink\" title=\"Mach\"></a>Mach</h4><p>Mach通过消息传递（采用邮箱）实现<br>包括两个邮箱：内核邮箱和通知邮箱。调用msg_send()来发送消息，msg_receive()接收消息，msg_rpc()用来进行远程过程调用。<br>系统调用port_allocate()来创建新邮箱。可以指定最大排队信息，而且消息复制到邮箱中可以保证单个发送者的顺序统一。<br>发送消息如果遇到邮箱满了，可能会等待（无限或n毫秒），或者立刻返回，或者在操作系统中为一个线程存储一个消息。<br>邮箱可以形成一个邮箱集合来服务单个任务。port_status()用于返回指定邮箱的消息数量。<br>Mach本来是为了分布式系统设计，但是为了多核系统，Mach也可以使用虚拟内存，把发送者地址空间映射到接收者地址空间，来提高性能。</p>\n<h4 id=\"Windows\"><a href=\"#Windows\" class=\"headerlink\" title=\"Windows\"></a>Windows</h4><p>windows支持多个操作环境或子系统，应用程序通过消息传递来通信。Windows使用ALPC工具来进行进程间通信。<br>类似于TCP连接，Windows内部也使用了<strong>连接端口</strong>和<strong>通信端口</strong>区分的思想。此外，通信回调机制允许服务器和客户端在等待时也能响应接受请求。<br>这个机制包含三种技术：</p>\n<ul>\n<li>对于小消息，采用消息队列进行存储，复制传递</li>\n<li>对于大消息（256字节+）：采用区段对象传递，为共享内存。</li>\n<li>对于巨大消息，采用API直接读写目标地址空间。</li>\n</ul>\n<p>注意：ALPC不属于WinAPI</p>\n<h3 id=\"服务器和客户端通信\"><a href=\"#服务器和客户端通信\" class=\"headerlink\" title=\"服务器和客户端通信\"></a>服务器和客户端通信</h3><h4 id=\"套接字\"><a href=\"#套接字\" class=\"headerlink\" title=\"套接字\"></a>套接字</h4><p>详见计算机网络</p>\n<h4 id=\"RPC\"><a href=\"#RPC\" class=\"headerlink\" title=\"RPC\"></a>RPC</h4><p>RPC：远程过程调用</p>\n<p>RPC和套接字不同，具有明确的数据结构。和本地调用过程相似，RPC隐藏了远程调用的通信细节。<br>对于每个远程过程，客户端都有一个存根用来调用服务器端口，并传递参数。返回值也可以传递回客户端。<br>通过时间戳，系统可以避免RPC被重复执行。而且还需要和客户确认RPC调用已经收到且执行。这要求客户机实现RPC调用的发送后接收到ACK信息。<br>使用交会服务程序，可以让客户请求RPC的端口灵活分配。<br>RPC可用于实现分布式文件系统</p>\n<h4 id=\"管道\"><a href=\"#管道\" class=\"headerlink\" title=\"管道\"></a>管道</h4><p>管道是一个半双工的结构<br>分为<strong>普通管道</strong>和<strong>命名管道</strong><br>UNIX上，管道采用pipe(int fd[])函数来创建，fd[0]为读出端，fd[1]为写入端<br>父子进程通信可以使用管道来进行，因为子进程继承了夫进程的管道，他们共享一个管道但是有两个fd。但是普通管道需要在同一机器上有父子关系的进程。</p>\n<p>命名管道：提供了一个双向的，不必须父子关系的，多进程通信的管道。<br>而且通信结束后，管道依旧存在。</p>\n<ul>\n<li><p>对于UNIX，管道通过mkfifo()系统调用来进行。通过调用对文件的读写函数来进行常规读写。只有显式删除才会关闭管道。这是半双工且单机通信的，除非用套接字来进行远程通信。</p>\n</li>\n<li><p>对于Windows，CreateNamedPipe()支持创建全双工且支持远程的通信。</p>\n</li>\n</ul>\n",
            "tags": [
                "技术",
                "博客",
                "操作系统"
            ]
        },
        {
            "id": "http://example.com/2024/03/15/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/",
            "url": "http://example.com/2024/03/15/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/",
            "title": "Linux学习笔记2",
            "date_published": "2024-03-15T02:05:10.000Z",
            "content_html": "<h2 id=\"账号文件\"><a href=\"#账号文件\" class=\"headerlink\" title=\"账号文件\"></a>账号文件</h2><h3 id=\"x2F-etc-x2F-passwd\"><a href=\"#x2F-etc-x2F-passwd\" class=\"headerlink\" title=\"&#x2F;etc&#x2F;passwd\"></a>&#x2F;etc&#x2F;passwd</h3><p>存储了</p>\n<ul>\n<li>账号信息</li>\n<li>x（密码）</li>\n<li>UID</li>\n<li>GID</li>\n<li>用户信息栏</li>\n<li>家目录</li>\n<li>shell</li>\n</ul>\n<h3 id=\"x2F-etc-x2F-shadow\"><a href=\"#x2F-etc-x2F-shadow\" class=\"headerlink\" title=\"&#x2F;etc&#x2F;shadow\"></a>&#x2F;etc&#x2F;shadow</h3><ul>\n<li>账号名</li>\n<li>密码</li>\n<li>最近修改</li>\n<li>不可修改天数</li>\n<li>建议修改天数</li>\n<li>警告天数</li>\n<li>过期密码宽限</li>\n<li>失效日期</li>\n</ul>\n<h2 id=\"忘记密码\"><a href=\"#忘记密码\" class=\"headerlink\" title=\"忘记密码\"></a>忘记密码</h2><p>普通用户：passwd<br>root：单人启动模式</p>\n<h2 id=\"用户组\"><a href=\"#用户组\" class=\"headerlink\" title=\"用户组\"></a>用户组</h2><p>&#x2F;etc&#x2F;group</p>\n<ul>\n<li>组名</li>\n<li>用户组密码</li>\n<li>GID</li>\n<li>支持的账号名称 逗号分开</li>\n</ul>\n<p>group：查看用户所属的组，第一个是有效用户组，即为创建文件时代表的组<br>newgrp：切换有效用户组，以另外一个单独的shell生效。</p>\n<p>加入用户组：root用usermod，组管理员用gpasswd</p>\n<h2 id=\"账号管理\"><a href=\"#账号管理\" class=\"headerlink\" title=\"账号管理\"></a>账号管理</h2><p>useradd：新建账户</p>\n<ul>\n<li>-g初始用户组</li>\n<li>-G次要用户组</li>\n<li>-e失效日期</li>\n<li>-f密码失效</li>\n<li>-s默认shell</li>\n</ul>\n<p>userdel：删除账户<br>usermod：修改存在的账户</p>\n<p>id：查询用户信息<br>finger：查询用户动态<br>chfn：改变自身动态</p>\n<h2 id=\"用户组管理\"><a href=\"#用户组管理\" class=\"headerlink\" title=\"用户组管理\"></a>用户组管理</h2><p>groupadd：新增组<br>groupmod：修改组<br>groupdel：删除组</p>\n<h2 id=\"ACL\"><a href=\"#ACL\" class=\"headerlink\" title=\"ACL\"></a>ACL</h2><p>ACL为访问控制列表，针对单一用户、单一目录来进行rwx的权限设置。</p>\n<p>setfacl：设置ACL参数</p>\n<ul>\n<li>-m为设置参数</li>\n<li>-x为删除参数</li>\n<li>-R递归设置</li>\n</ul>\n<p>使用方式：</p>\n<ul>\n<li>针对特定使用者：setfacl -m u:账号列表：rwx</li>\n<li>针对特定组：setfacl -m g:用户组列表：rwx</li>\n<li>针对有效权限：setfacl -m m:[rwx]<br>getfacl：查询文件权限<br>getfacl filename</li>\n</ul>\n<h2 id=\"用户身份切换\"><a href=\"#用户身份切换\" class=\"headerlink\" title=\"用户身份切换\"></a>用户身份切换</h2><p>su：切换shell执行不同身份</p>\n<ul>\n<li>-：直接变为root，作为login_shell</li>\n<li>-l：指定账号</li>\n<li>如无-，则表示用非login shell登录</li>\n</ul>\n<p>区别在于：非login shell时，你的环境变量还是使用的原来的用户，而loginshell会使用root的名称。</p>\n<p>sudo：以root权限来执行命令</p>\n<ul>\n<li>-b：后台执行</li>\n<li>-u：指定希望切换的使用者</li>\n</ul>\n<p>能否执行取决于是否在&#x2F;etc&#x2F;sudoers文件，可用visudo修改。<br>visudo可以通过添加用户，添加用户组，限制命令执行，别名等方式来简化流程。</p>\n<h2 id=\"特殊shell：-x2F-sbin-x2F-nologin\"><a href=\"#特殊shell：-x2F-sbin-x2F-nologin\" class=\"headerlink\" title=\"特殊shell：&#x2F;sbin&#x2F;nologin\"></a>特殊shell：&#x2F;sbin&#x2F;nologin</h2><p>系统账号可以登录，但是不能用shell访问系统资源</p>\n",
            "tags": [
                "技术",
                "博客",
                "Linux"
            ]
        },
        {
            "id": "http://example.com/2024/03/03/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/",
            "url": "http://example.com/2024/03/03/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/",
            "title": "Linux学习笔记1",
            "date_published": "2024-03-03T08:29:11.000Z",
            "content_html": "<h1 id=\"Linux学习笔记1\"><a href=\"#Linux学习笔记1\" class=\"headerlink\" title=\"Linux学习笔记1\"></a>Linux学习笔记1</h1><h2 id=\"启动运行级\"><a href=\"#启动运行级\" class=\"headerlink\" title=\"启动运行级\"></a>启动运行级</h2><p>Linux的&#x2F;etc&#x2F;rcX.d目录下存储着各个启动级的运行程序<br>运行级<strong>1</strong>时进入单用户模式，仅仅进行文件系统维护。标准运行级为<strong>3</strong>。运行级为<strong>5</strong>时会启动X Window服务。切换启动级别可以使用runlevel命令来设置</p>\n<h2 id=\"内核模块\"><a href=\"#内核模块\" class=\"headerlink\" title=\"内核模块\"></a>内核模块</h2><p>Linux内有两种方法插入设备驱动：</p>\n<ul>\n<li>编译进内核</li>\n<li>可插入的设备驱动</li>\n</ul>\n<p>linux内部有三种设备文件：</p>\n<ul>\n<li>字符设备文件：包括终端等</li>\n<li>块设备文件：包括硬盘</li>\n<li>网络设备文件：包括网卡和回环设备<br>每个设备都有一个节点文件，用于唯一标识设备（主设备号，次设备号）</li>\n</ul>\n<h2 id=\"设置终端\"><a href=\"#设置终端\" class=\"headerlink\" title=\"设置终端\"></a>设置终端</h2><p>可以使用setterm命令执行诸如：</p>\n<ul>\n<li>settterm -inversescreen on</li>\n<li>setterm -background white</li>\n<li>setterm -foreground black</li>\n</ul>\n<h2 id=\"GNU-nm\"><a href=\"#GNU-nm\" class=\"headerlink\" title=\"GNU nm\"></a>GNU nm</h2><p>这个命令可以分析obj文件并输出符号列表</p>\n<h2 id=\"man\"><a href=\"#man\" class=\"headerlink\" title=\"man\"></a>man</h2><p>man可以指定手册的部分，分为1-9内容</p>\n<ul>\n<li>1：命令名</li>\n<li>2：系统调用</li>\n<li>3：库调用</li>\n<li>4：特殊文件</li>\n<li>5：文件格式与约定</li>\n<li>6：游戏</li>\n<li>7：概览，约定</li>\n<li>8：root命令</li>\n<li>9：内核例程</li>\n</ul>\n<h2 id=\"ls\"><a href=\"#ls\" class=\"headerlink\" title=\"ls\"></a>ls</h2><p>如下参数：</p>\n<ul>\n<li>-F：标注文件类型</li>\n<li>-R：递归寻找</li>\n<li>加入字符串：模糊匹配</li>\n<li>–time&#x3D;atime：显示访问时间</li>\n<li>-d：不递归显示</li>\n</ul>\n<h2 id=\"copy\"><a href=\"#copy\" class=\"headerlink\" title=\"copy\"></a>copy</h2><p>cp source dest<br>如下参数：</p>\n<ul>\n<li>-i：询问是否覆盖</li>\n<li>-R：复制目录</li>\n</ul>\n<h2 id=\"链接\"><a href=\"#链接\" class=\"headerlink\" title=\"链接\"></a>链接</h2><p>ln srcfile linkfile</p>\n<p>参数；</p>\n<ul>\n<li>-s：符号链接</li>\n<li>无参数：硬链接</li>\n</ul>\n<h2 id=\"mv\"><a href=\"#mv\" class=\"headerlink\" title=\"mv\"></a>mv</h2><p>mv src dest</p>\n<p>移动文件是不会改变inode的。</p>\n<h2 id=\"目录操作\"><a href=\"#目录操作\" class=\"headerlink\" title=\"目录操作\"></a>目录操作</h2><p>mkdir ：-p可以创建缺失父目录</p>\n",
            "tags": [
                "技术",
                "博客",
                "Linux"
            ]
        },
        {
            "id": "http://example.com/2023/11/15/%E8%AF%BE%E9%A2%98%E7%BB%8423-11-15%E5%91%A8%E6%8A%A5/",
            "url": "http://example.com/2023/11/15/%E8%AF%BE%E9%A2%98%E7%BB%8423-11-15%E5%91%A8%E6%8A%A5/",
            "title": "课题组23-11-15周报",
            "date_published": "2023-11-15T08:09:06.000Z",
            "content_html": "<h1 id=\"实验关于fp16参数转换速度的问题\"><a href=\"#实验关于fp16参数转换速度的问题\" class=\"headerlink\" title=\"实验关于fp16参数转换速度的问题\"></a>实验关于fp16参数转换速度的问题</h1><p>本周进行了一个实验，主要用于观察pytorch中对张量转移的各种方法的性能差异。</p>\n<h2 id=\"实验思路\"><a href=\"#实验思路\" class=\"headerlink\" title=\"实验思路\"></a>实验思路</h2><h3 id=\"几种不同的传输方向\"><a href=\"#几种不同的传输方向\" class=\"headerlink\" title=\"几种不同的传输方向\"></a>几种不同的传输方向</h3><ul>\n<li>cpu -&gt; cpu</li>\n<li>cpu -&gt; gpu</li>\n<li>gpu -&gt; cpu</li>\n<li>gpu -&gt; gpu<h3 id=\"几种不同的数据\"><a href=\"#几种不同的数据\" class=\"headerlink\" title=\"几种不同的数据\"></a>几种不同的数据</h3></li>\n<li>fp32 -&gt; fp32</li>\n<li>fp32 -&gt; fp16<br><code>调用half()函数，将fp32数据转换为fp16数据</code></li>\n<li>fp16 -&gt; fp16</li>\n<li>fp16 -&gt; fp32<br><code>调用float()函数，将fp16数据转换为fp32数据</code></li>\n</ul>\n<p><strong>目前第三、四种暂未测试</strong></p>\n<h3 id=\"几种不同的传输方式\"><a href=\"#几种不同的传输方式\" class=\"headerlink\" title=\"几种不同的传输方式\"></a>几种不同的传输方式</h3><ul>\n<li>copy_()</li>\n<li>to()</li>\n</ul>\n<h2 id=\"实验过程\"><a href=\"#实验过程\" class=\"headerlink\" title=\"实验过程\"></a>实验过程</h2><p>准备一个目的地矩阵，一个源矩阵组（100个）。分别用随机数初始化。<br>循环100次，每次都遍历整个矩阵组，传输至对应的目的地矩阵。<br>测量总时长，对不同情况进行比较<br>代码模板如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> time<br>tensor_cpu_1 = torch.rand(<span class=\"hljs-number\">1000</span>, <span class=\"hljs-number\">1000</span>)<br>tensor_gpu_1 = torch.rand(<span class=\"hljs-number\">1000</span>,<span class=\"hljs-number\">1000</span>).cuda()<br>tensor_cpu_2 = torch.rand(<span class=\"hljs-number\">1000</span>, <span class=\"hljs-number\">1000</span>,<span class=\"hljs-number\">1000</span>)<br>tensor_gpu_2 = torch.rand(<span class=\"hljs-number\">1000</span>,<span class=\"hljs-number\">1000</span>,<span class=\"hljs-number\">1000</span>).cuda()<br>time_sum = <span class=\"hljs-number\">0</span><br><span class=\"hljs-keyword\">for</span> j <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">100</span>):<br>    start = time.time()<br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">100</span>):<br>        tensor_cpu_1.copy_(tensor_cpu_2[i])<br>    end = time.time()<br>    time_sum += end - start<br><br><br><span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">&quot;time for copy from cpu to cpu via _copy():&quot;</span>, time_sum)<br><br></code></pre></td></tr></table></figure>\n<p>如上代码展示了从cpu到cpu传输fp32的过程。最终展示了传输十万个1000*1000的矩阵所耗费的总时间。<br>经过实验，结果如下表所示：<br>记录数据如下：</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">传输方向</th>\n<th align=\"center\">传输方式</th>\n<th align=\"center\">数据类型</th>\n<th align=\"center\">时间</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">cpu -&gt; cpu</td>\n<td align=\"center\">copy_()</td>\n<td align=\"center\">fp32 -&gt; fp32</td>\n<td align=\"center\">2.187</td>\n</tr>\n<tr>\n<td align=\"center\">cpu -&gt; cpu</td>\n<td align=\"center\">to()</td>\n<td align=\"center\">fp32 -&gt; fp32</td>\n<td align=\"center\">0.025</td>\n</tr>\n<tr>\n<td align=\"center\">cpu -&gt; cpu</td>\n<td align=\"center\">copy_()</td>\n<td align=\"center\">fp32 -&gt; fp16</td>\n<td align=\"center\">5.855</td>\n</tr>\n<tr>\n<td align=\"center\">cpu -&gt; cpu</td>\n<td align=\"center\">to()</td>\n<td align=\"center\">fp32 -&gt; fp16</td>\n<td align=\"center\">5.634</td>\n</tr>\n<tr>\n<td align=\"center\">cpu -&gt; gpu</td>\n<td align=\"center\">copy_()</td>\n<td align=\"center\">fp32 -&gt; fp32</td>\n<td align=\"center\">9.663</td>\n</tr>\n<tr>\n<td align=\"center\">cpu -&gt; gpu</td>\n<td align=\"center\">to()</td>\n<td align=\"center\">fp32 -&gt; fp32</td>\n<td align=\"center\">9.555</td>\n</tr>\n<tr>\n<td align=\"center\">cpu -&gt; gpu</td>\n<td align=\"center\">copy_()</td>\n<td align=\"center\">fp32 -&gt; fp16</td>\n<td align=\"center\">9.876</td>\n</tr>\n<tr>\n<td align=\"center\">cpu -&gt; gpu</td>\n<td align=\"center\">to()</td>\n<td align=\"center\">fp32 -&gt; fp16</td>\n<td align=\"center\">10.264</td>\n</tr>\n<tr>\n<td align=\"center\">gpu -&gt; cpu</td>\n<td align=\"center\">copy_()</td>\n<td align=\"center\">fp32 -&gt; fp32</td>\n<td align=\"center\">8.895</td>\n</tr>\n<tr>\n<td align=\"center\">gpu -&gt; cpu</td>\n<td align=\"center\">to()</td>\n<td align=\"center\">fp32 -&gt; fp32</td>\n<td align=\"center\">13.649</td>\n</tr>\n<tr>\n<td align=\"center\">gpu -&gt; cpu</td>\n<td align=\"center\">copy_()</td>\n<td align=\"center\">fp32 -&gt; fp16</td>\n<td align=\"center\">10.051</td>\n</tr>\n<tr>\n<td align=\"center\">gpu -&gt; cpu</td>\n<td align=\"center\">to()</td>\n<td align=\"center\">fp32 -&gt; fp16</td>\n<td align=\"center\">7.320</td>\n</tr>\n<tr>\n<td align=\"center\">gpu -&gt; gpu</td>\n<td align=\"center\">copy_()</td>\n<td align=\"center\">fp32 -&gt; fp32</td>\n<td align=\"center\">0.605</td>\n</tr>\n<tr>\n<td align=\"center\">gpu -&gt; gpu</td>\n<td align=\"center\">to()</td>\n<td align=\"center\">fp32 -&gt; fp32</td>\n<td align=\"center\">0.029</td>\n</tr>\n<tr>\n<td align=\"center\">gpu -&gt; gpu</td>\n<td align=\"center\">copy_()</td>\n<td align=\"center\">fp32 -&gt; fp16</td>\n<td align=\"center\">0.484</td>\n</tr>\n<tr>\n<td align=\"center\">gpu -&gt; gpu</td>\n<td align=\"center\">to()</td>\n<td align=\"center\">fp32 -&gt; fp16</td>\n<td align=\"center\">0.591</td>\n</tr>\n</tbody></table>\n<ul>\n<li>注意，测试时间可能会有波动，尤其是在时间较短时，考虑到这种传输主要出现在gpu-&gt;gpu中，不是主要考虑内容</li>\n</ul>\n",
            "tags": [
                "技术",
                "课题组",
                "周报",
                "神经网络",
                "pytorch"
            ]
        },
        {
            "id": "http://example.com/2023/10/22/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E4%BA%94%E5%91%A8%E5%AD%A6%E4%B9%A0/",
            "url": "http://example.com/2023/10/22/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E4%BA%94%E5%91%A8%E5%AD%A6%E4%B9%A0/",
            "title": "课题组第五周学习",
            "date_published": "2023-10-22T15:36:49.000Z",
            "content_html": "<h1 id=\"高效直接访问主机内存的方法\"><a href=\"#高效直接访问主机内存的方法\" class=\"headerlink\" title=\"高效直接访问主机内存的方法\"></a>高效直接访问主机内存的方法</h1><h2 id=\"现有方法存在的问题\"><a href=\"#现有方法存在的问题\" class=\"headerlink\" title=\"现有方法存在的问题\"></a>现有方法存在的问题</h2><h3 id=\"通过加载后执行的方法\"><a href=\"#通过加载后执行的方法\" class=\"headerlink\" title=\"通过加载后执行的方法\"></a>通过加载后执行的方法</h3><p>面对巨大的模型参数规模，现有GPU的显存难以支撑大模型的训练。因此产生了一种通过加载后执行的方法，即将模型参数存储在主机内存中，每次训练时将参数加载到显存中，训练结束后将参数保存到主机内存中。这种方法的缺点是每次训练都需要将参数加载到显存中，这个过程会消耗大量的时间，例如在v100上，加载时间会是处理时间的4倍以上，导致训练效率低下。有一种异步加载方法，将加载层和训练层分开，训练层在训练时异步加载参数，但是这种方法会导致训练时的显存占用过高，而且层数较多时加载时间过高的劣势逐渐显现，优化并不明显。</p>\n<h2 id=\"本文提出的方法\"><a href=\"#本文提出的方法\" class=\"headerlink\" title=\"本文提出的方法\"></a>本文提出的方法</h2><h3 id=\"直接主机访问\"><a href=\"#直接主机访问\" class=\"headerlink\" title=\"直接主机访问\"></a>直接主机访问</h3><p>避开加载和训练不同步的问题，直接将cpu内存当作gpu的虚拟内存进行访问，这样避免了加载过程中占用gpu显存过高的问题，但是由于访问和数据流动要经过pcie总线，传输速度较慢。<br>因此，DHA使用了这样一种办法，使得其可以自适应选择访问方式，其可以通过直接主机访问和加载后执行两种方法进行训练，使得加载的时间可以隐藏在训练流的流水线中。</p>\n<h3 id=\"多GPU方法\"><a href=\"#多GPU方法\" class=\"headerlink\" title=\"多GPU方法\"></a>多GPU方法</h3><p>对于多个GPU，由于GPU间通信效率要高于PCIE通信效率，因此可以将模型拆分成多个部分，分别存储在不同的GPU中，这样每次训练的加载都可以直接从其他GPU中加载，而不需要从主机内存中加载，这样可以减少加载时间。</p>\n<h3 id=\"DeepPlan\"><a href=\"#DeepPlan\" class=\"headerlink\" title=\"DeepPlan\"></a>DeepPlan</h3><p>本文还提出了一个工具：用来为给定模型自动生成执行计划，过程如下：</p>\n<ul>\n<li>对本地GPU显存和主机内存分析性能</li>\n<li>通过比较DHA和流水线方法的延迟差异来决定每一层的策略</li>\n<li>如果有多个GPU，则根据GPU数量平均划分模型</li>\n<li>协调将直接主机访问的执行和加载后执行的执行进行协调<br>本方案在部署时只需要进行一次执行。<h2 id=\"原理分析\"><a href=\"#原理分析\" class=\"headerlink\" title=\"原理分析\"></a>原理分析</h2>对于不同层，加载——执行策略与DHA策略的时间是不同的，<table>\n<thead>\n<tr>\n<th align=\"center\">层</th>\n<th align=\"center\">加载——执行策略</th>\n<th align=\"center\">DHA策略</th>\n<th align=\"center\">结论</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">卷积层</td>\n<td align=\"center\">小规模差异不大</td>\n<td align=\"center\">大规模较慢</td>\n<td align=\"center\">推荐在较小卷积层使用DHA，同时加载较大卷积层等待直接执行</td>\n</tr>\n<tr>\n<td align=\"center\">全连接层</td>\n<td align=\"center\">加载快</td>\n<td align=\"center\">执行慢</td>\n<td align=\"center\">推荐在全连接层使用加载后执行，因为其需要频繁访问内存</td>\n</tr>\n<tr>\n<td align=\"center\">嵌入层</td>\n<td align=\"center\">加载较慢</td>\n<td align=\"center\">执行较快</td>\n<td align=\"center\">推荐在嵌入层使用DHA，因为其规模较大，而层中一些参数的访问较少</td>\n</tr>\n<tr>\n<td align=\"center\">归一化层</td>\n<td align=\"center\">LayerNorm更好</td>\n<td align=\"center\">BatchNorm更好</td>\n<td align=\"center\">需要根据具体情况进行选择</td>\n</tr>\n</tbody></table>\n</li>\n</ul>\n<p>产生差异的原因则是不同层对内存访问的需求不同，导致pcie访问次数不同，pcie作为瓶颈，访问次数越多，延迟越大。</p>\n<h3 id=\"并行传输\"><a href=\"#并行传输\" class=\"headerlink\" title=\"并行传输\"></a>并行传输</h3><p>对于多GPU场景，将模型划分为多个部分后，采用并行传输策略：从内存并行地将模型传输到两个GPU，再从第二个GPU向第一个GPU传输，这样可以减少传输时间。<br>在此基础上，可以将GPU2——GPU1的传输变为流水线传输，这样可以进一步减少传输时间。<br>但是，由于CPU提供的PCIE总线数量限制，多GPU系统，例如8GPU也只能每两个GPU公用一组总线，因此多GPU的总线需要考虑总线拓扑。</p>\n<h2 id=\"DeepPlan实现\"><a href=\"#DeepPlan实现\" class=\"headerlink\" title=\"DeepPlan实现\"></a>DeepPlan实现</h2><h3 id=\"整体实现思路\"><a href=\"#整体实现思路\" class=\"headerlink\" title=\"整体实现思路\"></a>整体实现思路</h3><p>再进行训练前，deepPlan会根据每一层的性能分析，推理出当前层采用何种方式进行训练（加载——执行orDHA）。遍历完整个网络后，将根据策略直接执行训练。如果在多GPU系统中，DeepPlan还会根据GPU连连接拓扑，将模型划分为多个部分，应用并行传输方案。</p>\n<h3 id=\"单层性能分析\"><a href=\"#单层性能分析\" class=\"headerlink\" title=\"单层性能分析\"></a>单层性能分析</h3><p>利用单层执行时间的统计数据，或者执行一次单层来得到每一层的性能数据。</p>\n<h3 id=\"层间性能分析\"><a href=\"#层间性能分析\" class=\"headerlink\" title=\"层间性能分析\"></a>层间性能分析</h3><p>对于每层性能已经得到的情况。检查每一层切换策略到DHA后其获得的性能差异是否比加载后执行的停滞时间更短，如果是的话则切换为DHA。并且通过递归的方式检查每个层之前最多可以使用几个DHA来缩短总加载停滞时间。</p>\n<h3 id=\"模型传输规划\"><a href=\"#模型传输规划\" class=\"headerlink\" title=\"模型传输规划\"></a>模型传输规划</h3><p>DeepPlan根据GPU拓扑，和PCIE交换机布局，避免并行加载的总线冲突，检查所选GPU是否使用NVLink，如果使用则直接进行并行传输，否则使用流水线传输。同时，根据并行传输带来的性能优化，重新规划每一层使用的策略。</p>\n",
            "tags": [
                "技术",
                "课题组",
                "周报",
                "神经网络",
                "pytorch"
            ]
        },
        {
            "id": "http://example.com/2023/10/13/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0/",
            "url": "http://example.com/2023/10/13/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0/",
            "title": "课题组第四周学习",
            "date_published": "2023-10-13T10:23:34.000Z",
            "content_html": "<h1 id=\"ZeRO-Offload方法\"><a href=\"#ZeRO-Offload方法\" class=\"headerlink\" title=\"ZeRO-Offload方法\"></a>ZeRO-Offload方法</h1><h2 id=\"提出背景\"><a href=\"#提出背景\" class=\"headerlink\" title=\"提出背景\"></a>提出背景</h2><p>对大模型训练来说，GPU显存对参数规模巨大的网络来说是一个瓶颈，然而CPU内存可以做到TB级别，因此可以考虑将一部分参数放在CPU上，而将需要频繁访问的参数放在GPU上，这样可以减少GPU显存的压力，提高训练速度。ZeRO-Offload提出了一种没有数据冗余的优化方法，可以将模型参数分布在CPU和GPU上，而且可以在CPU和GPU之间进行无缝的迁移。</p>\n<h3 id=\"大模型传统方法\"><a href=\"#大模型传统方法\" class=\"headerlink\" title=\"大模型传统方法\"></a>大模型传统方法</h3><p>针对大模型需要的内存过大的问题，传统分为两种方法：</p>\n<ul>\n<li>模型分割：将模型分割成多个部分，每个部分在GPU上训练，然后将结果传递给下一个部分，</li>\n<li>流水线并行：将训练过程分为不同层，每个层分给不同的GPU，然后将结果传递给下一个GPU<h2 id=\"增益来源\"><a href=\"#增益来源\" class=\"headerlink\" title=\"增益来源\"></a>增益来源</h2>根据计算流程，CPU的计算量相比于GPU的$O(MB)$,只有$O(M)$，其中M是模型大小，B是批次大小。<br>这个过程中，ZeRO-Offload将前向与后向传播分配给了GPU，而标准化计算和权重更新等对模型大小有直接联系的计算则分配给了CPU。<br>在数据吞吐方面，cpu与gpu之间仅存在fp16数据的传输，相比与其他方法（例如L2L）有大幅度减少<br>在并行方面，随着计算节点的增加，CPU的计算资源会随着节点数量增加而增加<br>CPU计算通过提高并行性增加了效率</li>\n</ul>\n<h3 id=\"对CPU作为计算瓶颈的解决方法\"><a href=\"#对CPU作为计算瓶颈的解决方法\" class=\"headerlink\" title=\"对CPU作为计算瓶颈的解决方法\"></a>对CPU作为计算瓶颈的解决方法</h3><h4 id=\"对CPU计算的优化\"><a href=\"#对CPU计算的优化\" class=\"headerlink\" title=\"对CPU计算的优化\"></a>对CPU计算的优化</h4><ul>\n<li>向量运算SIMD</li>\n<li>循环展开</li>\n<li>多核并行</li>\n<li>减少缓存抖动<h4 id=\"延迟参数更新\"><a href=\"#延迟参数更新\" class=\"headerlink\" title=\"延迟参数更新\"></a>延迟参数更新</h4>将参数更新延迟，重叠CPU与GPU计算。也就是说，在某一轮计算之后，此后每次gpu使用的优化器参数都是上一轮计算的结果，而不是这一轮计算的结果。，因此可以让cpu计算时间和gpu计算时间重叠。提高流水线负载率。<h2 id=\"优化方法\"><a href=\"#优化方法\" class=\"headerlink\" title=\"优化方法\"></a>优化方法</h2>ZeRO-Offload 同时利用CPU内存计算能力来优化。基于ZeRO优化方法，但是不是像原本多个GPU并行计算，并且通过联系收集器来进行并行。而是把这个通讯过程转化为与CPU的联系，相当于原本多个GPU同时做的工作，让单个GPU进行，每个阶段只进行原先一个GPU进行的工作，同时把其他GPU本应进行的计算状态经由内存进行存储。<h3 id=\"ZeRO的工作\"><a href=\"#ZeRO的工作\" class=\"headerlink\" title=\"ZeRO的工作\"></a>ZeRO的工作</h3>ZeRO，在ZeRO-Offload中使用ZeRO-2阶段，这个阶段你主要是分割模型状态和梯度。在ZeRO-2中，每个GPU都存储着所有参数，但是每轮训练只更新其中不包含的部分。<br>这个过程如下：</li>\n</ul>\n<ol>\n<li>每个GPU进行前馈，计算不同批次的损失。</li>\n<li>每个cpu进行反向传播，并且对每个有梯度的GPU使用减少梯度的算子进行平均。</li>\n<li>反向传播结束后，GPU使用其对应的梯度平均值对其部分参数和优化器状态进行更新。</li>\n<li>进行一次全收集，接收其他GPU计算的参数更新。</li>\n</ol>\n<h3 id=\"ZeRO-Offload的工作\"><a href=\"#ZeRO-Offload的工作\" class=\"headerlink\" title=\"ZeRO-Offload的工作\"></a>ZeRO-Offload的工作</h3><p>ZeRO-Offload将训练修改为数据流图，主要优势：使得CPU计算量减少了几个数量级。保证CPU与GPU通讯最小化。最大限度节省内存。</p>\n<h4 id=\"计算流图\"><a href=\"#计算流图\" class=\"headerlink\" title=\"计算流图\"></a>计算流图</h4><p>计算流图是一种图形化的表示，用于表示计算过程中的数据流动。在计算流图中，节点表示计算，边表示数据流动。<br><img src=\"https://raw.githubusercontent.com/lianga1/picGo_test/main/1.jpg\" alt=\"计算流图\"></p>\n<h4 id=\"减少CPU计算\"><a href=\"#减少CPU计算\" class=\"headerlink\" title=\"减少CPU计算\"></a>减少CPU计算</h4><p>ZeRO-Offload将前向与后向传播分配给了GPU，而标准化计算和权重更新等对模型大小有直接联系的计算则分配给了CPU。</p>\n<h4 id=\"减少CPU与GPU通讯\"><a href=\"#减少CPU与GPU通讯\" class=\"headerlink\" title=\"减少CPU与GPU通讯\"></a>减少CPU与GPU通讯</h4><p>创建fp32区：为了避免fp32数据在pcie总线传输，需要将所有fp32数据放在一个设备上进行处理<br>p16分配：将fp16必须放在前馈与反向传播共同节点的位置，因为这两个节点之间的通信是较大的。<br>因此，ZeRO-Offload将fp16分配给GPU，而将fp32分配给CPU。</p>\n<h4 id=\"减少内存\"><a href=\"#减少内存\" class=\"headerlink\" title=\"减少内存\"></a>减少内存</h4><p>将反向传播后得到的梯度，以及更新梯度所需要的计算和存储空间，写遭到CPU上，可以节省最多的显存使用。</p>\n<h2 id=\"优势\"><a href=\"#优势\" class=\"headerlink\" title=\"优势\"></a>优势</h2><h3 id=\"扩展性强\"><a href=\"#扩展性强\" class=\"headerlink\" title=\"扩展性强\"></a>扩展性强</h3><p>对于任何模型，其优化算法的优化参数对于ZeRO-Offload来说并不关键，其只是需要把fp32的计算内容单独放在CPU中。</p>\n<h3 id=\"支持并行\"><a href=\"#支持并行\" class=\"headerlink\" title=\"支持并行\"></a>支持并行</h3><p>对多个GPU而言。ZeRO-Offload基于ZeRO-2，因此可以将分区的参数分配给多个GPU。</p>\n<h3 id=\"模型并行\"><a href=\"#模型并行\" class=\"headerlink\" title=\"模型并行\"></a>模型并行</h3><p>ZeRO-Offload还可以用模型并行来实现更好的并行性。通过给cpu卸载梯度、优化器状态和优化器计算来和模型并行计算相适应。在这个情况下，首先，借由更难耗尽内存，可以使用更大的批次大小。其次，可以使用更多的GPU来进行模型并行计算。</p>\n",
            "tags": [
                "技术",
                "课题组",
                "周报",
                "神经网络",
                "pytorch"
            ]
        },
        {
            "id": "http://example.com/2023/09/30/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E4%B8%80%E5%91%A8%E5%AD%A6%E4%B9%A0/",
            "url": "http://example.com/2023/09/30/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E4%B8%80%E5%91%A8%E5%AD%A6%E4%B9%A0/",
            "title": "课题组第一周学习",
            "date_published": "2023-09-30T11:51:44.000Z",
            "content_html": "<h1 id=\"理论学习\"><a href=\"#理论学习\" class=\"headerlink\" title=\"理论学习\"></a>理论学习</h1><h2 id=\"反向传播算法\"><a href=\"#反向传播算法\" class=\"headerlink\" title=\"反向传播算法\"></a>反向传播算法</h2><p>反向传播是一种基于有监督学习，用于根据误差和损失函数调整网络权重的算法。反向传播算法的核心思想是通过链式法则计算损失函数对于每个权重的梯度，然后使用梯度下降法更新权重。<br>过程：</p>\n<ul>\n<li>首先通过正向传播，根据输入数据得到一个网络的激励</li>\n<li>根据得到的激励与目标值计算损失函数</li>\n<li>根据损失函数，从输出层开始，依次沿着计算图反向计算每个权重的梯度</li>\n<li>根据得到的梯度调整权重<br>[1]\t <a href=\"https://books.google.com/books/about/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.html?id=2-PWvQEACAAJ\">深度学习入门: 基于Python的理论与实现[M]. 人民邮电出版社, 2018.(p.121,161)</a><h2 id=\"前馈\"><a href=\"#前馈\" class=\"headerlink\" title=\"前馈\"></a>前馈</h2>前馈神经网络是一种最简单的神经网络，它的每个神经元都是前一层神经元的输出。前馈神经网络的每个神经元都是前一层神经元的输出，因此它的输出不会反馈到输入层，这种网络结构也被称为前馈神经网络。</li>\n</ul>\n<h2 id=\"卷积神经网络\"><a href=\"#卷积神经网络\" class=\"headerlink\" title=\"卷积神经网络\"></a>卷积神经网络</h2><h3 id=\"卷积\"><a href=\"#卷积\" class=\"headerlink\" title=\"卷积\"></a>卷积</h3><p>卷积（convolution）是一种数学运算，主要应用于信号处理中对系统响应的计算。卷积运算可以将某个冲激响应针对任意输入进行计算，得到对应的响应结果。卷积运算的公式如下：<br>$$<br>y(t) &#x3D; \\int_{-\\infty}^{\\infty} x(a)h(t-a)da<br>$$<br>其中，$x(t)$为输入信号，$h(t)$为系统响应，$y(t)$为输出信号。</p>\n<h3 id=\"二维离散卷积\"><a href=\"#二维离散卷积\" class=\"headerlink\" title=\"二维离散卷积\"></a>二维离散卷积</h3><p>对于图像处理来说，卷积需要用到二维矩阵的滑动窗口来进行卷积运算。二维离散卷积的公式如下：<br>$$<br>y(i,j) &#x3D; \\sum_{m&#x3D;-\\infty}^{\\infty}\\sum_{n&#x3D;-\\infty}^{\\infty}x(m,n)h(i-m,j-n)<br>$$<br>其中，$x(m,n)$为输入图像，$h(i,j)$为卷积核，$y(i,j)$为输出图像。</p>\n<h3 id=\"卷积神经网络-1\"><a href=\"#卷积神经网络-1\" class=\"headerlink\" title=\"卷积神经网络\"></a>卷积神经网络</h3><p>卷积神经网络（CNN）中，增加了卷积层和池化层。其可以从原本多维度的数据中提取欧氏距离较近的单元之间蕴含的信息。</p>\n<h4 id=\"卷积层\"><a href=\"#卷积层\" class=\"headerlink\" title=\"卷积层\"></a>卷积层</h4><p>在卷积层中，当输入数据是图像时，卷积层会以三维数据形式接收数据，并以三维数据形式传输到下一层，输入输出数据称为特征图（feature map）。其中，卷积层的输入数据称为输入特征图（input feature map），输出数据称为输出特征图（output feature map）。</p>\n<h4 id=\"CNN的处理流\"><a href=\"#CNN的处理流\" class=\"headerlink\" title=\"CNN的处理流\"></a>CNN的处理流</h4><p>针对一个图像，有三维的信息（长、宽、通道），同样，对这个图像进行处理的卷积核也是三维的。但是最终卷积得到的输出结果是二维的（每个通道卷积的结果加在一起）。在CNN中，针对多个卷积核，会得到多个二维的输出结果，这些输出结果会被叠加在一起，得到一个三维的输出结果。这个结果传递给下一层。同时，对多个数据，即批处理，卷积层将多个样本汇总成一次处理，传递中综合成四维的数据。</p>\n<h4 id=\"池化层\"><a href=\"#池化层\" class=\"headerlink\" title=\"池化层\"></a>池化层</h4><p>池化层是一种降低数据大小的方法，它可以减少数据的大小，同时也可以防止过拟合。池化层的处理流程如下：</p>\n<ul>\n<li>按照设定的步长，从输入数据中提取数据块</li>\n<li>例如MAX池化，将数据块中的最大值作为输出结果</li>\n<li>输出结果的规模即随步长变大而缩小<br>同时，池化层输入数据和输出数据的维度相同<h2 id=\"循环神经网络\"><a href=\"#循环神经网络\" class=\"headerlink\" title=\"循环神经网络\"></a>循环神经网络</h2>循环神经网络常用于nlp领域。它和前馈神经网络或CNN的主要区别在于循环神经网络（RNN）的隐藏层的输出不仅仅取决于当前的输入，还取决于前一时刻的隐藏层的输出。因此，RNN具有某种程度上的“记忆”能力。<br>另一个显著特征在于它们在每个网络层共享参数，RNN在每一层都共享相同的参数，这使得它们可以处理任意长度的序列。<br>然而，RNN在反向传播的过程中，梯度会随着时间的推移而消失或爆炸，这使得它们很难学习长期依赖关系。<h2 id=\"注意力机制\"><a href=\"#注意力机制\" class=\"headerlink\" title=\"注意力机制\"></a>注意力机制</h2>注意力机制可以增强神经网络输入数据中某些部分的权重，同时减弱其他部分的权重。<br>例如对一个翻译句子的网络，普通的逐个词翻译会在每一轮翻译过程中对单词序列依次提高注意力，也就是其注意力矩阵会是一个对角线上权值高的矩阵。但是在注意力机制下，每一轮翻译过程中，网络会根据上一轮的翻译结果，对输入句子中的某些部分进行更多的关注，即其权值的最大值不一定在对角线。从而提高翻译的连贯性。<h2 id=\"并行计算\"><a href=\"#并行计算\" class=\"headerlink\" title=\"并行计算\"></a>并行计算</h2>并行计算对计算任务进行拆分，将同时进行的计算任务分配到不同的计算单元上，从而提高计算速度。拆分的方式统称为并行方式，并行计算后的结果重新聚合的方式称为模型更新传递方式。<br>常见的并行方式有：</li>\n<li>数据并行：把数据集切分放到各个计算节点，并在哥哥节点之间传递模型参数</li>\n<li>模型并行：把模型切分放到各个计算节点，并在各个节点之间传递数据。一般把单个算子分配在配置相同的几个硬件上进行模型存储和计算。</li>\n<li>流水线并行：将模型切分成多个阶段，每个阶段在不同的计算节点上进行计算，每个阶段的计算结果传递给下一个阶段。<br>另外，如何更新模型参数也是并行计算的一个重要问题。在硬件组织架构方面，分为参数服务器架构和collective架构。在更新参数方面分为同步和异步更新<a href=\"https://zhuanlan.zhihu.com/p/350501860\">参考内容</a><h3 id=\"allreduce训练\"><a href=\"#allreduce训练\" class=\"headerlink\" title=\"allreduce训练\"></a>allreduce训练</h3>在同步更新参数的训练中，利用AllReduce来整合不同worker的梯度数据。AllReduce有很多种类的实现，主要关注的问题在于不同worker之间传递信息的拓扑结构。例如，对于一个有4个worker的集群，有以下几种拓扑结构：</li>\n<li><strong>ring</strong>：每个worker只和相邻的worker通信</li>\n<li><strong>mesh</strong>：每个worker和所有其他worker通信，但是效率比较低。</li>\n<li><strong>Master-Worker</strong>：一个worker作为master，其他worker作为worker，master和每个worker通信，worker之间不通信。<br>举N个worker的ring结构为例，考察这个结构的工作过程：</li>\n<li>每个worker计算自己的梯度</li>\n<li>每个worker把数据分成N份</li>\n<li>第k个worker把其第k份数据发送给第k+1个worker</li>\n<li>第k个worker把其第k-1份数据和第k-1个worker发送的数据整合，再发给下一个worker</li>\n<li>循环N次之后，每个worker包含最终整合结果的1份</li>\n<li>每个worker把自己的数据发送给下一个worker，收到数据后，每个worker的数据都是最终整合结果<br>这个结构的AllReduce的优势在于发送的数据量是固定的，和worker数量无关，避免了网络拥塞。<a href=\"https://zhuanlan.zhihu.com/p/100012827\">参考内容</a><h1 id=\"实践内容\"><a href=\"#实践内容\" class=\"headerlink\" title=\"实践内容\"></a>实践内容</h1><h2 id=\"lenet5\"><a href=\"#lenet5\" class=\"headerlink\" title=\"lenet5\"></a>lenet5</h2>lenet5是进行手写数字识别的CNN，它的结构如下：<br>输入层-&gt;卷积层-&gt;池化层-&gt;卷积层-&gt;池化层-&gt;全连接层-&gt;全连接层-&gt;输出层（高斯连接）<br>与CNN不同的地方在于，LeNet使用sigmoid函数而非reLU函数。<br>lenet5网络的实现代码如下：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">LeNet</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-built_in\">super</span>(LeNet, self).__init__()<br>        self.conv = nn.Sequential(<br>            nn.Conv2d(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">5</span>), <span class=\"hljs-comment\"># in_channels, out_channels, kernel_size</span><br>            nn.Sigmoid(),<br>            nn.MaxPool2d(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>), <span class=\"hljs-comment\"># kernel_size, stride</span><br>            nn.Conv2d(<span class=\"hljs-number\">6</span>, <span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">5</span>),<br>            nn.Sigmoid(),<br>            nn.MaxPool2d(<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">2</span>)<br>        )<br>        self.fc = nn.Sequential(<br>            nn.Linear(<span class=\"hljs-number\">16</span>*<span class=\"hljs-number\">4</span>*<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">120</span>),<br>            nn.Sigmoid(),<br>            nn.Linear(<span class=\"hljs-number\">120</span>, <span class=\"hljs-number\">84</span>),<br>            nn.Sigmoid(),<br>            nn.Linear(<span class=\"hljs-number\">84</span>, <span class=\"hljs-number\">10</span>)<br>        )<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, img</span>):</span><br>        feature = self.conv(img)<br>        output = self.fc(feature.view(img.shape[<span class=\"hljs-number\">0</span>], -<span class=\"hljs-number\">1</span>))<br>        <span class=\"hljs-keyword\">return</span> output<br><br></code></pre></td></tr></table></figure>\n这个网络定义了两个部分，一个是卷积层，一个是全连接层。卷积层的输入是一个1通道的图像，输出是一个6通道的图像，卷积核的大小为5*5。全连接层的输入是16*4*4的数据，输出是10个类别的概率。<h2 id=\"resnet\"><a href=\"#resnet\" class=\"headerlink\" title=\"resnet\"></a>resnet</h2>ResNet主要用于解决深度神经网络无法找到更好的解的问题。在深层网络中，梯度消失或爆炸的问题会导致网络无法训练。ResNet通过引入残差块（residual block）来解决这个问题。ResNet将堆叠的几个隐含层作为一个残差块，用残差块拟合的函数从原本的f(x)变为f(x)+x。<br>[4]\t<a href=\"https://arxiv.org/abs/1512.03385\">HE K, ZHANG X, REN S, et al. Deep residual learning for image recognition[C]. Proceedings of the IEEE conference on computer vision and pattern recognition, 2016:770-778.</a><br>通过每个block中残差路径和shortcut路径的设计，可以实现不同的ResNet网络。事实证明，不断增加ResNet的深度，也没有发生解的退化，反而可以提高网络的性能。因此ResNet可以实现如下的网络结构：<br><img src=\"https://raw.githubusercontent.com/lianga1/picGo_test/main/3u8Wwj.png\" alt=\"resnet\"><h3 id=\"实际部署\"><a href=\"#实际部署\" class=\"headerlink\" title=\"实际部署\"></a>实际部署</h3>残差块类定义如下：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Bottleneck</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-comment\"># 残差块定义</span><br>    extention = <span class=\"hljs-number\">4</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, inplanes, planes, stride, downsample=<span class=\"hljs-literal\">None</span></span>):</span><br>        <span class=\"hljs-built_in\">super</span>(Bottleneck, self).__init__()<br>        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=<span class=\"hljs-number\">1</span>, stride=stride, bias=<span class=\"hljs-literal\">False</span>)<br>        self.bn1 = nn.BatchNorm2d(planes)<br><br>        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class=\"hljs-number\">3</span>, stride=<span class=\"hljs-number\">1</span>, padding=<span class=\"hljs-number\">1</span>, bias=<span class=\"hljs-literal\">False</span>)<br>        self.bn2 = nn.BatchNorm2d(planes)<br><br>        self.conv3 = nn.Conv2d(planes, planes * self.extention, kernel_size=<span class=\"hljs-number\">1</span>, stride=<span class=\"hljs-number\">1</span>, bias=<span class=\"hljs-literal\">False</span>)<br>        self.bn3 = nn.BatchNorm2d(planes * self.extention)<br><br>        self.relu = nn.ReLU(inplace=<span class=\"hljs-literal\">True</span>)<br><br>        self.downsample = downsample<br>        self.stride = stride<br></code></pre></td></tr></table></figure>\nResNet网络定义如下：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ResNet50</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, block, layers, num_class</span>):</span><br>        self.inplane = <span class=\"hljs-number\">64</span><br>        <span class=\"hljs-built_in\">super</span>(ResNet50, self).__init__()<br><br>        self.block = block<br>        self.layers = layers<br><br>        self.conv1 = nn.Conv2d(<span class=\"hljs-number\">3</span>, self.inplane, kernel_size=<span class=\"hljs-number\">7</span>, stride=<span class=\"hljs-number\">2</span>, padding=<span class=\"hljs-number\">3</span>, bias=<span class=\"hljs-literal\">False</span>)<br>        self.bn1 = nn.BatchNorm2d(self.inplane)<br>        self.relu = nn.ReLU()<br>        self.maxpool = nn.MaxPool2d(kernel_size=<span class=\"hljs-number\">3</span>, stride=<span class=\"hljs-number\">2</span>, padding=<span class=\"hljs-number\">1</span>)<br><br>        self.stage1 = self.make_layer(self.block, <span class=\"hljs-number\">64</span>, layers[<span class=\"hljs-number\">0</span>], stride=<span class=\"hljs-number\">1</span>)<br>        self.stage2 = self.make_layer(self.block, <span class=\"hljs-number\">128</span>, layers[<span class=\"hljs-number\">1</span>], stride=<span class=\"hljs-number\">2</span>)<br>        self.stage3 = self.make_layer(self.block, <span class=\"hljs-number\">256</span>, layers[<span class=\"hljs-number\">2</span>], stride=<span class=\"hljs-number\">2</span>)<br>        self.stage4 = self.make_layer(self.block, <span class=\"hljs-number\">512</span>, layers[<span class=\"hljs-number\">3</span>], stride=<span class=\"hljs-number\">2</span>)<br><br>        self.avgpool = nn.AvgPool2d(<span class=\"hljs-number\">7</span>)<br>        self.fc = nn.Linear(<span class=\"hljs-number\">512</span> * block.extention, num_class)<br><br><br></code></pre></td></tr></table></figure>\n在30Epoch后，在测试集的准确度达到了75%。</li>\n</ul>\n<h2 id=\"BERT\"><a href=\"#BERT\" class=\"headerlink\" title=\"BERT\"></a>BERT</h2><p>BERT是基于Transformer的预训练模型，主要用于自然语言处理，它能够预测句子中缺失的词语。以及判断两个句子是不是上下句。<br>整个框架由多层transformer的encoder堆叠而成。encoder由注意力层和feed-forward层组成。<br>BERT中，输入由三种不同embedding组成：</p>\n<ul>\n<li><p>wordpiece embedding：由但词向量组成将单词划分成一组有限公共子词单元。</p>\n</li>\n<li><p>position embedaang：将单词的位置信息编码成特征向量。Transformer通过制定规则来构建一个position embedding</p>\n</li>\n<li><p>segment embedding：用于区分两个句子的向量表示。用于区别问答等非对称子句。</p>\n<h3 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h3><p>BERT的主要结构是Transformer，Transformer结构如下图所示：<br><img src=\"https://raw.githubusercontent.com/lianga1/picGo_test/main/20200814234510853.jpg\" alt=\"transformer\"><br>其中左侧部分即为encoder部分。<br>encoder单元由一个multi-head-Attention + Layer Normalization + feedforword + Layer Normalization 叠加产生。<br>在比较大的BERT模型中，有24层encoder，每层有16个Attention，词向量维度1024。在较小情况下，有12层encoder，每层12个Attention，词向量维度768。<br>任何时候feed-forward大小都是词向量维度的4倍。</p>\n<h4 id=\"Attention-Layer\"><a href=\"#Attention-Layer\" class=\"headerlink\" title=\"Attention Layer\"></a>Attention Layer</h4><p>这一层的输入是由X &#x3D; (batch_size,max_len_embedding)构成的。<br>单个self-attention 计算过程是输入X分别和三个矩阵Wq,Wk,Wv相乘，得到Q,K,V。然后计算Q和K的点积，再除以$\\sqrt{d_k}$，再经过softmax函数，得到attention矩阵。最后将attention矩阵和V相乘即加权求和，得到输出。<br>multi-head-Attention将多个不同的self-attention输出进行拼接，然后再乘以一个矩阵W0，得到最终的输出output_sum &#x3D; (batch_size,max_len,n*w_length)这个结果再经过一个全连接层就是整个multi-head-Attention的输出。</p>\n<h4 id=\"Layer-Normalization\"><a href=\"#Layer-Normalization\" class=\"headerlink\" title=\"Layer Normalization\"></a>Layer Normalization</h4><p>这个层相当于对每句话的embedding做归一化，所以用LN而非Batch Normalization</p>\n<h4 id=\"BERT每一层的学习\"><a href=\"#BERT每一层的学习\" class=\"headerlink\" title=\"BERT每一层的学习\"></a>BERT每一层的学习</h4><p>从浅层到深层分别可以学习到surface，短语，语法和语义的信息。</p>\n<h3 id=\"BERT的训练\"><a href=\"#BERT的训练\" class=\"headerlink\" title=\"BERT的训练\"></a>BERT的训练</h3><p>定义几个层的类如下：</p>\n</li>\n<li><p>Embedding：输入的embedding层，包括wordpiece embedding，position embedding，segment embedding</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Embeddings</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-built_in\">super</span>(Embeddings, self).__init__()<br>        self.seg_emb = nn.Embedding(n_segs, d_model)<br>        self.word_emb = nn.Embedding(max_vocab, d_model)<br>        self.pos_emb = nn.Embedding(max_len, d_model)<br>        self.norm = nn.LayerNorm(d_model)<br>        self.dropout = nn.Dropout(p_dropout)<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, x, seg</span>):</span><br>        <span class=\"hljs-string\">&#x27;&#x27;&#x27;</span><br><span class=\"hljs-string\">        x: [batch, seq_len]</span><br><span class=\"hljs-string\">        &#x27;&#x27;&#x27;</span><br>        word_enc = self.word_emb(x)<br><br>        <span class=\"hljs-comment\"># positional embedding</span><br>        pos = torch.arange(x.shape[<span class=\"hljs-number\">1</span>], dtype=torch.long, device=device)<br>        pos = pos.unsqueeze(<span class=\"hljs-number\">0</span>).expand_as(x)<br>        pos_enc = self.pos_emb(pos)<br><br>        seg_enc = self.seg_emb(seg)<br>        x = self.norm(word_enc + pos_enc + seg_enc)<br>        <span class=\"hljs-keyword\">return</span> self.dropout(x)<br>        <span class=\"hljs-comment\"># return: [batch, seq_len, d_model]</span><br></code></pre></td></tr></table></figure>\n</li>\n<li><p>Multi-Head-Attention层</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">ScaledDotProductAttention</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-built_in\">super</span>(ScaledDotProductAttention, self).__init__()<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, Q, K, V, attn_mask</span>):</span><br>        scores = torch.matmul(Q, K.transpose(-<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">2</span>) / msqrt(d_k))<br>        <span class=\"hljs-comment\"># scores: [batch, n_heads, seq_len, seq_len]</span><br>        scores.masked_fill_(attn_mask, -<span class=\"hljs-number\">1e9</span>)<br>        attn = nn.Softmax(dim=-<span class=\"hljs-number\">1</span>)(scores)<br>        <span class=\"hljs-comment\"># context: [batch, n_heads, seq_len, d_v]</span><br>        context = torch.matmul(attn, V)<br>        <span class=\"hljs-keyword\">return</span> context<br><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">MultiHeadAttention</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-built_in\">super</span>(MultiHeadAttention, self).__init__()<br>        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=<span class=\"hljs-literal\">False</span>)<br>        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=<span class=\"hljs-literal\">False</span>)<br>        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=<span class=\"hljs-literal\">False</span>)<br>        self.fc = nn.Linear(n_heads * d_v, d_model, bias=<span class=\"hljs-literal\">False</span>)<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, Q, K, V, attn_mask</span>):</span><br>        <span class=\"hljs-string\">&#x27;&#x27;&#x27;</span><br><span class=\"hljs-string\">        Q, K, V: [batch, seq_len, d_model]</span><br><span class=\"hljs-string\">        attn_mask: [batch, seq_len, seq_len]</span><br><span class=\"hljs-string\">        &#x27;&#x27;&#x27;</span><br>        batch = Q.size(<span class=\"hljs-number\">0</span>)<br>        <span class=\"hljs-string\">&#x27;&#x27;&#x27;</span><br><span class=\"hljs-string\">        split Q, K, V to per head formula: [batch, seq_len, n_heads, d_k]</span><br><span class=\"hljs-string\">        Convenient for matrix multiply opearation later</span><br><span class=\"hljs-string\">        q, k, v: [batch, n_heads, seq_len, d_k / d_v]</span><br><span class=\"hljs-string\">        &#x27;&#x27;&#x27;</span><br>        per_Q = self.W_Q(Q).view(batch, -<span class=\"hljs-number\">1</span>, n_heads, d_k).transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>)<br>        per_K = self.W_K(K).view(batch, -<span class=\"hljs-number\">1</span>, n_heads, d_k).transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>)<br>        per_V = self.W_V(V).view(batch, -<span class=\"hljs-number\">1</span>, n_heads, d_v).transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>)<br><br>        attn_mask = attn_mask.unsqueeze(<span class=\"hljs-number\">1</span>).repeat(<span class=\"hljs-number\">1</span>, n_heads, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># context: [batch, n_heads, seq_len, d_v]</span><br>        context = ScaledDotProductAttention()(per_Q, per_K, per_V, attn_mask)<br>        context = context.transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>).contiguous().view(<br>            batch, -<span class=\"hljs-number\">1</span>, n_heads * d_v)<br><br>        <span class=\"hljs-comment\"># output: [batch, seq_len, d_model]</span><br>        output = self.fc(context)<br>        <span class=\"hljs-keyword\">return</span> output<br></code></pre></td></tr></table></figure></li>\n<li><p>其余层，包括FeedForword层和池化层</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">FeedForwardNetwork</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-built_in\">super</span>(FeedForwardNetwork, self).__init__()<br>        self.fc1 = nn.Linear(d_model, d_ff)<br>        self.fc2 = nn.Linear(d_ff, d_model)<br>        self.dropout = nn.Dropout(p_dropout)<br>        self.gelu = gelu<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, x</span>):</span><br>        x = self.fc1(x)<br>        x = self.dropout(x)<br>        x = self.gelu(x)<br>        x = self.fc2(x)<br>        <span class=\"hljs-keyword\">return</span> x<br><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Pooler</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-built_in\">super</span>(Pooler, self).__init__()<br>        self.fc = nn.Linear(d_model, d_model)<br>        self.tanh = nn.Tanh()<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, x</span>):</span><br>        <span class=\"hljs-string\">&#x27;&#x27;&#x27;</span><br><span class=\"hljs-string\">        x: [batch, d_model] (first place output)</span><br><span class=\"hljs-string\">        &#x27;&#x27;&#x27;</span><br>        x = self.fc(x)<br>        x = self.tanh(x)<br>        <span class=\"hljs-keyword\">return</span> x<br><br></code></pre></td></tr></table></figure></li>\n<li><p>Encoder层和组合而成的BERT网络</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">EncoderLayer</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self</span>):</span><br>        <span class=\"hljs-built_in\">super</span>(EncoderLayer, self).__init__()<br>        self.norm1 = nn.LayerNorm(d_model)<br>        self.norm2 = nn.LayerNorm(d_model)<br><br>        self.enc_attn = MultiHeadAttention()<br>        self.ffn = FeedForwardNetwork()<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, x, pad_mask</span>):</span><br>        <span class=\"hljs-string\">&#x27;&#x27;&#x27;</span><br><span class=\"hljs-string\">        pre-norm</span><br><span class=\"hljs-string\">        see more detail in https://openreview.net/pdf?id=B1x8anVFPr</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        x: [batch, seq_len, d_model]</span><br><span class=\"hljs-string\">        &#x27;&#x27;&#x27;</span><br>        residual = x<br>        x = self.norm1(x)<br>        x = self.enc_attn(x, x, x, pad_mask) + residual<br>        residual = x<br>        x = self.norm2(x)<br>        x = self.ffn(x)<br>        <span class=\"hljs-keyword\">return</span> x + residual<br><br><br><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">BERT</span>(<span class=\"hljs-params\">nn.Module</span>):</span><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span>(<span class=\"hljs-params\">self, n_layers</span>):</span><br>        <span class=\"hljs-built_in\">super</span>(BERT, self).__init__()<br>        self.embedding = Embeddings()<br>        self.encoders = nn.ModuleList([<br>            EncoderLayer() <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n_layers)<br>        ])<br><br>        self.pooler = Pooler()<br><br>        self.next_cls = nn.Linear(d_model, <span class=\"hljs-number\">2</span>)<br>        self.gelu = gelu<br><br>        shared_weight = self.pooler.fc.weight<br>        self.fc = nn.Linear(d_model, d_model)<br>        self.fc.weight = shared_weight<br><br>        shared_weight = self.embedding.word_emb.weight<br>        self.word_classifier = nn.Linear(d_model, max_vocab, bias=<span class=\"hljs-literal\">False</span>)<br>        self.word_classifier.weight = shared_weight<br><br>    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span>(<span class=\"hljs-params\">self, tokens, segments, masked_pos</span>):</span><br>        output = self.embedding(tokens, segments)<br>        enc_self_pad_mask = get_pad_mask(tokens)<br>        <span class=\"hljs-keyword\">for</span> layer <span class=\"hljs-keyword\">in</span> self.encoders:<br>            output = layer(output, enc_self_pad_mask)<br>        <span class=\"hljs-comment\"># output: [batch, max_len, d_model]</span><br><br>        <span class=\"hljs-comment\"># NSP Task</span><br>        hidden_pool = self.pooler(output[:, <span class=\"hljs-number\">0</span>])<br>        logits_cls = self.next_cls(hidden_pool)<br><br>        <span class=\"hljs-comment\"># Masked Language Model Task</span><br>        <span class=\"hljs-comment\"># masked_pos: [batch, max_pred] -&gt; [batch, max_pred, d_model]</span><br>        masked_pos = masked_pos.unsqueeze(-<span class=\"hljs-number\">1</span>).expand(-<span class=\"hljs-number\">1</span>, -<span class=\"hljs-number\">1</span>, d_model)<br><br>        <span class=\"hljs-comment\"># h_masked: [batch, max_pred, d_model]</span><br>        h_masked = torch.gather(output, dim=<span class=\"hljs-number\">1</span>, index=masked_pos)<br>        h_masked = self.gelu(self.fc(h_masked))<br>        logits_lm = self.word_classifier(h_masked)<br>        <span class=\"hljs-comment\"># logits_lm: [batch, max_pred, max_vocab]</span><br>        <span class=\"hljs-comment\"># logits_cls: [batch, 2]</span><br><br>        <span class=\"hljs-keyword\">return</span> logits_cls, logits_lm<br><br></code></pre></td></tr></table></figure>\n<p>batch-size设为6<br>训练300个Epoch<br>训练结果进行预测例句<br>结果如下：</p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">========================================================<br>Masked data:<br>[<span class=\"hljs-string\">&#x27;[CLS]&#x27;</span>, <span class=\"hljs-string\">&#x27;[MASK]&#x27;</span>, <span class=\"hljs-string\">&#x27;[MASK]&#x27;</span>, <span class=\"hljs-string\">&#x27;you&#x27;</span>, <span class=\"hljs-string\">&#x27;too&#x27;</span>, <span class=\"hljs-string\">&#x27;how&#x27;</span>, <span class=\"hljs-string\">&#x27;are&#x27;</span>, <span class=\"hljs-string\">&#x27;you&#x27;</span>, <span class=\"hljs-string\">&#x27;today&#x27;</span>, <span class=\"hljs-string\">&#x27;[SEP]&#x27;</span>, <span class=\"hljs-string\">&#x27;great&#x27;</span>,<br> <span class=\"hljs-string\">&#x27;my&#x27;</span>, <span class=\"hljs-string\">&#x27;baseball&#x27;</span>, <span class=\"hljs-string\">&#x27;team&#x27;</span>, <span class=\"hljs-string\">&#x27;won&#x27;</span>, <span class=\"hljs-string\">&#x27;the&#x27;</span>, <span class=\"hljs-string\">&#x27;competition&#x27;</span>, <span class=\"hljs-string\">&#x27;[SEP]&#x27;</span>]<br>BERT reconstructed:<br>[<span class=\"hljs-string\">&#x27;[CLS]&#x27;</span>, <span class=\"hljs-string\">&#x27;nice&#x27;</span>, <span class=\"hljs-string\">&#x27;meet&#x27;</span>, <span class=\"hljs-string\">&#x27;you&#x27;</span>, <span class=\"hljs-string\">&#x27;too&#x27;</span>, <span class=\"hljs-string\">&#x27;how&#x27;</span>, <span class=\"hljs-string\">&#x27;are&#x27;</span>, <span class=\"hljs-string\">&#x27;you&#x27;</span>, <span class=\"hljs-string\">&#x27;today&#x27;</span>, <span class=\"hljs-string\">&#x27;[SEP]&#x27;</span>, <span class=\"hljs-string\">&#x27;great&#x27;</span>,<br> <span class=\"hljs-string\">&#x27;my&#x27;</span>, <span class=\"hljs-string\">&#x27;baseball&#x27;</span>, <span class=\"hljs-string\">&#x27;team&#x27;</span>, <span class=\"hljs-string\">&#x27;won&#x27;</span>, <span class=\"hljs-string\">&#x27;the&#x27;</span>, <span class=\"hljs-string\">&#x27;competition&#x27;</span>, <span class=\"hljs-string\">&#x27;[SEP]&#x27;</span>]<br>Original sentence:<br>[<span class=\"hljs-string\">&#x27;[CLS]&#x27;</span>, <span class=\"hljs-string\">&#x27;nice&#x27;</span>, <span class=\"hljs-string\">&#x27;meet&#x27;</span>, <span class=\"hljs-string\">&#x27;you&#x27;</span>, <span class=\"hljs-string\">&#x27;too&#x27;</span>, <span class=\"hljs-string\">&#x27;how&#x27;</span>, <span class=\"hljs-string\">&#x27;are&#x27;</span>, <span class=\"hljs-string\">&#x27;you&#x27;</span>, <span class=\"hljs-string\">&#x27;today&#x27;</span>, <span class=\"hljs-string\">&#x27;[SEP]&#x27;</span>, <span class=\"hljs-string\">&#x27;great&#x27;</span>,<br> <span class=\"hljs-string\">&#x27;my&#x27;</span>, <span class=\"hljs-string\">&#x27;baseball&#x27;</span>, <span class=\"hljs-string\">&#x27;team&#x27;</span>, <span class=\"hljs-string\">&#x27;won&#x27;</span>, <span class=\"hljs-string\">&#x27;the&#x27;</span>, <span class=\"hljs-string\">&#x27;competition&#x27;</span>, <span class=\"hljs-string\">&#x27;[SEP]&#x27;</span>]<br>===============Next Sentence <span class=\"hljs-attribute\">Prediction</span>===============<br>Two sentences are continuous? <span class=\"hljs-literal\">True</span><br>BERT predict: <span class=\"hljs-literal\">True</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n",
            "tags": [
                "技术",
                "课题组",
                "周报",
                "神经网络",
                "pytorch"
            ]
        },
        {
            "id": "http://example.com/2023/09/24/%E5%85%B3%E4%BA%8Eselenium%E5%8C%85%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E9%99%A4/",
            "url": "http://example.com/2023/09/24/%E5%85%B3%E4%BA%8Eselenium%E5%8C%85%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E9%99%A4/",
            "title": "关于selenium包安装运行的问题排除",
            "date_published": "2023-09-24T09:03:44.000Z",
            "content_html": "<h1 id=\"selenium-包安装\"><a href=\"#selenium-包安装\" class=\"headerlink\" title=\"selenium 包安装\"></a>selenium 包安装</h1><p>首先是想要在base环境下安装的，但是因为base环境的内容太多，solve解决依赖问题耗时过长，所以考虑新建环境。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs bash\">conda create -n webdriver python=3.7<br>conda activate webdriver<br>conda install selenium<br></code></pre></td></tr></table></figure>\n<h1 id=\"出现问题\"><a href=\"#出现问题\" class=\"headerlink\" title=\"出现问题\"></a>出现问题</h1><p>在按照例程运行代码时，出现了以下问题：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> selenium <span class=\"hljs-keyword\">import</span> webdriver<br><span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd<br><span class=\"hljs-keyword\">import</span> platform<br><span class=\"hljs-keyword\">import</span> matplotlib.pyplot <span class=\"hljs-keyword\">as</span> plt<br><span class=\"hljs-keyword\">import</span> os<br>chromedriver = os.path.abspath(<span class=\"hljs-string\">&#x27;C:\\\\Users\\\\18381\\\\anaconda3\\\\Scripts\\\\chromedriver.exe&#x27;</span>)<br>os.environ[<span class=\"hljs-string\">&quot;webdriver.chrome.driver&quot;</span>] = chromedriver<br>driver = webdriver.Chrome()<br></code></pre></td></tr></table></figure>\n\n<p>出现了以下错误：<br>Unable to obtain driver using Selenium Manager: C:\\Users\\18381\\anaconda3\\envs\\webdriver\\lib\\site-packages\\selenium\\webdriver\\common\\windows\\selenium-manager.exe is missing.</p>\n<p>因此，查阅github上有关issue，发现是conda打包问题，没有打包这个可执行文件。因此，需要手动下载这个文件，放到对应的目录下。<br><a href=\"https://github.com/SeleniumHQ/selenium/tree/trunk/common/manager\">下载文件</a></p>\n<h1 id=\"其他需要注意的地方\"><a href=\"#其他需要注意的地方\" class=\"headerlink\" title=\"其他需要注意的地方\"></a>其他需要注意的地方</h1><p>比如求解器，可以使用新的求解器例如<a href=\"https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community\">libmamba</a><br>虽然我还没完全搞懂这个东西如何使用</p>\n<p>需要先安装chrome和对应的chromedriver<br><a href=\"https://chromedriver.chromium.org/downloads\">chromedriver</a></p>\n",
            "tags": [
                "技术",
                "python"
            ]
        },
        {
            "id": "http://example.com/2023/07/27/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-27/",
            "url": "http://example.com/2023/07/27/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-27/",
            "title": "电赛培训-23-07-27",
            "date_published": "2023-07-27T02:04:23.000Z",
            "content_html": "<h2 id=\"赛程\"><a href=\"#赛程\" class=\"headerlink\" title=\"赛程\"></a>赛程</h2><p>9-11号作品测评<br>2号早晨7点半到413，放题</p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/19/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-19/",
            "url": "http://example.com/2023/07/19/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-19/",
            "title": "电赛培训-23-07-19",
            "date_published": "2023-07-19T02:19:52.000Z",
            "content_html": "<h1 id=\"pid控制系统\"><a href=\"#pid控制系统\" class=\"headerlink\" title=\"pid控制系统\"></a>pid控制系统</h1><h2 id=\"公式\"><a href=\"#公式\" class=\"headerlink\" title=\"公式\"></a>公式</h2><p>$$ u(t)&#x3D;K_p e(t)+K_i \\int_0^t e(\\tau) d\\tau + K_d \\frac{de(t)}{dt} $$</p>\n<h2 id=\"作用\"><a href=\"#作用\" class=\"headerlink\" title=\"作用\"></a>作用</h2><ul>\n<li>比例项：减小误差</li>\n<li>积分项：消除稳态误差</li>\n<li>微分项：减小超调量</li>\n</ul>\n<h3 id=\"超调量\"><a href=\"#超调量\" class=\"headerlink\" title=\"超调量\"></a>超调量</h3><p>$$ \\xi &#x3D; \\frac{e^{-\\frac{\\pi \\zeta}{\\sqrt{1-\\zeta^2}}}}{\\sqrt{1-\\zeta^2}} $$<br>超调量的意义在于：在没有积分项的情况下，超调量越大，系统的响应越快，但是超调量越大，系统的稳定性越差<br>其中 $\\zeta$ 是阻尼系数，$\\zeta$ 越大，超调量越小，系统越稳定</p>\n<h2 id=\"误差\"><a href=\"#误差\" class=\"headerlink\" title=\"误差\"></a>误差</h2><p>低频抖动：积分项过大<br>高频抖动：微分项过大</p>\n<h2 id=\"例子\"><a href=\"#例子\" class=\"headerlink\" title=\"例子\"></a>例子</h2><p>状态量：超声波，速度，MPU6050姿态，</p>\n<h1 id=\"卡尔曼滤波\"><a href=\"#卡尔曼滤波\" class=\"headerlink\" title=\"卡尔曼滤波\"></a>卡尔曼滤波</h1><h2 id=\"作用-1\"><a href=\"#作用-1\" class=\"headerlink\" title=\"作用\"></a>作用</h2><p>利用间接测量值，计算最优估算，组合各种可能受到噪音影响的数据源。</p>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><h3 id=\"状态观察\"><a href=\"#状态观察\" class=\"headerlink\" title=\"状态观察\"></a>状态观察</h3><p>状态观察是指，通过测量值，计算出状态量的过程，<br>状态观测器得到的估计状态表示为$ \\hat{x}  $</p>\n<h3 id=\"状态预测\"><a href=\"#状态预测\" class=\"headerlink\" title=\"状态预测\"></a>状态预测</h3><p>根据数学模型，从已有的状态量，通过计算得到了一个估计量$ \\hat{x} $<br>然而，数学模型的预测有其局限性，初值条件不同所以不能得到相同的结果。<br>所以需要状态估算器</p>\n<h3 id=\"状态估算\"><a href=\"#状态估算\" class=\"headerlink\" title=\"状态估算\"></a>状态估算</h3><p>需要估算值收敛到实际值，所以需要反馈，反馈误差为e<br>$$ e &#x3D; x - \\hat{x} $$假设一个微分方程：<br>$$ \\dot{x} &#x3D; Ax + Bu $$$$ y &#x3D; Cx $$以上是一个真实系统<br>$$ \\dot{\\hat{x}} &#x3D; A\\hat{x} + Bu + Ke$$$$ \\hat{y} &#x3D; C\\hat{x} $$这是系统估算模型</p>\n<p>两方程分别相减得到：<br>$$ \\dot{e} &#x3D;(A- KC)·e$$$$ y-\\hat{y} &#x3D; C·e$$<br>解得:<br>$$e(t) &#x3D; e^{A-KC} ·e(0)$$<br>若A-KC的值小于0，那么e(t)会收敛到0，即估算值收敛到实际值，实际上，k可以加速收敛过程。</p>\n<h3 id=\"例子-1\"><a href=\"#例子-1\" class=\"headerlink\" title=\"例子\"></a>例子</h3><p>$$ \\dot{x} &#x3D; Ax + Bu + w$$$$ y &#x3D; Cx + v$$<br>w是过程噪声，v是测量噪声，他们都服从高斯分布，且互相独立。<br>在初始条件下，状态估算器估计了$\\hat{x}$，真实值在这个中心的正态分布周围<br>在多轮预测后，估计值的分布会比初始条件下的估计分布更大，同时，还有一个测量方程得到的均值与方差都不同的分布，这两个分布的相乘就得到优化估计。<br>事实上，卡尔曼滤波器方程是一个随机系统的状态观测器<br>公式如下：<br>$$ \\hat{x}<em>k&#x3D;A·\\hat{x}</em>{k-1} +B·u_k +K_k(y_k - C(A·\\hat{x}+B·u_k)) $$<br>其中$\\hat{x_k^-}$是前项估测，代表前两项的和，所以公式写为：<br>$$ \\hat{x}_k^ &#x3D; A·\\hat{x_k^-} ++K_k(y_k - C\\hat{x_k^-}) $$</p>\n<p>所以结果成为后验估值。</p>\n<p>误差协方差矩阵P<br>$$ P_k^- &#x3D; AP_{k-1}A^T +Q$$<br>这个就是对矩阵P的估值</p>\n<p>第二步，更新状态<br>$$ K_k &#x3D; \\frac{P_k^-C^T}{(CP_k^-C^T+R)} $$<br>这个是卡尔曼增益，使得更新K后误差协方差最小<br>$$ P_k &#x3D; (I-K_kC)P_k^- $$</p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/18/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-18/",
            "url": "http://example.com/2023/07/18/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-18/",
            "title": "电赛培训-23-07-18",
            "date_published": "2023-07-18T02:44:15.000Z",
            "content_html": "<h1 id=\"arduino小车测速\"><a href=\"#arduino小车测速\" class=\"headerlink\" title=\"arduino小车测速\"></a>arduino小车测速</h1><h2 id=\"霍尔编码器\"><a href=\"#霍尔编码器\" class=\"headerlink\" title=\"霍尔编码器\"></a>霍尔编码器</h2><h2 id=\"外部中断\"><a href=\"#外部中断\" class=\"headerlink\" title=\"外部中断\"></a>外部中断</h2><p>一个霍尔编码器如果有两个传感器传出两路信号，就能根据相位差同时测量速度和方向<br>但是arduino只有两个硬件中断管脚，同时还要使能计时器中断，所以需要一个外部中断库<br>PinChangeInterrupt库</p>\n<h2 id=\"定时中断\"><a href=\"#定时中断\" class=\"headerlink\" title=\"定时中断\"></a>定时中断</h2><p>atmel内部有三个定时器</p>\n<ul>\n<li>Timer0是delay用的</li>\n<li>Timer1是pwm用的</li>\n<li>只有Timer2可以使用来进行定时中断<br>因此，需要使用MsTimer2库来实现定时中断</li>\n</ul>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/14/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-14/",
            "url": "http://example.com/2023/07/14/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-14/",
            "title": "电赛培训-23-07-14",
            "date_published": "2023-07-14T01:30:14.000Z",
            "content_html": "<h1 id=\"PWM\"><a href=\"#PWM\" class=\"headerlink\" title=\"PWM\"></a>PWM</h1><h2 id=\"通用定时器\"><a href=\"#通用定时器\" class=\"headerlink\" title=\"通用定时器\"></a>通用定时器</h2><h3 id=\"预分频\"><a href=\"#预分频\" class=\"headerlink\" title=\"预分频\"></a>预分频</h3><p>通过对时钟频率进行分频，实现了让计数器可以计数更长的时间。</p>\n<h2 id=\"占空比\"><a href=\"#占空比\" class=\"headerlink\" title=\"占空比\"></a>占空比</h2><p>占空比的实现是通过调节计数器到达翻转电平的值的大小来实现的。<br>利用的是计数器的比较功能<br>通过调节一个计数器不同的值，可以同时实现多个pwm的多个占空比的调节。但是他们的频率是相同的，若想要不同频率需要使用不同的计时器。<br>TIM3&#x2F;4通道数较多</p>\n<h2 id=\"捕获模式\"><a href=\"#捕获模式\" class=\"headerlink\" title=\"捕获模式\"></a>捕获模式</h2><p>捕获模式可以用来测量信号的频率，占空比等。</p>\n<h2 id=\"设置\"><a href=\"#设置\" class=\"headerlink\" title=\"设置\"></a>设置</h2><p>打开对应channel的pwm生成，设定预分频和counter值（推荐一个方便运算占空比的值）</p>\n<h2 id=\"作业\"><a href=\"#作业\" class=\"headerlink\" title=\"作业\"></a>作业</h2><ul>\n<li>需要实现通过按键增加占空比</li>\n<li>用捕获模式测量发生的PWM波频率和占空比</li>\n</ul>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/13/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-13/",
            "url": "http://example.com/2023/07/13/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-13/",
            "title": "电赛培训-23-07-13",
            "date_published": "2023-07-13T01:57:16.000Z",
            "content_html": "<h1 id=\"stm32串口通信\"><a href=\"#stm32串口通信\" class=\"headerlink\" title=\"stm32串口通信\"></a>stm32串口通信</h1><h1 id=\"定时器\"><a href=\"#定时器\" class=\"headerlink\" title=\"定时器\"></a>定时器</h1><h2 id=\"通用定时器\"><a href=\"#通用定时器\" class=\"headerlink\" title=\"通用定时器\"></a>通用定时器</h2><p>采用apb1&#x2F;apb2总线</p>\n<h3 id=\"预分频\"><a href=\"#预分频\" class=\"headerlink\" title=\"预分频\"></a>预分频</h3><p>计时时长&#x3D; (预分频+1) * (计数器值+1) &#x2F; 时钟频率</p>\n<h3 id=\"中断回调\"><a href=\"#中断回调\" class=\"headerlink\" title=\"中断回调\"></a>中断回调</h3><p>HAL_TIM_PeriodElapsedCallback(TIM_HandleTypeDef *htim)<br>这个函数可以复制到it文件中，定义这个函数即可在中断中调用这个函数。</p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/12/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-12/",
            "url": "http://example.com/2023/07/12/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-12/",
            "title": "电赛培训-23-07-12",
            "date_published": "2023-07-12T01:51:29.000Z",
            "content_html": "<h1 id=\"stm32定时器\"><a href=\"#stm32定时器\" class=\"headerlink\" title=\"stm32定时器\"></a>stm32定时器</h1><p>SysTick控制寄存器：<br>在SysTick_Config函数中，需要传进一个参数，代表着多少个tick触发一次中断。这个参数是一个32位的寄存器，但是只有24位有效，因此最大值是2^24-1，也就是16777215，也就是16Mhz的时钟下，最大延时是1s。如果需要更长的延时，需要自己写一个计数器，然后在中断中进行判断。<br>有一个变量是SystemCoreClock，代表当前时钟速度。把这个变量除以多少，就是把一秒分成多少份来计时。<br>在SysTick_Handler这个函数中，每次计时器触发中断都会调用这个函数，可以设置一个静态变量来进行计数，例如每1ms触发中断，就让这个函数每500次进入中断才执行某个行为，就能实现每500ms执行一次某个行为。</p>\n<h1 id=\"按键中断\"><a href=\"#按键中断\" class=\"headerlink\" title=\"按键中断\"></a>按键中断</h1>",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/11/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-11/",
            "url": "http://example.com/2023/07/11/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-11/",
            "title": "电赛培训-23-07-11",
            "date_published": "2023-07-11T01:49:47.000Z",
            "content_html": "<h1 id=\"stm32-开发\"><a href=\"#stm32-开发\" class=\"headerlink\" title=\"stm32 开发\"></a>stm32 开发</h1><h2 id=\"配置内容\"><a href=\"#配置内容\" class=\"headerlink\" title=\"配置内容\"></a>配置内容</h2><p>main.c中的user code 注释中间是不会被cube重新生成的</p>\n<h2 id=\"时钟树\"><a href=\"#时钟树\" class=\"headerlink\" title=\"时钟树\"></a>时钟树</h2><h2 id=\"第一个hal函数\"><a href=\"#第一个hal函数\" class=\"headerlink\" title=\"第一个hal函数\"></a>第一个hal函数</h2><p>HAL_GPIO_WritePin(GPIOF,LED0_PIN|LED1_PIN, GPIO_PIN_SET);<br>HAL_Delay(ms);</p>\n<h2 id=\"板载按钮\"><a href=\"#板载按钮\" class=\"headerlink\" title=\"板载按钮\"></a>板载按钮</h2><p>PE4作为ButtonPin，使能需要一个上拉电阻</p>\n<h2 id=\"中断\"><a href=\"#中断\" class=\"headerlink\" title=\"中断\"></a>中断</h2><p>可以在cube中更改引脚为外部中断，可以调节中断触发模式</p>\n<h1 id=\"stm32用于clion的诸多问题\"><a href=\"#stm32用于clion的诸多问题\" class=\"headerlink\" title=\"stm32用于clion的诸多问题\"></a>stm32用于clion的诸多问题</h1><ol>\n<li>Error: libusb_open() failed with LIBUSB_ERROR_NOT_SUPPORTED<br>初步估计是usb驱动问题，因此计划使用zadig重装驱动，libusb</li>\n<li>Error:Error: timed out while waiting for target halted<br>似乎是在等待重启的过程中超时，难道是没有设置重启？<br><strong>解决了，忘了换配置文件了，老配置文件没问题</strong></li>\n<li>问题又来了，Initfailed，连接不到target，先用的玄学方法：按住rst按键，再烧录，就用这种笨方法至少可以烧录了<br>作为重置方法，接下来有一个比较好的解决方案，就是再cubemx中，pinout设置栏，再systemcore的sys部分里，有一个debug模式选择，之前一直是disable，所以拒绝再外部烧写，现在改成serial wire，就可以了。</li>\n</ol>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/10/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-10/",
            "url": "http://example.com/2023/07/10/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-10/",
            "title": "电赛培训-23-07-10",
            "date_published": "2023-07-10T01:40:59.000Z",
            "content_html": "<h1 id=\"spi与i2c\"><a href=\"#spi与i2c\" class=\"headerlink\" title=\"spi与i2c\"></a>spi与i2c</h1><h2 id=\"iic通信\"><a href=\"#iic通信\" class=\"headerlink\" title=\"iic通信\"></a>iic通信</h2><p>i2c是一种用于设备间通讯的两线协议<br>硬件和软件实现都通过machine.I2C和machine.SoftI2C来实现。<br>硬件I2c优势在于速度快，但是对使用的引脚有限制。<br>软件I2C优势在于兼容性强，但是速度慢<br>函数：</p>\n<ul>\n<li>硬件I2C：使用以下参数来构造I2C对象<ul>\n<li>id表示特定的外设，取决于特定板子</li>\n<li>scl：时钟线引脚，Pin</li>\n<li>sda：数据线引脚，Pin</li>\n<li>freq：时钟频率，整数</li>\n</ul>\n</li>\n</ul>\n<p><strong>注意接线先关注缺少的端口例如I2C或uart，之后再关注gpio</strong></p>\n<ul>\n<li>软件I2C：使用以下参数来构造I2C对象<ul>\n<li>scl：时钟线引脚，Pin</li>\n<li>sda：数据线引脚，Pin</li>\n<li>freq：时钟频率，整数</li>\n<li>timeout：超时时间，整数</li>\n</ul>\n</li>\n<li>init函数可以重新定义</li>\n<li>I2C.start()：开始通信</li>\n<li>I2C.stop()：结束通信</li>\n<li>I2C.readint(buf,nack&#x3D;True):读取字节存储到buf中，字节长度是buf长度，收到出最后一个字节以外所有子接后，将发送ack，如果设置nack则发送nack，ack代表着以后还会传输，nack代表着这是最后一个字节</li>\n<li>I2C.write(buf)：将buf中的字节写入到总线上，检查每个字节是否收到ack</li>\n<li>I2C.readfrom(addr,nbytes,stop&#x3D;True):从addr地址读取nbytes个字节，如果stop为True则在输入结束时发送stop信号。</li>\n<li>I2c.readfrom_into(adr,)</li>\n<li>I2c.writeto(addr,buf,stop&#x3D;True)</li>\n<li>I2c.writevto(addr,vector,stop&#x3D;True)将vector中包含的字节写入addr指定的从站，vector应该具有缓冲协议的元组或对象列表</li>\n<li>I2c.readfrom_mem(addr,memaddr,nbytes,addrsize&#x3D;8)从memaddr指定的内存地址开始，从addr指定的从站读出nbytes。参数addrsize以位为单位指定地址大小，返回读取数据bytes对象。</li>\n<li><h3 id=\"硬件I3c外设\"><a href=\"#硬件I3c外设\" class=\"headerlink\" title=\"硬件I3c外设\"></a>硬件I3c外设</h3>任何可用的输出引脚都可以用于scl和sda，默认情况下，I2C对象使用id 0，scl引脚为22，sda引脚为21，时钟频率为400kHz。</li>\n</ul>\n<h2 id=\"spi通信\"><a href=\"#spi通信\" class=\"headerlink\" title=\"spi通信\"></a>spi通信</h2><p>spi是一种由主机驱动的同步串行协议。在物理层概念，一条总线有三条线路组成：SCK，MOSI、MISO，多个设备可以共享一条总线。每个设备有一个单独的第四个信号SS（从设备选择），来选择总线上的特定设备并与之通信。</p>\n<figure class=\"highlight gml\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs gml\">machine.SPI(<span class=\"hljs-symbol\">id</span>)# 在给定的总线<span class=\"hljs-symbol\">id</span>上构造一个SPI对象。<span class=\"hljs-symbol\">id</span>的值取决于特定端口以及硬件<br></code></pre></td></tr></table></figure>\n<h1 id=\"stm32\"><a href=\"#stm32\" class=\"headerlink\" title=\"stm32\"></a>stm32</h1><h2 id=\"引脚\"><a href=\"#引脚\" class=\"headerlink\" title=\"引脚\"></a>引脚</h2><p>在cubemx中，浅黄色是不能修改定义的，深黄色也是默认的。</p>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><p>引脚配置，在pinout_configuration中，如下图所示：<br><img src=\"/2023/07/10/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-10/GPIO_conf.png\" alt=\"引脚配置\"><br>可以配置其中每个引脚的功能，例如GPIO、SPI、I2C等等。</p>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/07/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-07/",
            "url": "http://example.com/2023/07/07/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-07/",
            "title": "电赛培训-23-07-07",
            "date_published": "2023-07-07T01:34:49.000Z",
            "content_html": "<h1 id=\"串口通信\"><a href=\"#串口通信\" class=\"headerlink\" title=\"串口通信\"></a>串口通信</h1><h2 id=\"串行vs并行\"><a href=\"#串行vs并行\" class=\"headerlink\" title=\"串行vs并行\"></a>串行vs并行</h2><p>并行优点：快，效率高<br>缺点：需要端口多<br>串行优点：只需要一个端口<br>缺点：慢，效率低，且需要明确数据拍成一串的规则<br>（大端法vs小端法）</p>\n<h2 id=\"通信\"><a href=\"#通信\" class=\"headerlink\" title=\"通信\"></a>通信</h2><p>串行通信每次只发送一个字节，对于字节内部发送bit的顺序，每个通讯协议都是相同的，但是字节的顺序却不一定相同，这就是大端法和小端法的区别。</p>\n<h3 id=\"I2C通信\"><a href=\"#I2C通信\" class=\"headerlink\" title=\"I2C通信\"></a>I2C通信</h3><p>一个通信口可以和多个设备进行传输，只需要SDA和SCL两个数据线即可，SDA为数据线，SCL为时钟线，时钟线由主设备控制，主设备为发送方，从设备为接收方，从设备的地址由主设备指定，主设备发送数据时，从设备会返回一个ACK信号，表示接收成功，如果没有返回ACK信号，主设备会认为发送失败，重新发送。<br>但是，I2C驱动能力较弱，需要在数据线加上拉电阻，且所有设备必须有不同地址。</p>\n<h3 id=\"SPI通信\"><a href=\"#SPI通信\" class=\"headerlink\" title=\"SPI通信\"></a>SPI通信</h3><p>不需要考虑地址为问题，可以一个Master带多个slave。<br>缺点：每多一个从机，就需要有一个IO口作为片选信号，且需要一个时钟信号，所以需要的IO口较多。</p>\n<h3 id=\"UART通信\"><a href=\"#UART通信\" class=\"headerlink\" title=\"UART通信\"></a>UART通信</h3><p>接线非常简单，且双方对等，谁都可以随时发送信息。<br>缺点：容易接错，且难实现多个设备同时通信。而且功耗较大，所以很多传感器上不配备。<br>波特率：每个位对应时间长度的倒数<br>uart通信有起始位，数据位，校验位，停止位，所以每个字节需要10个bit，所以波特率为115200时，每秒可以传输11520个字节。</p>\n<h4 id=\"电平标准\"><a href=\"#电平标准\" class=\"headerlink\" title=\"电平标准\"></a>电平标准</h4><p>usb标准：看D+和D-的电平差，差大是1，小是0<br>TTL电平：0v是低电平，5&#x2F;3.3v是高电平<br>RS232电平：-3v<del>-15v是低电平，3v</del>15v是高电平</p>\n<h4 id=\"Arduino的uart\"><a href=\"#Arduino的uart\" class=\"headerlink\" title=\"Arduino的uart\"></a>Arduino的uart</h4><p>ttl电平5v<br>1为tx<br>0为rx<br>内部已通过ch340g串口转usb，与usb相连，arduino用uart串口发送信息时，会通过ch340g转换为usb信号，所以可以通过usb接收信息。<br>函数：</p>\n<figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs reasonml\"><span class=\"hljs-module-access\"><span class=\"hljs-module\"><span class=\"hljs-identifier\">Serial</span>.</span></span><span class=\"hljs-keyword\">begin</span>(baudrate)：设置波特率<br><span class=\"hljs-module-access\"><span class=\"hljs-module\"><span class=\"hljs-identifier\">Serianl</span>.</span></span>print(content,选项)：发送信息,可以是数字，字符串，数组，对象，选项可以是DEC，BIN，OCT，HEX，BYTE，WORD，FLOAT，STRING，可以指定发送的进制，或者发送字符串。<br><span class=\"hljs-module-access\"><span class=\"hljs-module\"><span class=\"hljs-identifier\">Serial</span>.</span></span>println(content,选项)：发送信息，与print不同的是，会在最后加上换行符。<br><span class=\"hljs-module-access\"><span class=\"hljs-module\"><span class=\"hljs-identifier\">Serial</span>.</span></span>available<span class=\"hljs-literal\">()</span>：返回接收缓冲区中的字节数<br><span class=\"hljs-module-access\"><span class=\"hljs-module\"><span class=\"hljs-identifier\">Serial</span>.</span></span>read<span class=\"hljs-constructor\">Bytes(<span class=\"hljs-params\">char</span>类型数组名，最大读取长度)</span><br><span class=\"hljs-module-access\"><span class=\"hljs-module\"><span class=\"hljs-identifier\">Serial</span>.</span></span>write(<span class=\"hljs-built_in\">char</span>类型数组名，写入长度)：总共能发送数据长度个字节。按照数组中每个原始值诸葛发送，可以借助这个功能，对<span class=\"hljs-keyword\">struct</span>结构体中相关数据作为一个整体，将结构体指针强制转型为byte*类型，后面数据长度用sizeof(<span class=\"hljs-keyword\">struct</span>),这样就可以将结构体作为一个整体发送。<br></code></pre></td></tr></table></figure>\n<h4 id=\"Arduino的uart工具\"><a href=\"#Arduino的uart工具\" class=\"headerlink\" title=\"Arduino的uart工具\"></a>Arduino的uart工具</h4><ul>\n<li>串口绘图仪：可以发送数据时利用数据名：数据的格式，将以时间为横轴，数值为纵轴，根据格式中构成的变量数量，以不同颜色的线段，随时间变化的情况进行绘图。</li>\n<li>BYSerial<br>串口不能同时被多个程序打开。<h2 id=\"网络\"><a href=\"#网络\" class=\"headerlink\" title=\"网络\"></a>网络</h2>基本概念：</li>\n<li>TCP&#x2F;IP协议：定义了设备如何连接如互联网</li>\n<li>TCP：信息必须齐全的网络通信的基础</li>\n<li>UDP：信息可以缺少或者需要广播的网络通信的基础</li>\n<li>IP：计算机之间用于识别身份的临时位置编号</li>\n<li>ICMP：网络控制信号协议</li>\n<li>DHCP：动态分配ip地址协议</li>\n<li>一个能连接互联网的网课出厂自带的编号。<h3 id=\"ipv4\"><a href=\"#ipv4\" class=\"headerlink\" title=\"ipv4\"></a>ipv4</h3>ipv4定义了32位二进制地址<br>同时，ipv4定义了一些只会用于内部网络的地址编号，称为私网ip段，剩下的都是用于全球公网ip。<br>例如</li>\n</ul>\n<p>10.0.0.0-10.255.255.255<br>172.16.0.0-172.31.255.255<br>192.168.0.0-192.168.255.255</p>\n<h3 id=\"ipv6\"><a href=\"#ipv6\" class=\"headerlink\" title=\"ipv6\"></a>ipv6</h3><p>ipv6定义了128位二进制地址</p>\n<h3 id=\"子网掩码\"><a href=\"#子网掩码\" class=\"headerlink\" title=\"子网掩码\"></a>子网掩码</h3><p>子网掩码用于判断ip地址的前几位是网络号，后几位是主机号。<br>32个二进制位表示ip地址截止到哪里，只要相同就认为在同一个子网内，可以直接通信无需交给网关做转发。要求必须1卡头，连续多个1，剩下的是0。255.255.255.0对于这个设备，前面三个点分十进制数相同，那就认为是在同一个网络下，因此会直接连接而不会寻求网关。</p>\n<h3 id=\"tcp协议\"><a href=\"#tcp协议\" class=\"headerlink\" title=\"tcp协议\"></a>tcp协议</h3><p>传输控制协议，是面向连接的，可靠的，基于字节流的传输层通信协议，一个tcp连接需要有：</p>\n<ol>\n<li>在一个网络色悲伤，特定的网络端口如8080（最好大于1023）上开创一个tcp server，这个过程叫做绑定端口，并开始监听端口。</li>\n<li>得到该网络设备的ip地址，因此需要体现获得server的ipv4地址，以及开启tcp监听端口。<h3 id=\"udp协议\"><a href=\"#udp协议\" class=\"headerlink\" title=\"udp协议\"></a>udp协议</h3>无连接的传输协议，成为用户数据报协议<br>udp提供了一个无需链接就能发送封装的ip数据包的方法，建立一套tcp连接需要有：</li>\n<li>在一个网络设备上，特定的网络端口如8080（最好大于1023）上开创一个udp socket</li>\n<li>设定好目的地IP地址和端口便可以随心所欲发送数据</li>\n<li>目的地ip地址对应网络设备B，如果尝试在自己9090端口上开创一个udp socket，且A正好在发送信息，那么此时就能受到A发送的信息。</li>\n</ol>\n<h2 id=\"wifi连接\"><a href=\"#wifi连接\" class=\"headerlink\" title=\"wifi连接\"></a>wifi连接</h2><h3 id=\"station终端\"><a href=\"#station终端\" class=\"headerlink\" title=\"station终端\"></a>station终端</h3><p>新建station</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">import</span> network<br>wlan - network.WLAN(network.STA.<span class=\"hljs-keyword\">IF</span>)# <span class=\"hljs-keyword\">create</span> station<br>wlan.active(<span class=\"hljs-keyword\">True</span>)<br>wlan.scan() #scan <span class=\"hljs-keyword\">for</span> acess points(AP)<br>wlan.isconnected() #<span class=\"hljs-keyword\">check</span> <span class=\"hljs-keyword\">if</span> the station <span class=\"hljs-keyword\">is</span> connected <span class=\"hljs-keyword\">to</span> an AP<br><br>wlan.<span class=\"hljs-keyword\">connect</span>(<span class=\"hljs-string\">&#x27;ssid&#x27;</span>, <span class=\"hljs-string\">&#x27;key&#x27;</span>) #<span class=\"hljs-keyword\">connect</span> <span class=\"hljs-keyword\">to</span> an AP<br>wlan.config(<span class=\"hljs-string\">&#x27;mac&#x27;</span>) #<span class=\"hljs-keyword\">get</span> the interfac<span class=\"hljs-string\">e&#x27;s MAC address</span><br><span class=\"hljs-string\">wlan.ifconfig() #get the interface&#x27;</span>s IP/netmask/gw/DNS addresses<br></code></pre></td></tr></table></figure>\n<p>新建AP</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">import</span> network<br>ap = network.WLAN(network.AP_IF) # <span class=\"hljs-keyword\">create</span> acess <span class=\"hljs-type\">point</span> interface<br>ap.config(ssid=<span class=\"hljs-string\">&#x27;ESP-AP&#x27;</span>) #<span class=\"hljs-keyword\">set</span> the SSID <span class=\"hljs-keyword\">of</span> the <span class=\"hljs-keyword\">access</span> <span class=\"hljs-type\">point</span><br>ap.config(max_clients=<span class=\"hljs-number\">10</span>) #<span class=\"hljs-keyword\">set</span> how many clients can <span class=\"hljs-keyword\">connect</span> <span class=\"hljs-keyword\">to</span> the <span class=\"hljs-keyword\">access</span> <span class=\"hljs-type\">point</span><br>ap.active(<span class=\"hljs-keyword\">True</span>)<br></code></pre></td></tr></table></figure>\n<p>tcp通讯：</p>\n<ol>\n<li>连接wifi</li>\n<li>获取本地ip</li>\n<li>创建tcp</li>\n<li>绑定本地ip和端口</li>\n<li>设定最大连接数</li>\n<li>配置tcp选项</li>\n<li>用户进入获取用户组</li>\n<li>读取用户信息，</li>\n<li>发送接收到的数据给发送者</li>\n</ol>\n<p>udp通讯：server</p>\n<ol>\n<li>创建socket对象要设置udp模式</li>\n</ol>\n<p>udp通信：client</p>\n<ol>\n<li>判断wifi连接</li>\n<li>发送使用sendto函数</li>\n</ol>\n",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/06/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-06/",
            "url": "http://example.com/2023/07/06/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-06/",
            "title": "电赛培训-23-07-06",
            "date_published": "2023-07-06T01:48:40.000Z",
            "content_html": "<h1 id=\"ESP32\"><a href=\"#ESP32\" class=\"headerlink\" title=\"ESP32\"></a>ESP32</h1><h2 id=\"中断\"><a href=\"#中断\" class=\"headerlink\" title=\"中断\"></a>中断</h2><p>中断处理程序不要运行时间过长，不要分配内存</p>\n<h3 id=\"紧急异常缓冲区\"><a href=\"#紧急异常缓冲区\" class=\"headerlink\" title=\"紧急异常缓冲区\"></a>紧急异常缓冲区</h3><p>如果ISR中发生错误，MicroPython无法生成错误报告<br>除非创建特殊缓冲区</p>\n<figure class=\"highlight elm\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs elm\"><span class=\"hljs-keyword\">import</span> micropython<br><span class=\"hljs-title\">micropython</span>.alloc_emergency_exception_buf(<span class=\"hljs-number\">100</span>)<br></code></pre></td></tr></table></figure>\n<h2 id=\"UART\"><a href=\"#UART\" class=\"headerlink\" title=\"UART\"></a>UART</h2><p>esp32有三个硬件UART，分别是UART0，UART1，UART2<br>各自分配了默认GPIO<br>TX：当前设备的发送<br>RX：当前设备的接收<br>串口中不分主从</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">from</span> machine import UART<br><span class=\"hljs-attribute\">uart1</span> = (<span class=\"hljs-number\">1</span>,baudrate=<span class=\"hljs-number\">9600</span>,tx=<span class=\"hljs-number\">33</span>,rx=<span class=\"hljs-number\">32</span>)#指定了id<br><br></code></pre></td></tr></table></figure>\n<p>任何GPIO都可以用于使用GPIO矩阵的硬件UART，除了可以用作rx的仅输入引脚34-39<br>发送与接受的波特率一样</p>\n<p>一种调试方法：不能使用调试器时，可以利用串口输出进行调试。</p>\n<h2 id=\"ADC\"><a href=\"#ADC\" class=\"headerlink\" title=\"ADC\"></a>ADC</h2><figure class=\"highlight reasonml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs reasonml\">from machine import ADC<br>adc = <span class=\"hljs-constructor\">ADC(<span class=\"hljs-params\">pin</span>)</span><br><span class=\"hljs-keyword\">val</span> = adc.read<span class=\"hljs-constructor\">_u16()</span><br><span class=\"hljs-keyword\">val</span> = adc.read<span class=\"hljs-constructor\">_uv()</span># <span class=\"hljs-keyword\">to</span> microvolts<br></code></pre></td></tr></table></figure>\n<p><strong>ADC2也被wifi使用，所以开启wifi时会发生adc2异常</strong></p>\n<h2 id=\"定时器\"><a href=\"#定时器\" class=\"headerlink\" title=\"定时器\"></a>定时器</h2><p>Timer.init(*,mode&#x3D;Timer.PERIODIC,period&#x3D;-1,callback&#x3D;None)</p>\n<ul>\n<li>mode 可以是ONE_SHOT或PERIODIC（单次或周期计时）</li>\n</ul>\n<h2 id=\"PWM\"><a href=\"#PWM\" class=\"headerlink\" title=\"PWM\"></a>PWM</h2>",
            "tags": []
        },
        {
            "id": "http://example.com/2023/07/05/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-05/",
            "url": "http://example.com/2023/07/05/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-05/",
            "title": "电赛培训-23-07-05",
            "date_published": "2023-07-05T01:46:48.000Z",
            "content_html": "<h1 id=\"Arduino\"><a href=\"#Arduino\" class=\"headerlink\" title=\"Arduino\"></a>Arduino</h1><p>软件：使用Arduino IDE，以C++风格语言编写相关库。<br>利用IDE编译固件下载到Arduino的前提条件是有bootloader程序。<br>所以从程序到固件的关键在于bootloader，其他单片机也可以装载bootloader固件，然后使用arduino库。</p>\n<h2 id=\"硬件-uno板\"><a href=\"#硬件-uno板\" class=\"headerlink\" title=\"硬件 uno板\"></a>硬件 uno板</h2><p>工作电压5v,可以typeB，DC5.5，或者跳线接入<br>共有14个数字输入输出（6个PWM口），6个模拟输入输出</p>\n<h2 id=\"系统指示灯\"><a href=\"#系统指示灯\" class=\"headerlink\" title=\"系统指示灯\"></a>系统指示灯</h2><ul>\n<li>ON：系统指示灯</li>\n<li>RX：接收指示灯</li>\n<li>TX：发送指示灯</li>\n<li>L：内置LED，对应13号数字口<h2 id=\"开始编写代码\"><a href=\"#开始编写代码\" class=\"headerlink\" title=\"开始编写代码\"></a>开始编写代码</h2>有两个一定会有的函数，void setup()和void loop()，分别是初始化和循环函数。<br>setup会执行一次，loop在setup后会自动循环<h3 id=\"setup函数\"><a href=\"#setup函数\" class=\"headerlink\" title=\"setup函数\"></a>setup函数</h3>setup中用pinMode配置管脚模式为输出<br>pinMode(pin编号，INPUT)：高阻态，可认为是100m欧姆，电平不定。<br>pinMode(pinnum,INPUT_PULLUP):内置上拉输入，无外部信号默认高电平。<br>pinMode(pinnum,OUTPUT):输出模式，uno上高电平5v，电流&lt;40mA</li>\n</ul>\n<h3 id=\"loop函数\"><a href=\"#loop函数\" class=\"headerlink\" title=\"loop函数\"></a>loop函数</h3><ul>\n<li>digitalWrite(pinnum,HIGH&#x2F;LOW):输出高低电平，只对output模式有效</li>\n<li>digitalRead(pinnum):读取高低电平,返回HIGH&#x2F;LOW两种电平</li>\n<li>analogRead(anaPinNum)：读取模拟输入电平，返回0-1023的数字，对应0-5v的电压</li>\n<li>analogWrite(pwmPinNum,0-255)：输出PWM波，对应0-5v的电压，频率为490Hz(3,9,10,11pin),或980Hz(5,6pin)</li>\n<li>analogReference(AD参考电压输入来源)：切换AD参考电压输入来源，有默认值，一般不用，可以让输出更加精细。</li>\n</ul>\n<h3 id=\"中断和轮询\"><a href=\"#中断和轮询\" class=\"headerlink\" title=\"中断和轮询\"></a>中断和轮询</h3><p>轮询：不断重复读取某个状态值，缺点是占用资源<br>中断：可以通过某个状态改变来发送信号，然后发送信号后可以执行其他操作，之后再恢复到发送信号之前的状态。<br>管脚中断：attachInterrupt(digitalPinToInterrupt(pinnum),ISR,mode),第一个参数是中断管脚号（uno为2，3），第二个参数是中断服务函数（可以自定义），第三个参数是中断模式，有LOW，RISING，FALLING，CHANGE四种模式。</p>\n<ul>\n<li>LOW：低电平触发</li>\n<li>RISING：上升沿触发</li>\n<li>FALLING：下降沿触发</li>\n<li>CHANGE：任意电平变化触发</li>\n</ul>\n<p><strong>注意，终端服务函数应当很短，而且不能使用其他中断实现的函数，延时需要delayMicroseconds(us)</strong><br><strong>修改全局变量应当用volatile修饰，防止编译器优化</strong></p>\n<h1 id=\"ESP32\"><a href=\"#ESP32\" class=\"headerlink\" title=\"ESP32\"></a>ESP32</h1><h2 id=\"硬件\"><a href=\"#硬件\" class=\"headerlink\" title=\"硬件\"></a>硬件</h2><p>esp32-WROOM-32<br>串口芯片：CP2102<br>核心频率240mHz<br>WiFi IEEE 802.11 b&#x2F;g&#x2F;n 2.4GHz<br>BLuetooth 4.2 BR&#x2F;EDR and BLE<br>520k SRAM 448kB ROM<br>2个I2S，RMT远程控制，LED PWM，1个host SD&#x2F;eMMC&#x2F;SDIO，一个slave SDIO&#x2F;SPI. TWAI(CAN),12bitADC,Ethernet</p>\n<h2 id=\"开发环境\"><a href=\"#开发环境\" class=\"headerlink\" title=\"开发环境\"></a>开发环境</h2><p>MicroPython+Thonny</p>\n<h3 id=\"常用库\"><a href=\"#常用库\" class=\"headerlink\" title=\"常用库\"></a>常用库</h3><h3 id=\"GPIO\"><a href=\"#GPIO\" class=\"headerlink\" title=\"GPIO\"></a>GPIO</h3><figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs pgsql\"><span class=\"hljs-keyword\">from</span> machine <span class=\"hljs-keyword\">import</span> Pin<br><br>p0 = Pin(<span class=\"hljs-number\">0</span>,Pin.<span class=\"hljs-keyword\">OUT</span>) # <span class=\"hljs-keyword\">create</span> output pin <span class=\"hljs-keyword\">on</span> GPIO0<br>p0.<span class=\"hljs-keyword\">on</span>() # <span class=\"hljs-keyword\">set</span> pin <span class=\"hljs-keyword\">to</span> &quot;on&quot; (high) <span class=\"hljs-keyword\">level</span><br>p0.<span class=\"hljs-keyword\">off</span>() # <span class=\"hljs-keyword\">set</span> pin <span class=\"hljs-keyword\">to</span> &quot;off&quot; (low) <span class=\"hljs-keyword\">level</span><br>p0.<span class=\"hljs-keyword\">value</span>(<span class=\"hljs-number\">1</span>) # <span class=\"hljs-keyword\">set</span> pin <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">on</span>/high<br>p0.init(p0.<span class=\"hljs-keyword\">IN</span>,p0.PULL_DOWN) # <span class=\"hljs-keyword\">set</span> pin <span class=\"hljs-keyword\">to</span> <span class=\"hljs-keyword\">input</span> <span class=\"hljs-keyword\">with</span> a pull-down resistor<br></code></pre></td></tr></table></figure>\n<p>init函数中，id是强制的</p>\n<ul>\n<li><p>mode指定引脚模式，有IN，OUT，OPEN_DRAIN，AF_OPEN_DRAIN四种模式</p>\n</li>\n<li><p>pull指定引脚是否连接弱上拉电阻，有None，PULL_UP，PULL_DOWN三种模式<br>弱上拉指上拉电阻阻值较大，高电平很容易因为外部电流驱动而拉低。</p>\n</li>\n<li><p>drive具有不同的最大安全电流的限制，有DRIVE_0-3四种选择</p>\n</li>\n<li><p>alt为引脚的备用功能，仅对alt和alt_open_drain两种模式有效，有0-7八种选择</p>\n</li>\n</ul>\n<p>value函数中，如果不带参数，就是得到当前状态，如果在输出模式，需要带参数，变为设置电平</p>\n<p>配置在引脚的触发源处于活动状态时要调用中断处理程序，如果引脚模式为Pin.IN，可以使用irq函数，如果引脚模式为Pin.IN，可以使用Pin.IRQ_RISING，Pin.IRQ_FALLING，Pin.IRQ_ANY三种模式，分别对应上升沿，下降沿，任意电平变化触发中断。</p>\n",
            "tags": [
                "技术",
                "博客",
                "电赛"
            ]
        },
        {
            "id": "http://example.com/2023/05/29/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3WSL-Ubuntu%E6%89%BE%E4%B8%8D%E5%88%B0sys-time-h%E7%9A%84%E9%97%AE%E9%A2%98/",
            "url": "http://example.com/2023/05/29/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3WSL-Ubuntu%E6%89%BE%E4%B8%8D%E5%88%B0sys-time-h%E7%9A%84%E9%97%AE%E9%A2%98/",
            "title": "关于解决WSL_Ubuntu找不到sys/time.h的问题",
            "date_published": "2023-05-29T07:24:24.000Z",
            "content_html": "<h1 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h1><p>在使用WSL_Ubuntu的时候，编译C代码时，出现了找不到sys&#x2F;time.h的问题</p>\n<h1 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h1><h2 id=\"第一次失败\"><a href=\"#第一次失败\" class=\"headerlink\" title=\"第一次失败\"></a>第一次失败</h2><p>网上的一个直接解决方案是安装libc6-dev-amd64<br>但是问题又一次出现，当输入指令<br><code>sudo apt-get install libc6-dev-amd64</code><br>发生报错 unable to locate package</p>\n<h2 id=\"第二次失败\"><a href=\"#第二次失败\" class=\"headerlink\" title=\"第二次失败\"></a>第二次失败</h2><p>于是转而解决无法定位包的问题，根据查找发现需要在&#x2F;etc&#x2F;apt&#x2F;sources.list中添加源,添加了清华源、阿里源后输入<br><code>sudo apt-get update</code><br>更新完成后再次尝试安装libc6-dev-amd64，但是问题依旧存在</p>\n<h2 id=\"第三次解决\"><a href=\"#第三次解决\" class=\"headerlink\" title=\"第三次解决\"></a>第三次解决</h2><p>这次发现libc6-dev-amd64是一个需要在i386架构下安装的包，于是尝试添加i386架构，运行指令<br><code>dpkg --add-architecture i386</code><br>添加成功后再次输入<br><code>sudo apt-get update</code><br>更新完成后再次尝试安装libc6-dev-amd64，问题解决</p>\n",
            "tags": [
                "技术",
                "博客",
                "Linux",
                "WSL",
                "编译"
            ]
        },
        {
            "id": "http://example.com/2023/05/14/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/",
            "url": "http://example.com/2023/05/14/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/",
            "title": "电赛学习笔记-机器视觉",
            "date_published": "2023-05-14T09:04:31.000Z",
            "content_html": "<h1 id=\"开发环境\"><a href=\"#开发环境\" class=\"headerlink\" title=\"开发环境\"></a>开发环境</h1><h2 id=\"安装opencv\"><a href=\"#安装opencv\" class=\"headerlink\" title=\"安装opencv\"></a>安装opencv</h2><h2 id=\"开发板：STM32F407\"><a href=\"#开发板：STM32F407\" class=\"headerlink\" title=\"开发板：STM32F407\"></a>开发板：STM32F407</h2><h2 id=\"IDE：STM32CubeIDE\"><a href=\"#IDE：STM32CubeIDE\" class=\"headerlink\" title=\"IDE：STM32CubeIDE\"></a>IDE：STM32CubeIDE</h2><h2 id=\"配置过程\"><a href=\"#配置过程\" class=\"headerlink\" title=\"配置过程\"></a>配置过程</h2><p>配置工程ioc文件，配置好基础外设后，再packs中安装X-CUBE-AI组件包，在软件包外设中添加模型文件，设置压缩倍数，导入测试集验证准确率</p>\n<h2 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h2><h3 id=\"yolo\"><a href=\"#yolo\" class=\"headerlink\" title=\"yolo\"></a>yolo</h3><p>利用mobilenet yolo50k模型可以导入到单片机中，只需要较少内存即可实现实时运行，实现人脸识别的功能</p>\n<h3 id=\"openmv\"><a href=\"#openmv\" class=\"headerlink\" title=\"openmv\"></a>openmv</h3><h2 id=\"硬件\"><a href=\"#硬件\" class=\"headerlink\" title=\"硬件\"></a>硬件</h2><p>正点原子ov7725摄像头<br>yolo50k</p>\n<h1 id=\"相关资料\"><a href=\"#相关资料\" class=\"headerlink\" title=\"相关资料\"></a>相关资料</h1><p><a href=\"https://www.bilibili.com/video/BV1Bt411w77m/?share_source=copy_web&vd_source=4ed5c2c0429d7681216f506ac1e74065\">稚晖君</a><br><a href=\"https://github.com/dog-qiuqiu/MobileNet-Yolo\">yolo50k仓库</a><br><a href=\"https://www.bilibili.com/video/BV1FL411u72p/?share_source=copy_web&vd_source=4ed5c2c0429d7681216f506ac1e74065\">实时运行案例</a></p>\n",
            "tags": [
                "技术",
                "博客",
                "电赛"
            ]
        },
        {
            "id": "http://example.com/2023/05/14/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-micropython/",
            "url": "http://example.com/2023/05/14/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-micropython/",
            "title": "电赛学习笔记-micropython",
            "date_published": "2023-05-14T08:47:54.000Z",
            "content_html": "<h1 id=\"micropython简介\"><a href=\"#micropython简介\" class=\"headerlink\" title=\"micropython简介\"></a>micropython简介</h1><p>micropython是一个能够利用python进行单片机开发的固件，目前主要是在esp32平台上进行的开发</p>\n<h1 id=\"micropython安装\"><a href=\"#micropython安装\" class=\"headerlink\" title=\"micropython安装\"></a>micropython安装</h1><ul>\n<li>在micropython官网找到对应的单片机的型号的固件文件（.bin），下载到对应位置</li>\n<li>pip install esptool</li>\n<li>连接esp32单片机，查看端口号</li>\n<li>根据micropython官网的指示，利用esptool.py文件，清除单片机flash，再部署固件到单片机。</li>\n<li>安装uPyCraft IDE，选择好开发板类型和端口号后，<h1 id=\"micropython使用\"><a href=\"#micropython使用\" class=\"headerlink\" title=\"micropython使用\"></a>micropython使用</h1>需要根据单片机自带的库函数，进行python文档的开发<h1 id=\"micropython的优点\"><a href=\"#micropython的优点\" class=\"headerlink\" title=\"micropython的优点\"></a>micropython的优点</h1>代码量少，配置简单</li>\n</ul>\n",
            "tags": [
                "技术",
                "博客",
                "电赛"
            ]
        },
        {
            "id": "http://example.com/2023/05/11/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/",
            "url": "http://example.com/2023/05/11/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/",
            "title": "电赛学习笔记（1）——stm32学习笔记",
            "date_published": "2023-05-11T08:19:20.000Z",
            "content_html": "<h1 id=\"stm32基础\"><a href=\"#stm32基础\" class=\"headerlink\" title=\"stm32基础\"></a>stm32基础</h1><h2 id=\"关于stm32产品线\"><a href=\"#关于stm32产品线\" class=\"headerlink\" title=\"关于stm32产品线\"></a>关于stm32产品线</h2><h3 id=\"stm32f1系列-cortex-m3\"><a href=\"#stm32f1系列-cortex-m3\" class=\"headerlink\" title=\"stm32f1系列 cortex-m3\"></a>stm32f1系列 cortex-m3</h3><h3 id=\"stm32f4系列-cortex-m4\"><a href=\"#stm32f4系列-cortex-m4\" class=\"headerlink\" title=\"stm32f4系列 cortex-m4\"></a>stm32f4系列 cortex-m4</h3><ul>\n<li>内置了rgb lcd驱动</li>\n<li>加入了DSP与FPU模块<h3 id=\"stm32f7系列-cortex-m7\"><a href=\"#stm32f7系列-cortex-m7\" class=\"headerlink\" title=\"stm32f7系列 cortex-m7\"></a>stm32f7系列 cortex-m7</h3></li>\n<li>高速内存得到应用 <h2 id=\"寄存器编程\"><a href=\"#寄存器编程\" class=\"headerlink\" title=\"寄存器编程\"></a>寄存器编程</h2></li>\n</ul>\n<p><strong>关键字volatile</strong>需要在声明寄存器变量的时候添加，因为要防止编译器自行优化。</p>\n<h2 id=\"HAL库\"><a href=\"#HAL库\" class=\"headerlink\" title=\"HAL库\"></a>HAL库</h2><p>硬件抽象层，可以将不同产品线的芯片的寄存器操作抽象为函数，方便移植<br><strong><font color=\"red\">本笔记使用HAL库进行编程</font></strong><br>相对的，HAL库会产生大量的判断来降低代码运行效率<br>但是，还有另一个Low Layer库（LL），这个库可以提高效率</p>\n<h2 id=\"stm32cubeMX配置\"><a href=\"#stm32cubeMX配置\" class=\"headerlink\" title=\"stm32cubeMX配置\"></a>stm32cubeMX配置</h2><h2 id=\"stm32计时器\"><a href=\"#stm32计时器\" class=\"headerlink\" title=\"stm32计时器\"></a>stm32计时器</h2><h3 id=\"PWM调制输出\"><a href=\"#PWM调制输出\" class=\"headerlink\" title=\"PWM调制输出\"></a>PWM调制输出</h3><h4 id=\"几个重要参数\"><a href=\"#几个重要参数\" class=\"headerlink\" title=\"几个重要参数\"></a>几个重要参数</h4><ul>\n<li>占空比：高电平占整个周期的比例</li>\n<li>频率：整个PWM周期的倒数</li>\n<li>分辨率：占空比变化步长 <h4 id=\"PWM实现方法\"><a href=\"#PWM实现方法\" class=\"headerlink\" title=\"PWM实现方法\"></a>PWM实现方法</h4>输出比较模式，依靠内部计数器cnt和ccr设置的数值的比较来进行输出电平的控制，常用的有匹配时电平翻转和PWM模式<br>PWM占空比：$$DutyCycle&#x3D;\\frac{CCR}{ARR}$$<br>PWM频率：$$Freq&#x3D;\\frac{F_{clk}}{ARR}$$<br>PWM分辨率：$$Resolution&#x3D;\\frac{ARR}{2^{n}}$$<h4 id=\"高级定时器\"><a href=\"#高级定时器\" class=\"headerlink\" title=\"高级定时器\"></a>高级定时器</h4>死区生成：可以避免推挽电路上下管同时打开导致短路<h3 id=\"PWM控制电机\"><a href=\"#PWM控制电机\" class=\"headerlink\" title=\"PWM控制电机\"></a>PWM控制电机</h3>舵机是根据pwm信号控制舵机转动角度的，内部有直流电机<h4 id=\"电机驱动芯片\"><a href=\"#电机驱动芯片\" class=\"headerlink\" title=\"电机驱动芯片\"></a>电机驱动芯片</h4>利用H桥，可以控制电机转动方向。四个开关管可以构成两个推挽电路，使得电机可以获得两个方向的电流。<br>电机需要的电源一般是大功率的，不能直接通过gpio驱动，因此可以通过让stlink的5v口接入电机驱动芯片来获得电源。但是注意，pwm信号的地应当和电机电源的地相连，否则会出现电平不稳定的情况。<h3 id=\"PWM代码\"><a href=\"#PWM代码\" class=\"headerlink\" title=\"PWM代码\"></a>PWM代码</h3>pwm的激活结构如下：<br><img src=\"/2023/05/11/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/PWM_Structure.jpg\" alt=\"PWM_Structure\"></li>\n<li>RCC开启时钟</li>\n<li>配置时基单元</li>\n<li>配置输出比较单元</li>\n<li>配置GPIO，设置为复用推挽输出</li>\n<li>运行控制，启动计数器<h4 id=\"TIM库函数\"><a href=\"#TIM库函数\" class=\"headerlink\" title=\"TIM库函数\"></a>TIM库函数</h4>在hal库中，tim相关库函数在stm32f1xx_hal_tim.h文件中<br>其中有关输出比较的内容有：</li>\n<li>TIM_OC_InitTypeDef: 输出比较初始化结构体</li>\n<li>HAL_StatusTypeDef HAL_TIM_OC_Init(TIM_HandleTypeDef *htim)：输出比较初始化函数</li>\n<li>HAL_StatusTypeDef HAL_TIM_OC_ConfigChannel(TIM_HandleTypeDef *htim, TIM_OC_InitTypeDef *sConfig, uint32_t Channel)：配置输出通道函数</li>\n</ul>\n",
            "tags": [
                "技术",
                "博客",
                "电赛"
            ]
        },
        {
            "id": "http://example.com/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/",
            "url": "http://example.com/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/",
            "title": "记录：装修博客",
            "date_published": "2022-04-21T09:32:11.000Z",
            "content_html": "<p><font color=\"Red\" size=\"6\"><strong>本文长期更新，后面更新的部分也会插在不同部分</strong></font></p>\n<h1 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h1><ul>\n<li><a href=\".#%E5%8A%9F%E8%83%BD%E8%AE%BE%E7%BD%AE\">功能设置</a><ul>\n<li><a href=\".#%E4%B8%BB%E9%A2%98%E9%80%89%E5%8F%96\">主题选取</a><ul>\n<li><a href=\".#%E5%BD%92%E6%A1%A3%E4%B8%8E%E6%A0%87%E7%AD%BE\">归档与标签</a></li>\n<li><a href=\".#%E4%B8%8B%E4%B8%80%E6%AD%A5%EF%BC%8C%E5%8F%8B%E9%93%BE%E4%B8%8E%E4%BD%9C%E8%80%85%E9%93%BE%E6%8E%A5\">友链与作者链接</a></li>\n<li><a href=\".#%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E7%9A%84%E9%AA%9A%E6%93%8D%E4%BD%9C\">一些其他的骚操作</a></li>\n</ul>\n</li>\n<li><a href=\".#%E6%87%92%E5%8A%A0%E8%BD%BD\">懒加载</a></li>\n</ul>\n</li>\n<li><a href=\".#%E7%BE%8E%E8%A7%82%E8%AE%BE%E7%BD%AE\">美观设置</a><ul>\n<li><a href=\".#%E8%83%8C%E6%99%AF%E5%9B%BE\">背景图</a><ul>\n<li><a href=\".#%E4%B8%BB%E9%A1%B5%E8%83%8C%E6%99%AF%E5%9B%BE\">主页背景图</a></li>\n<li><a href=\".#%E6%96%87%E7%AB%A0%E8%83%8C%E6%99%AF%E5%9B%BE\">文章背景图</a></li>\n</ul>\n</li>\n<li><a href=\".#%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2%E5%9B%BE\">文章封面图</a></li>\n<li><a href=\".#%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E5%8A%A8%E7%94%BB\">图片加载动画</a></li>\n</ul>\n</li>\n<li><a href=\".#%E6%89%A9%E5%B1%95%E8%AE%BE%E7%BD%AE\">扩展设置</a></li>\n</ul>\n<h1 id=\"功能设置\"><a href=\"#功能设置\" class=\"headerlink\" title=\"功能设置\"></a>功能设置</h1><h2 id=\"主题选取\"><a href=\"#主题选取\" class=\"headerlink\" title=\"主题选取\"></a>主题选取</h2><p>一个博客的功能上限，很大程度上是取决于这个主题给你提供的功能，因此一个好的主题很重要<br>主题的选取，可以看我的另一篇文章<a href=\"https://lianga1.github.io/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/\">Hexo主题模板切换</a><br>但是大部分时候我们用的功能不会很多，而基础的功能，例如归档，友链，个人介绍等功能，绝大部分的主题都具备。所以仅需要挑选好看的主题即可，关于主题的美观问题，我们放在<a href=\".#%E7%BE%8E%E8%A7%82%E8%AE%BE%E7%BD%AE\">美观设置</a>模块说。<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/theme1.jpg\" alt=\"theme\"></p>\n<h2 id=\"导航栏\"><a href=\"#导航栏\" class=\"headerlink\" title=\"导航栏\"></a>导航栏</h2><p>导航栏是一个博客的门面。设置好导航栏，你的博客会非常的有条理。</p>\n<h3 id=\"归档与标签\"><a href=\"#归档与标签\" class=\"headerlink\" title=\"归档与标签\"></a>归档与标签</h3><p>如果读者想找一篇文章,总不能让读者去挨篇文章翻吧，所以，在写文章的时候，做好标签设置和归档工作，是写一篇文章的必要工作。那么，如何归档呢？<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/categories.jpg\" alt=\"categories\"><br>在md语法中，我们可以在文章顶部的标签部分，加入如下几行</p>\n<figure class=\"highlight subunit\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs subunit\"><span class=\"hljs-keyword\">tags:</span><br>- 标签1<br>- 标签2<br>……<br>- 标签n<br>categories: <br>- 一级目录<br>- 二级目录<br></code></pre></td></tr></table></figure>\n<p><font size=\"4\"><strong>注意</strong></font>：tags和categories必须无缩进，否则在生成html时会报错</p>\n<p>这样，你就拥有了一个可以从标签和分级目录中查询的文章了</p>\n<h3 id=\"下一步，友链与作者链接\"><a href=\"#下一步，友链与作者链接\" class=\"headerlink\" title=\"下一步，友链与作者链接\"></a>下一步，友链与作者链接</h3><p><font color=\"Red\" size=\"6\"><strong>注意</strong></font>，本文之后的内容以Fluid主题为准，其他主题大同小异，具体操作可以参照主题的介绍文档。</p>\n<hr>\n<p>为什么把友链放到前面说呢，<del>当然是因为我最开始没管作者链接</del>，是因为友链的设置更加简单<br>我们需要在主题的_config.yml中（以下如果没有特殊说明，都是themes下的配置文件），在navbar：menu里，加入links，如下<br><code> - &#123; key: &quot;links&quot;, link: &quot;/links/&quot;, icon: &quot;iconfont icon-link-fill&quot; &#125;</code><br>这样就可以<br>然后找到links部分<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/links.jpg\" alt=\"links\"><br>将enable改为true即可，这样，我们的主页导航栏就会出现“友链”了。<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/links2.jpg\" alt=\"links2\"></p>\n<p><font size=\"4\">如何添加友链呢</font></p>\n<p>只需要在config文件中的links模块下的item中，按照如下格式添加即可</p>\n<figure class=\"highlight dts\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dts\">- &#123;<br><span class=\"hljs-symbol\">      title:</span> <span class=\"hljs-string\">&quot;rittmeister&quot;</span>,<br><span class=\"hljs-symbol\">      intro:</span> <span class=\"hljs-string\">&quot;xxx的博客&quot;</span>,<br><span class=\"hljs-symbol\">      link:</span> <span class=\"hljs-string\">&quot;https://lianga1.github.io/&quot;</span>,<br><span class=\"hljs-symbol\">      avatar:</span> <span class=\"hljs-string\">&quot;/img/avatar.png&quot;</span><br>    &#125;<br></code></pre></td></tr></table></figure>\n<p>其中avatar是图标，存在主题文件夹下&#x2F;source&#x2F;img文件夹中，你可以根据喜好来更改</p>\n<hr>\n<p>接下来是作者链接，作者链接略微复杂<br>首先，我们需要在config文件中，找到about：模块<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/about1.jpg\" alt=\"about\"><br>确认是enable状态<br>当然，我们现在博客中点击这个页面，会显示404<br>原因是我们需要创建一个专门的about页面，方法如下，cmd输入代码<br><code>hexo new page about</code><br>即会在source文件夹创建一个about文件夹，里面有一个index.md文件，进入<br>在标签部分，添加<br><code>layout: about</code><br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/about2.jpg\" alt=\"about\"><br>这样，我们就会发现作者链接可以进入了。然后，我们可以在config-about模块，添加自己想要的功能。<br>例如我还添加了微信二维码<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/about3.jpg\" alt=\"about3\"><br>除此之外，fluid提供了丰富的图标库，可以在其doc中查询css的使用方法，这里不展开介绍了</p>\n<h3 id=\"一些其他的骚操作\"><a href=\"#一些其他的骚操作\" class=\"headerlink\" title=\"一些其他的骚操作\"></a>一些其他的骚操作</h3><p>你还可以直接加一些新的链接，还是在navbar：menu部分里加，比如我就新加了一个tape提问箱，妈妈再也不用担心没人提问了<br><del>笑死，自闭症患儿罢了，哪有人去你的博客提问啊</del></p>\n<h2 id=\"懒加载\"><a href=\"#懒加载\" class=\"headerlink\" title=\"懒加载\"></a>懒加载</h2><p>这个功能还是蛮有用的，单独开出来说一下<br>这个是可以让你的网页先加载，图片慢慢加载的功能，毕竟你的github服务器，如果等所有封面图都加载出来，黄花菜都凉了<br>实现方法：<br>config文件中lazyload：模块，enable设为true即可</p>\n<h1 id=\"美观设置\"><a href=\"#美观设置\" class=\"headerlink\" title=\"美观设置\"></a>美观设置</h1><p>我个人很有自知之明，知道我的审美能力一般，这里仅提供一些方法上的指导</p>\n<h2 id=\"背景图\"><a href=\"#背景图\" class=\"headerlink\" title=\"背景图\"></a>背景图</h2><p>（施工中——2022.4.22半夜一点半）</p>\n<hr>\n<p>（4.23更新）<br>背景图是博客的门面，选一张得体的背景图，可以极大的提高博客的氛围感，甚至可以增加阅读体验，以下介绍一下插入背景图的方法</p>\n<h3 id=\"主页背景图\"><a href=\"#主页背景图\" class=\"headerlink\" title=\"主页背景图\"></a>主页背景图</h3><p>主页背景图，我推荐构图简单，色彩主调统一的图片，否则背景图上的字会显示不清。<br>修改背景图的方法很简单，在config文件中，搜索</p>\n<blockquote>\n<p>banner_img</p>\n</blockquote>\n<p>这个是所有背景图的关键词，因此你可以搜索到17个词<br>找到index模块下的banner_img<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/banner1.jpg\" alt=\"banner_img\"><br>其后面的目录是主题的source文件夹下的目录，只需要把你想要的图片放在这个目录下，并在config中替换即可</p>\n<h3 id=\"其他背景图\"><a href=\"#其他背景图\" class=\"headerlink\" title=\"其他背景图\"></a>其他背景图</h3><p>emm，其他的背景图嘛，我希望你可以找到一套图，来和主页的背景映衬而且又各具特色，但是目前我还没有找到这种理想的图包。</p>\n<h2 id=\"文章封面图\"><a href=\"#文章封面图\" class=\"headerlink\" title=\"文章封面图\"></a>文章封面图</h2><p>文章封面图的设置，是在文章的顶部内容栏中加入index_img: 一行<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/index_img1.jpg\" alt=\"index_img\"><br>然后，图片的位置是你的<font color=\"Red\" size=\"6\"><strong>主题目录下</strong></font>的source&#x2F;img文件夹，这里我建议给你的每篇文章进行归档，方便整理。<br>这样，你的博客文章就有封面图了<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/index_img2.jpg\" alt=\"index_img\"></p>\n<h2 id=\"图片加载动画\"><a href=\"#图片加载动画\" class=\"headerlink\" title=\"图片加载动画\"></a>图片加载动画</h2><p>如果我们打开了懒加载功能，那么我们就会看到图片加载时会有一个动画，这里的加载其实是一个gif，和图片一样，我们也是可以更换的，比如换成一个跑步的Mario<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/mario.gif\" alt=\"mario\"><br>下面介绍一下设置方法：<br>在config文件中找到lazyload模块，然后，找到loading_img<br>改为你在主题的source中的路径<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/loading.jpg\" alt=\"loading\"><br>以上，操作完成。</p>\n<h2 id=\"关于导航栏的一些玩法\"><a href=\"#关于导航栏的一些玩法\" class=\"headerlink\" title=\"关于导航栏的一些玩法\"></a>关于导航栏的一些玩法</h2><p>导航栏，美化是一个可以深入折腾的天地，简单介绍几个玩法</p>\n<h3 id=\"毛玻璃特效\"><a href=\"#毛玻璃特效\" class=\"headerlink\" title=\"毛玻璃特效\"></a>毛玻璃特效</h3><p>这个可以让你的导航栏显示成亚克力效果<br>只需要在config文件的navbar模块下，ground_glass设置为enable：true即可，下面还可以调节模糊的颜色，模糊程度等。<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/navbar1.jpg\" alt=\"ground_glass\"></p>\n<h3 id=\"自己的名字\"><a href=\"#自己的名字\" class=\"headerlink\" title=\"自己的名字\"></a>自己的名字</h3><p>你可以在导航栏的左侧标注你的名字，具体操作类似上条：<br><code>navbar--blog_title</code></p>\n<h3 id=\"菜单图标\"><a href=\"#菜单图标\" class=\"headerlink\" title=\"菜单图标\"></a>菜单图标</h3><p>菜单上的选项，你可以设置图标<br>方法如下：<br>在navbar–menu模块下，找到对应的菜单栏选项，在icon：位置，根据自己的需要，选择对应的css</p>\n<blockquote>\n<p><a href=\"https://hexo.fluid-dev.com/docs/icon/#%E5%86%85%E7%BD%AE%E7%A4%BE%E4%BA%A4%E5%9B%BE%E6%A0%87\">css库</a></p>\n</blockquote>\n<h2 id=\"关于标签栏的一些玩法\"><a href=\"#关于标签栏的一些玩法\" class=\"headerlink\" title=\"关于标签栏的一些玩法\"></a>关于标签栏的一些玩法</h2><h3 id=\"标签栏中显示的图标\"><a href=\"#标签栏中显示的图标\" class=\"headerlink\" title=\"标签栏中显示的图标\"></a>标签栏中显示的图标</h3><p>我们当然想让自己的名字显示在浏览器标签栏上来代替那个<del>丑陋的</del>Hexo标识，我们可以在config文件中的</p>\n<figure class=\"highlight avrasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs avrasm\"><span class=\"hljs-symbol\">favicon:</span><br>以及<br><span class=\"hljs-symbol\">apple_touch_icon:</span><br></code></pre></td></tr></table></figure>\n<p>这两项中，改变自己想要的图片，同样，图片的位置是&#x2F;img<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/favicon.jpg\" alt=\"favicon\"></p>\n<h3 id=\"标签栏的名字\"><a href=\"#标签栏的名字\" class=\"headerlink\" title=\"标签栏的名字\"></a>标签栏的名字</h3><p>改了图标，我们当然想要把“Hexo”改变为自己想要的名字<br><font color=\"Red\" size=\"6\"><strong>注意</strong></font>，这个是要在blog目录下的config文件更改，不要在主题配置里找！<br>在config文件中，找到site模块</p>\n<p><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/sitename.jpg\" alt=\"sitename\"><br>将其title设置为你想要的内容即可</p>\n<h3 id=\"标签栏的连接符\"><a href=\"#标签栏的连接符\" class=\"headerlink\" title=\"标签栏的连接符\"></a>标签栏的连接符</h3><p>当你打开一个文章页面或其他页面时，你会发现：标签栏名称变为<br><code>“页面名”-“站点名”</code><br>其实，中间的这个衔接符号，我们也是可以更改的，只需要在主题config文件中<br>找到“tab_title_separator:”模块<br>即可将其改为你想要的内容<br><img src=\"/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/linker.jpg\" alt=\"linker\"></p>\n<hr>\n<p>（4.24施工完毕，还有一些内容，回头再说了）</p>\n",
            "tags": [
                "博客",
                "记录"
            ]
        },
        {
            "id": "http://example.com/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/",
            "url": "http://example.com/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/",
            "title": "关于解决无法上传图片的问题",
            "date_published": "2022-04-18T15:45:02.000Z",
            "content_html": "<h1 id=\"问题\"><a href=\"#问题\" class=\"headerlink\" title=\"问题\"></a>问题</h1><p>事情是这样的，我在写博客的时候发现，我的图片即使以正确的格式引用，依旧会出现无法加载的问题<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/problem.jpg\" alt=\"问题如图\"></p>\n<p>众所周知，没有图片，你写个啥都没法直观地展示，就好像pre时用txt做演示，大家嘴上不说什么，心里肯定知道<del>你是忘了做ppt了</del></p>\n<p>总之，根据我一晚上的研究成果，整理出来了几个解决图片无法显示的问题的方法供大家参考。</p>\n<h1 id=\"解决方法\"><a href=\"#解决方法\" class=\"headerlink\" title=\"解决方法\"></a>解决方法</h1><h2 id=\"目录\"><a href=\"#目录\" class=\"headerlink\" title=\"目录\"></a>目录</h2><p>一共有这么几个方法，大家可以都试试，挑一个自己最喜欢的</p>\n<ul>\n<li><p><a href=\"./#%E5%9B%BE%E5%BA%8A%E6%B3%95\">图床法</a></p>\n<ul>\n<li>github&amp;gitee图床</li>\n<li>图床网站</li>\n<li>PicGo</li>\n</ul>\n</li>\n<li><p><a href=\"./#%E6%9C%AC%E5%9C%B0%E4%B8%8A%E4%BC%A0%E6%B3%95\">本地上传法</a></p>\n</li>\n</ul>\n<h2 id=\"图床法\"><a href=\"#图床法\" class=\"headerlink\" title=\"图床法\"></a>图床法</h2><p>是这样的，一般来说，你的hexo博客在部署到服务器时，不会给你上传那些文章里链接的图片的，所以你的md文章里链接的图片一般情况下是无法上传的，自然就无法加载出来，但是你的图片如果是网络图片，直接链接网址，就可以通过联网加载的方式显示有如下几种方法</p>\n<h3 id=\"Github-amp-Gitee仓库图床\"><a href=\"#Github-amp-Gitee仓库图床\" class=\"headerlink\" title=\"Github&amp;Gitee仓库图床\"></a>Github&amp;Gitee仓库图床</h3><p>这个的原理就是让你的公有仓库变成图床，白嫖存储空间</p>\n<h4 id=\"操作流程\"><a href=\"#操作流程\" class=\"headerlink\" title=\"操作流程\"></a>操作流程</h4><p>具体来说，github和gitee方法相似，这里仅介绍github，gitee方法类似<br>gitee的访问速度会更快一点，github的容量没有限制，可以自己取舍</p>\n<ol>\n<li>注册一个github账户</li>\n<li>创建一个新的公有库，注意一定是<strong>公有</strong>，否则外部无法访问</li>\n<li>在库存中创建一个文件夹<br> <img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/github.jpg\" alt=\"add_a_file\"></li>\n<li>把你的图片上传<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/upload.jpg\" alt=\"upload\"></li>\n<li>点击你的图片，复制地址框中的地址，注意要把bolb改为raw<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/raw.jpg\" alt=\"raw\"></li>\n<li>然后就可以在你的博客里引用这个地址了！<blockquote>\n<p>你可以用cdn加速github，比如Jsdelivr，加速方法不在本文讨论范围</p>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"图床网站\"><a href=\"#图床网站\" class=\"headerlink\" title=\"图床网站\"></a>图床网站</h3><p>上面说的只是把github当作一个公开访问的图片网站，当然，市面上还有很多的专用图床网站，免费的付费的都有，这里介绍一个免费的网站<a href=\"https://imgtu.com/\">imgtu.com</a></p>\n<ol>\n<li>打开网站，上传图片<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/image.jpg\" alt=\"image\"><blockquote>\n<p>注意不能挂梯子</p>\n</blockquote>\n</li>\n<li>上传完成后，在底部链接栏，找到md链接，复制粘贴到你的文章插图位置就ok了<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/save_the_link.jpg\" alt=\"save_the_link\"></li>\n</ol>\n<p>这个方法还是比较简单的,基本上有手就行，没手的话，<del>那你也别搞博客了</del></p>\n<h3 id=\"PicGo\"><a href=\"#PicGo\" class=\"headerlink\" title=\"PicGo\"></a>PicGo</h3><p>除了以上介绍的两种方法，还有一个比较“软件化”的方案，就是<a href=\"https://molunerfinn.com/PicGo/\">PicGo</a></p>\n<p>PicGo是一个开源的软件，它的优点是方便快捷，不用登网站，操作比较easy，而且集成了很多平台。<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/PicGo.jpg\" alt=\"PicGo\"></p>\n<h4 id=\"操作方法\"><a href=\"#操作方法\" class=\"headerlink\" title=\"操作方法\"></a>操作方法</h4><p>还是以GitHub为例，首先我们进入<strong>图床设置</strong>-&gt;<strong>Github</strong><br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/picgo_github.jpg\" alt=\"picgo_github\"><br>在对应的框里输入信息</p>\n<blockquote>\n<p>存储路径是你的GitHub仓库里的路径，没有时会创建<br>自定义域名就是你可以用cdn加速访问图片，最后两级就是你的用户名和仓库名<br>下面介绍一下token的获取方法</p>\n</blockquote>\n<h5 id=\"获取Github-Token\"><a href=\"#获取Github-Token\" class=\"headerlink\" title=\"获取Github Token\"></a>获取Github Token</h5><p>首先从个人列表进入settings<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/token1.jpg\" alt=\"token1\"><br>然后进入最底部的developer settings<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/token2.jpg\" alt=\"token2\"><br>然后进入Personal access tokens，点generate new token<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/token3.jpg\" alt=\"token3\"><br>按照如下操作<br><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/token4.jpg\" alt=\"token4\"><br>生成后记得复制，这个token<font color=\"Red\" size=\"6\"><strong>只会出现一次</strong></font></p>\n<p>至此，PicGo的使用介绍就完成了</p>\n<h2 id=\"本地上传法\"><a href=\"#本地上传法\" class=\"headerlink\" title=\"本地上传法\"></a>本地上传法</h2><h2 id=\"（施工中，累了，明天再说）\"><a href=\"#（施工中，累了，明天再说）\" class=\"headerlink\" title=\"（施工中，累了，明天再说）\"></a>（施工中，累了，明天再说）</h2><p>2022.4.20更新</p>\n<p>继续说本地上传法</p>\n<p>我们之前说过，本地的图片是不会被hexo上传的，其实这个说法不严谨<br>严格来说，是你凭空放一张图片，无法上传<br>但是，我们可以通过一个方法来上传本地图片，那就是hexo-asset-image。</p>\n<h3 id=\"操作方法-1\"><a href=\"#操作方法-1\" class=\"headerlink\" title=\"操作方法\"></a>操作方法</h3><p>首先安装hexo-asset-image<br><code>npm install https://github.com/CodeFalling/hexo-asset-image --save</code></p>\n<ul>\n<li>注意，如果你安装速度慢的话，可以讲npm换为淘宝镜像，切换方法如下：<br><code>npm config set registry https://registry.npm.taobao.org</code><br>安装完成后，我们要在_config.yml中作如下更改<blockquote>\n<p> 将 post_asset_folder 设置为true</p>\n</blockquote>\n</li>\n</ul>\n<p><img src=\"/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/post.jpg\" alt=\"post\"><br>然后，每当我们新建一篇博客时，就会有一个同名文件夹在_post文件夹中生成了<br>我们把需要插入的图片放到这个文件夹里面，在文章中引用格式如下<br><code>![图片描述]（./包名/NO.01.001.jpg）</code><br><font size=\"5\">或者</font><br><code>![logo](logo.jpg)</code><br>就可以了，这个方法也是我在用的方法，非常方便，缺点是对服务器压力比较大。</p>\n<h1 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h1><p>上述的几个方法，各有优缺点，可以结合自己的特点来使用<br>注意图片描述必须是全英文，否则无法显示图片<br>希望有所帮助</p>\n",
            "tags": [
                "技术",
                "博客",
                "markdown"
            ]
        },
        {
            "id": "http://example.com/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/",
            "url": "http://example.com/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/",
            "title": "Hexo主题模板切换",
            "date_published": "2022-04-18T12:56:34.000Z",
            "content_html": "<h1 id=\"下载主题\"><a href=\"#下载主题\" class=\"headerlink\" title=\"下载主题\"></a>下载主题</h1><p>首先，我们找一个比较好看的主题，比如我找的Fluid<br><img src=\"/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/fluid.jpg\" alt=\"fluid网址：https://hexo.fluid-dev.com \"></p>\n<p>找到了这个主题的<a href=\"https://github.com/fluid-dev/hexo-theme-fluid\">github网址</a> </p>\n<p>然后呢，我们需要在cmd中输入一行神秘代码<br><code>git clone https://github.com/fluid-dev/hexo-theme-fluid themes\\fluid</code></p>\n<p>git clone 是在GitHub上下载的命令，中间的部分是这个主题的网址，最后是你在blog目录下需要把这个下载的主题存到的位置，系统会自动创建空的文件夹。</p>\n<p>然后静待下载，下载完成后，我们的工作就成功了一大半了！</p>\n<h1 id=\"应用主题\"><a href=\"#应用主题\" class=\"headerlink\" title=\"应用主题\"></a>应用主题</h1><p>应用主题的方法很简单，只需要打开blog目录下的_config.yml文件，把倒数第二个部分的“theme：”改为你的主题所在文件夹的名字就OK了。<br><img src=\"/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/config.jpg\" alt=\"这样\"></p>\n<p>别忘了部署到服务器！</p>\n",
            "tags": [
                "技术",
                "博客",
                "markdown"
            ]
        },
        {
            "id": "http://example.com/2021/08/24/md%E8%AF%AD%E6%B3%95%E8%AF%95%E9%AA%8C/",
            "url": "http://example.com/2021/08/24/md%E8%AF%AD%E6%B3%95%E8%AF%95%E9%AA%8C/",
            "title": "md语法试验",
            "date_published": "2021-08-24T07:32:52.000Z",
            "content_html": "<h1 id=\"分层\"><a href=\"#分层\" class=\"headerlink\" title=\"分层\"></a>分层</h1><h2 id=\"二级目录\"><a href=\"#二级目录\" class=\"headerlink\" title=\"二级目录\"></a>二级目录</h2><h3 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h3><h4 id=\"无序列表\"><a href=\"#无序列表\" class=\"headerlink\" title=\"无序列表\"></a>无序列表</h4><ul>\n<li>小标</li>\n<li>无序</li>\n<li>各种符号都行<ul>\n<li>第二层嵌套<ul>\n<li>第n层嵌套<h4 id=\"有序列表\"><a href=\"#有序列表\" class=\"headerlink\" title=\"有序列表\"></a>有序列表</h4></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li>有序列表</li>\n<li>第一行序号为起始序号</li>\n<li>即使后面序号错误也会顺序下排<ol>\n<li>嵌套效果<h2 id=\"内容\"><a href=\"#内容\" class=\"headerlink\" title=\"内容\"></a>内容</h2><h3 id=\"引用说明\"><a href=\"#引用说明\" class=\"headerlink\" title=\"引用说明\"></a>引用说明</h3><blockquote>\n<p>引用内容</p>\n<blockquote>\n<p>二级引用</p>\n<blockquote>\n<p>三级引用</p>\n</blockquote>\n</blockquote>\n</blockquote>\n<h3 id=\"代码块\"><a href=\"#代码块\" class=\"headerlink\" title=\"代码块\"></a>代码块</h3><p><code>少量代码，单行使用，用·包裹</code></p>\n</li>\n</ol>\n</li>\n</ol>\n<figure class=\"highlight\"><table><tr><td class=\"gutter\"><div class=\"code-wrapper\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></div></td><td class=\"code\"><pre><code class=\"hljs\"><br>大量代码多行使用，用三个·包裹<br>大量代码多行使用，用三个·包裹<br>大量代码多行使用，用三个·包裹<br>大量代码多行使用，用三个·包裹<br><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"链接\"><a href=\"#链接\" class=\"headerlink\" title=\"链接\"></a>链接</h2><h3 id=\"网页链接\"><a href=\"#网页链接\" class=\"headerlink\" title=\"网页链接\"></a>网页链接</h3><h4 id=\"行内式\"><a href=\"#行内式\" class=\"headerlink\" title=\"行内式\"></a>行内式</h4><p>链接放在【】中，地址放在后面的小括号中，引号内是title<br><a href=\"www.baidu.com\" title=\"百度一下，你就知道\">百度</a><br>[百度]是一个搜索引擎</p>\n<h4 id=\"参数式\"><a href=\"#参数式\" class=\"headerlink\" title=\"参数式\"></a>参数式</h4><p>链接在【】内，地址在冒号后面，title用引号<br>[百度]:<a href=\"http://www.baidu.com/\">www.baidu.com</a> “百度一下，你就知道”<br>[百度]是一个搜索引擎</p>\n<h3 id=\"图片\"><a href=\"#图片\" class=\"headerlink\" title=\"图片\"></a>图片</h3><p>与链接基本一致，注意在引用图片时【】前加上！<br><img src=\"/2021/08/24/md%E8%AF%AD%E6%B3%95%E8%AF%95%E9%AA%8C/download\\edge\\13623636-6d878e3d3ef63825\" alt=\"logo\"> “my logo”</p>\n<h2 id=\"工整\"><a href=\"#工整\" class=\"headerlink\" title=\"工整\"></a>工整</h2><h3 id=\"分割线\"><a href=\"#分割线\" class=\"headerlink\" title=\"分割线\"></a>分割线</h3><h2 id=\"由-这三种之一的三个符号表示\"><a href=\"#由-这三种之一的三个符号表示\" class=\"headerlink\" title=\"由* - _这三种之一的三个符号表示\"></a>由* - _这三种之一的三个符号表示</h2><p>这就是分割线</p>\n<h3 id=\"表格\"><a href=\"#表格\" class=\"headerlink\" title=\"表格\"></a>表格</h3><p>&#x2F;&#x2F;例子</p>\n<table>\n<thead>\n<tr>\n<th align=\"left\">123</th>\n<th align=\"center\">234</th>\n<th align=\"right\">345</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">abc</td>\n<td align=\"center\">bcd</td>\n<td align=\"right\">cde</td>\n</tr>\n</tbody></table>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><h3 id=\"强调字体\"><a href=\"#强调字体\" class=\"headerlink\" title=\"强调字体\"></a>强调字体</h3><ol>\n<li>强调字体<br> 用星号包裹，如<em>md</em>,<strong>md</strong> </li>\n<li>转义<br> 用\\</li>\n<li>删除线<br> <del>删除</del></li>\n</ol>\n",
            "tags": [
                "技术",
                "博客",
                "markdown"
            ]
        }
    ]
}