<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Linux学习笔记2</title>
    <link href="/2024/03/15/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/"/>
    <url>/2024/03/15/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02/</url>
    
    <content type="html"><![CDATA[<h2 id="账号文件"><a href="#账号文件" class="headerlink" title="账号文件"></a>账号文件</h2><h3 id="x2F-etc-x2F-passwd"><a href="#x2F-etc-x2F-passwd" class="headerlink" title="&#x2F;etc&#x2F;passwd"></a>&#x2F;etc&#x2F;passwd</h3><p>存储了</p><ul><li>账号信息</li><li>x（密码）</li><li>UID</li><li>GID</li><li>用户信息栏</li><li>家目录</li><li>shell</li></ul><h3 id="x2F-etc-x2F-shadow"><a href="#x2F-etc-x2F-shadow" class="headerlink" title="&#x2F;etc&#x2F;shadow"></a>&#x2F;etc&#x2F;shadow</h3><ul><li>账号名</li><li>密码</li><li>最近修改</li><li>不可修改天数</li><li>建议修改天数</li><li>警告天数</li><li>过期密码宽限</li><li>失效日期</li></ul><h2 id="忘记密码"><a href="#忘记密码" class="headerlink" title="忘记密码"></a>忘记密码</h2><p>普通用户：passwd<br>root：单人启动模式</p><h2 id="用户组"><a href="#用户组" class="headerlink" title="用户组"></a>用户组</h2><p>&#x2F;etc&#x2F;group</p><ul><li>组名</li><li>用户组密码</li><li>GID</li><li>支持的账号名称 逗号分开</li></ul><p>group：查看用户所属的组，第一个是有效用户组，即为创建文件时代表的组<br>newgrp：切换有效用户组，以另外一个单独的shell生效。</p><p>加入用户组：root用usermod，组管理员用gpasswd</p><h2 id="账号管理"><a href="#账号管理" class="headerlink" title="账号管理"></a>账号管理</h2><p>useradd：新建账户</p><ul><li>-g初始用户组</li><li>-G次要用户组</li><li>-e失效日期</li><li>-f密码失效</li><li>-s默认shell</li></ul><p>userdel：删除账户<br>usermod：修改存在的账户</p><p>id：查询用户信息<br>finger：查询用户动态<br>chfn：改变自身动态</p><h2 id="用户组管理"><a href="#用户组管理" class="headerlink" title="用户组管理"></a>用户组管理</h2><p>groupadd：新增组<br>groupmod：修改组<br>groupdel：删除组</p><h2 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h2><p>ACL为访问控制列表，针对单一用户、单一目录来进行rwx的权限设置。</p><p>setfacl：设置ACL参数</p><ul><li>-m为设置参数</li><li>-x为删除参数</li><li>-R递归设置</li></ul><p>使用方式：</p><ul><li>针对特定使用者：setfacl -m u:账号列表：rwx</li><li>针对特定组：setfacl -m g:用户组列表：rwx</li><li>针对有效权限：setfacl -m m:[rwx]<br>getfacl：查询文件权限<br>getfacl filename</li></ul><h2 id="用户身份切换"><a href="#用户身份切换" class="headerlink" title="用户身份切换"></a>用户身份切换</h2><p>su：切换shell执行不同身份</p><ul><li>-：直接变为root，作为login_shell</li><li>-l：指定账号</li><li>如无-，则表示用非login shell登录</li></ul><p>区别在于：非login shell时，你的环境变量还是使用的原来的用户，而loginshell会使用root的名称。</p><p>sudo：以root权限来执行命令</p><ul><li>-b：后台执行</li><li>-u：指定希望切换的使用者</li></ul><p>能否执行取决于是否在&#x2F;etc&#x2F;sudoers文件，可用visudo修改。<br>visudo可以通过添加用户，添加用户组，限制命令执行，别名等方式来简化流程。</p><h2 id="特殊shell：-x2F-sbin-x2F-nologin"><a href="#特殊shell：-x2F-sbin-x2F-nologin" class="headerlink" title="特殊shell：&#x2F;sbin&#x2F;nologin"></a>特殊shell：&#x2F;sbin&#x2F;nologin</h2><p>系统账号可以登录，但是不能用shell访问系统资源</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux学习笔记1</title>
    <link href="/2024/03/03/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/"/>
    <url>/2024/03/03/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B01/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux学习笔记1"><a href="#Linux学习笔记1" class="headerlink" title="Linux学习笔记1"></a>Linux学习笔记1</h1><h2 id="启动运行级"><a href="#启动运行级" class="headerlink" title="启动运行级"></a>启动运行级</h2><p>Linux的&#x2F;etc&#x2F;rcX.d目录下存储着各个启动级的运行程序<br>运行级<strong>1</strong>时进入单用户模式，仅仅进行文件系统维护。标准运行级为<strong>3</strong>。运行级为<strong>5</strong>时会启动X Window服务。切换启动级别可以使用runlevel命令来设置</p><h2 id="内核模块"><a href="#内核模块" class="headerlink" title="内核模块"></a>内核模块</h2><p>Linux内有两种方法插入设备驱动：</p><ul><li>编译进内核</li><li>可插入的设备驱动</li></ul><p>linux内部有三种设备文件：</p><ul><li>字符设备文件：包括终端等</li><li>块设备文件：包括硬盘</li><li>网络设备文件：包括网卡和回环设备<br>每个设备都有一个节点文件，用于唯一标识设备（主设备号，次设备号）</li></ul><h2 id="设置终端"><a href="#设置终端" class="headerlink" title="设置终端"></a>设置终端</h2><p>可以使用setterm命令执行诸如：</p><ul><li>settterm -inversescreen on</li><li>setterm -background white</li><li>setterm -foreground black</li></ul><h2 id="GNU-nm"><a href="#GNU-nm" class="headerlink" title="GNU nm"></a>GNU nm</h2><p>这个命令可以分析obj文件并输出符号列表</p><h2 id="man"><a href="#man" class="headerlink" title="man"></a>man</h2><p>man可以指定手册的部分，分为1-9内容</p><ul><li>1：命令名</li><li>2：系统调用</li><li>3：库调用</li><li>4：特殊文件</li><li>5：文件格式与约定</li><li>6：游戏</li><li>7：概览，约定</li><li>8：root命令</li><li>9：内核例程</li></ul><h2 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h2><p>如下参数：</p><ul><li>-F：标注文件类型</li><li>-R：递归寻找</li><li>加入字符串：模糊匹配</li><li>–time&#x3D;atime：显示访问时间</li><li>-d：不递归显示</li></ul><h2 id="copy"><a href="#copy" class="headerlink" title="copy"></a>copy</h2><p>cp source dest<br>如下参数：</p><ul><li>-i：询问是否覆盖</li><li>-R：复制目录</li></ul><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><p>ln srcfile linkfile</p><p>参数；</p><ul><li>-s：符号链接</li><li>无参数：硬链接</li></ul><h2 id="mv"><a href="#mv" class="headerlink" title="mv"></a>mv</h2><p>mv src dest</p><p>移动文件是不会改变inode的。</p><h2 id="目录操作"><a href="#目录操作" class="headerlink" title="目录操作"></a>目录操作</h2><p>mkdir ：-p可以创建缺失父目录</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>课题组23-11-15周报</title>
    <link href="/2023/11/15/%E8%AF%BE%E9%A2%98%E7%BB%8423-11-15%E5%91%A8%E6%8A%A5/"/>
    <url>/2023/11/15/%E8%AF%BE%E9%A2%98%E7%BB%8423-11-15%E5%91%A8%E6%8A%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="实验关于fp16参数转换速度的问题"><a href="#实验关于fp16参数转换速度的问题" class="headerlink" title="实验关于fp16参数转换速度的问题"></a>实验关于fp16参数转换速度的问题</h1><p>本周进行了一个实验，主要用于观察pytorch中对张量转移的各种方法的性能差异。</p><h2 id="实验思路"><a href="#实验思路" class="headerlink" title="实验思路"></a>实验思路</h2><h3 id="几种不同的传输方向"><a href="#几种不同的传输方向" class="headerlink" title="几种不同的传输方向"></a>几种不同的传输方向</h3><ul><li>cpu -&gt; cpu</li><li>cpu -&gt; gpu</li><li>gpu -&gt; cpu</li><li>gpu -&gt; gpu<h3 id="几种不同的数据"><a href="#几种不同的数据" class="headerlink" title="几种不同的数据"></a>几种不同的数据</h3></li><li>fp32 -&gt; fp32</li><li>fp32 -&gt; fp16<br><code>调用half()函数，将fp32数据转换为fp16数据</code></li><li>fp16 -&gt; fp16</li><li>fp16 -&gt; fp32<br><code>调用float()函数，将fp16数据转换为fp32数据</code></li></ul><p><strong>目前第三、四种暂未测试</strong></p><h3 id="几种不同的传输方式"><a href="#几种不同的传输方式" class="headerlink" title="几种不同的传输方式"></a>几种不同的传输方式</h3><ul><li>copy_()</li><li>to()</li></ul><h2 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h2><p>准备一个目的地矩阵，一个源矩阵组（100个）。分别用随机数初始化。<br>循环100次，每次都遍历整个矩阵组，传输至对应的目的地矩阵。<br>测量总时长，对不同情况进行比较<br>代码模板如下：</p><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> time<br>tensor_cpu_1 = torch.rand(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>)<br>tensor_gpu_1 = torch.rand(<span class="hljs-number">1000</span>,<span class="hljs-number">1000</span>).cuda()<br>tensor_cpu_2 = torch.rand(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>,<span class="hljs-number">1000</span>)<br>tensor_gpu_2 = torch.rand(<span class="hljs-number">1000</span>,<span class="hljs-number">1000</span>,<span class="hljs-number">1000</span>).cuda()<br>time_sum = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    start = time.time()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>        tensor_cpu_1.copy_(tensor_cpu_2[i])<br>    end = time.time()<br>    time_sum += end - start<br><br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;time for copy from cpu to cpu via _copy():&quot;</span>, time_sum)<br><br></code></pre></td></tr></table></figure><p>如上代码展示了从cpu到cpu传输fp32的过程。最终展示了传输十万个1000*1000的矩阵所耗费的总时间。<br>经过实验，结果如下表所示：<br>记录数据如下：</p><table><thead><tr><th align="center">传输方向</th><th align="center">传输方式</th><th align="center">数据类型</th><th align="center">时间</th></tr></thead><tbody><tr><td align="center">cpu -&gt; cpu</td><td align="center">copy_()</td><td align="center">fp32 -&gt; fp32</td><td align="center">2.187</td></tr><tr><td align="center">cpu -&gt; cpu</td><td align="center">to()</td><td align="center">fp32 -&gt; fp32</td><td align="center">0.025</td></tr><tr><td align="center">cpu -&gt; cpu</td><td align="center">copy_()</td><td align="center">fp32 -&gt; fp16</td><td align="center">5.855</td></tr><tr><td align="center">cpu -&gt; cpu</td><td align="center">to()</td><td align="center">fp32 -&gt; fp16</td><td align="center">5.634</td></tr><tr><td align="center">cpu -&gt; gpu</td><td align="center">copy_()</td><td align="center">fp32 -&gt; fp32</td><td align="center">9.663</td></tr><tr><td align="center">cpu -&gt; gpu</td><td align="center">to()</td><td align="center">fp32 -&gt; fp32</td><td align="center">9.555</td></tr><tr><td align="center">cpu -&gt; gpu</td><td align="center">copy_()</td><td align="center">fp32 -&gt; fp16</td><td align="center">9.876</td></tr><tr><td align="center">cpu -&gt; gpu</td><td align="center">to()</td><td align="center">fp32 -&gt; fp16</td><td align="center">10.264</td></tr><tr><td align="center">gpu -&gt; cpu</td><td align="center">copy_()</td><td align="center">fp32 -&gt; fp32</td><td align="center">8.895</td></tr><tr><td align="center">gpu -&gt; cpu</td><td align="center">to()</td><td align="center">fp32 -&gt; fp32</td><td align="center">13.649</td></tr><tr><td align="center">gpu -&gt; cpu</td><td align="center">copy_()</td><td align="center">fp32 -&gt; fp16</td><td align="center">10.051</td></tr><tr><td align="center">gpu -&gt; cpu</td><td align="center">to()</td><td align="center">fp32 -&gt; fp16</td><td align="center">7.320</td></tr><tr><td align="center">gpu -&gt; gpu</td><td align="center">copy_()</td><td align="center">fp32 -&gt; fp32</td><td align="center">0.605</td></tr><tr><td align="center">gpu -&gt; gpu</td><td align="center">to()</td><td align="center">fp32 -&gt; fp32</td><td align="center">0.029</td></tr><tr><td align="center">gpu -&gt; gpu</td><td align="center">copy_()</td><td align="center">fp32 -&gt; fp16</td><td align="center">0.484</td></tr><tr><td align="center">gpu -&gt; gpu</td><td align="center">to()</td><td align="center">fp32 -&gt; fp16</td><td align="center">0.591</td></tr></tbody></table><ul><li>注意，测试时间可能会有波动，尤其是在时间较短时，考虑到这种传输主要出现在gpu-&gt;gpu中，不是主要考虑内容</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>周报</tag>
      
      <tag>课题组</tag>
      
      <tag>神经网络</tag>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>课题组第五周学习</title>
    <link href="/2023/10/22/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E4%BA%94%E5%91%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/10/22/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E4%BA%94%E5%91%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="高效直接访问主机内存的方法"><a href="#高效直接访问主机内存的方法" class="headerlink" title="高效直接访问主机内存的方法"></a>高效直接访问主机内存的方法</h1><h2 id="现有方法存在的问题"><a href="#现有方法存在的问题" class="headerlink" title="现有方法存在的问题"></a>现有方法存在的问题</h2><h3 id="通过加载后执行的方法"><a href="#通过加载后执行的方法" class="headerlink" title="通过加载后执行的方法"></a>通过加载后执行的方法</h3><p>面对巨大的模型参数规模，现有GPU的显存难以支撑大模型的训练。因此产生了一种通过加载后执行的方法，即将模型参数存储在主机内存中，每次训练时将参数加载到显存中，训练结束后将参数保存到主机内存中。这种方法的缺点是每次训练都需要将参数加载到显存中，这个过程会消耗大量的时间，例如在v100上，加载时间会是处理时间的4倍以上，导致训练效率低下。有一种异步加载方法，将加载层和训练层分开，训练层在训练时异步加载参数，但是这种方法会导致训练时的显存占用过高，而且层数较多时加载时间过高的劣势逐渐显现，优化并不明显。</p><h2 id="本文提出的方法"><a href="#本文提出的方法" class="headerlink" title="本文提出的方法"></a>本文提出的方法</h2><h3 id="直接主机访问"><a href="#直接主机访问" class="headerlink" title="直接主机访问"></a>直接主机访问</h3><p>避开加载和训练不同步的问题，直接将cpu内存当作gpu的虚拟内存进行访问，这样避免了加载过程中占用gpu显存过高的问题，但是由于访问和数据流动要经过pcie总线，传输速度较慢。<br>因此，DHA使用了这样一种办法，使得其可以自适应选择访问方式，其可以通过直接主机访问和加载后执行两种方法进行训练，使得加载的时间可以隐藏在训练流的流水线中。</p><h3 id="多GPU方法"><a href="#多GPU方法" class="headerlink" title="多GPU方法"></a>多GPU方法</h3><p>对于多个GPU，由于GPU间通信效率要高于PCIE通信效率，因此可以将模型拆分成多个部分，分别存储在不同的GPU中，这样每次训练的加载都可以直接从其他GPU中加载，而不需要从主机内存中加载，这样可以减少加载时间。</p><h3 id="DeepPlan"><a href="#DeepPlan" class="headerlink" title="DeepPlan"></a>DeepPlan</h3><p>本文还提出了一个工具：用来为给定模型自动生成执行计划，过程如下：</p><ul><li>对本地GPU显存和主机内存分析性能</li><li>通过比较DHA和流水线方法的延迟差异来决定每一层的策略</li><li>如果有多个GPU，则根据GPU数量平均划分模型</li><li>协调将直接主机访问的执行和加载后执行的执行进行协调<br>本方案在部署时只需要进行一次执行。<h2 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h2>对于不同层，加载——执行策略与DHA策略的时间是不同的，<table><thead><tr><th align="center">层</th><th align="center">加载——执行策略</th><th align="center">DHA策略</th><th align="center">结论</th></tr></thead><tbody><tr><td align="center">卷积层</td><td align="center">小规模差异不大</td><td align="center">大规模较慢</td><td align="center">推荐在较小卷积层使用DHA，同时加载较大卷积层等待直接执行</td></tr><tr><td align="center">全连接层</td><td align="center">加载快</td><td align="center">执行慢</td><td align="center">推荐在全连接层使用加载后执行，因为其需要频繁访问内存</td></tr><tr><td align="center">嵌入层</td><td align="center">加载较慢</td><td align="center">执行较快</td><td align="center">推荐在嵌入层使用DHA，因为其规模较大，而层中一些参数的访问较少</td></tr><tr><td align="center">归一化层</td><td align="center">LayerNorm更好</td><td align="center">BatchNorm更好</td><td align="center">需要根据具体情况进行选择</td></tr></tbody></table></li></ul><p>产生差异的原因则是不同层对内存访问的需求不同，导致pcie访问次数不同，pcie作为瓶颈，访问次数越多，延迟越大。</p><h3 id="并行传输"><a href="#并行传输" class="headerlink" title="并行传输"></a>并行传输</h3><p>对于多GPU场景，将模型划分为多个部分后，采用并行传输策略：从内存并行地将模型传输到两个GPU，再从第二个GPU向第一个GPU传输，这样可以减少传输时间。<br>在此基础上，可以将GPU2——GPU1的传输变为流水线传输，这样可以进一步减少传输时间。<br>但是，由于CPU提供的PCIE总线数量限制，多GPU系统，例如8GPU也只能每两个GPU公用一组总线，因此多GPU的总线需要考虑总线拓扑。</p><h2 id="DeepPlan实现"><a href="#DeepPlan实现" class="headerlink" title="DeepPlan实现"></a>DeepPlan实现</h2><h3 id="整体实现思路"><a href="#整体实现思路" class="headerlink" title="整体实现思路"></a>整体实现思路</h3><p>再进行训练前，deepPlan会根据每一层的性能分析，推理出当前层采用何种方式进行训练（加载——执行orDHA）。遍历完整个网络后，将根据策略直接执行训练。如果在多GPU系统中，DeepPlan还会根据GPU连连接拓扑，将模型划分为多个部分，应用并行传输方案。</p><h3 id="单层性能分析"><a href="#单层性能分析" class="headerlink" title="单层性能分析"></a>单层性能分析</h3><p>利用单层执行时间的统计数据，或者执行一次单层来得到每一层的性能数据。</p><h3 id="层间性能分析"><a href="#层间性能分析" class="headerlink" title="层间性能分析"></a>层间性能分析</h3><p>对于每层性能已经得到的情况。检查每一层切换策略到DHA后其获得的性能差异是否比加载后执行的停滞时间更短，如果是的话则切换为DHA。并且通过递归的方式检查每个层之前最多可以使用几个DHA来缩短总加载停滞时间。</p><h3 id="模型传输规划"><a href="#模型传输规划" class="headerlink" title="模型传输规划"></a>模型传输规划</h3><p>DeepPlan根据GPU拓扑，和PCIE交换机布局，避免并行加载的总线冲突，检查所选GPU是否使用NVLink，如果使用则直接进行并行传输，否则使用流水线传输。同时，根据并行传输带来的性能优化，重新规划每一层使用的策略。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>周报</tag>
      
      <tag>课题组</tag>
      
      <tag>神经网络</tag>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>课题组第四周学习</title>
    <link href="/2023/10/13/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/10/13/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E5%9B%9B%E5%91%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="ZeRO-Offload方法"><a href="#ZeRO-Offload方法" class="headerlink" title="ZeRO-Offload方法"></a>ZeRO-Offload方法</h1><h2 id="提出背景"><a href="#提出背景" class="headerlink" title="提出背景"></a>提出背景</h2><p>对大模型训练来说，GPU显存对参数规模巨大的网络来说是一个瓶颈，然而CPU内存可以做到TB级别，因此可以考虑将一部分参数放在CPU上，而将需要频繁访问的参数放在GPU上，这样可以减少GPU显存的压力，提高训练速度。ZeRO-Offload提出了一种没有数据冗余的优化方法，可以将模型参数分布在CPU和GPU上，而且可以在CPU和GPU之间进行无缝的迁移。</p><h3 id="大模型传统方法"><a href="#大模型传统方法" class="headerlink" title="大模型传统方法"></a>大模型传统方法</h3><p>针对大模型需要的内存过大的问题，传统分为两种方法：</p><ul><li>模型分割：将模型分割成多个部分，每个部分在GPU上训练，然后将结果传递给下一个部分，</li><li>流水线并行：将训练过程分为不同层，每个层分给不同的GPU，然后将结果传递给下一个GPU<h2 id="增益来源"><a href="#增益来源" class="headerlink" title="增益来源"></a>增益来源</h2>根据计算流程，CPU的计算量相比于GPU的$O(MB)$,只有$O(M)$，其中M是模型大小，B是批次大小。<br>这个过程中，ZeRO-Offload将前向与后向传播分配给了GPU，而标准化计算和权重更新等对模型大小有直接联系的计算则分配给了CPU。<br>在数据吞吐方面，cpu与gpu之间仅存在fp16数据的传输，相比与其他方法（例如L2L）有大幅度减少<br>在并行方面，随着计算节点的增加，CPU的计算资源会随着节点数量增加而增加<br>CPU计算通过提高并行性增加了效率</li></ul><h3 id="对CPU作为计算瓶颈的解决方法"><a href="#对CPU作为计算瓶颈的解决方法" class="headerlink" title="对CPU作为计算瓶颈的解决方法"></a>对CPU作为计算瓶颈的解决方法</h3><h4 id="对CPU计算的优化"><a href="#对CPU计算的优化" class="headerlink" title="对CPU计算的优化"></a>对CPU计算的优化</h4><ul><li>向量运算SIMD</li><li>循环展开</li><li>多核并行</li><li>减少缓存抖动<h4 id="延迟参数更新"><a href="#延迟参数更新" class="headerlink" title="延迟参数更新"></a>延迟参数更新</h4>将参数更新延迟，重叠CPU与GPU计算。也就是说，在某一轮计算之后，此后每次gpu使用的优化器参数都是上一轮计算的结果，而不是这一轮计算的结果。，因此可以让cpu计算时间和gpu计算时间重叠。提高流水线负载率。<h2 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h2>ZeRO-Offload 同时利用CPU内存计算能力来优化。基于ZeRO优化方法，但是不是像原本多个GPU并行计算，并且通过联系收集器来进行并行。而是把这个通讯过程转化为与CPU的联系，相当于原本多个GPU同时做的工作，让单个GPU进行，每个阶段只进行原先一个GPU进行的工作，同时把其他GPU本应进行的计算状态经由内存进行存储。<h3 id="ZeRO的工作"><a href="#ZeRO的工作" class="headerlink" title="ZeRO的工作"></a>ZeRO的工作</h3>ZeRO，在ZeRO-Offload中使用ZeRO-2阶段，这个阶段你主要是分割模型状态和梯度。在ZeRO-2中，每个GPU都存储着所有参数，但是每轮训练只更新其中不包含的部分。<br>这个过程如下：</li></ul><ol><li>每个GPU进行前馈，计算不同批次的损失。</li><li>每个cpu进行反向传播，并且对每个有梯度的GPU使用减少梯度的算子进行平均。</li><li>反向传播结束后，GPU使用其对应的梯度平均值对其部分参数和优化器状态进行更新。</li><li>进行一次全收集，接收其他GPU计算的参数更新。</li></ol><h3 id="ZeRO-Offload的工作"><a href="#ZeRO-Offload的工作" class="headerlink" title="ZeRO-Offload的工作"></a>ZeRO-Offload的工作</h3><p>ZeRO-Offload将训练修改为数据流图，主要优势：使得CPU计算量减少了几个数量级。保证CPU与GPU通讯最小化。最大限度节省内存。</p><h4 id="计算流图"><a href="#计算流图" class="headerlink" title="计算流图"></a>计算流图</h4><p>计算流图是一种图形化的表示，用于表示计算过程中的数据流动。在计算流图中，节点表示计算，边表示数据流动。<br><img src="https://raw.githubusercontent.com/lianga1/picGo_test/main/1.jpg" alt="计算流图"></p><h4 id="减少CPU计算"><a href="#减少CPU计算" class="headerlink" title="减少CPU计算"></a>减少CPU计算</h4><p>ZeRO-Offload将前向与后向传播分配给了GPU，而标准化计算和权重更新等对模型大小有直接联系的计算则分配给了CPU。</p><h4 id="减少CPU与GPU通讯"><a href="#减少CPU与GPU通讯" class="headerlink" title="减少CPU与GPU通讯"></a>减少CPU与GPU通讯</h4><p>创建fp32区：为了避免fp32数据在pcie总线传输，需要将所有fp32数据放在一个设备上进行处理<br>p16分配：将fp16必须放在前馈与反向传播共同节点的位置，因为这两个节点之间的通信是较大的。<br>因此，ZeRO-Offload将fp16分配给GPU，而将fp32分配给CPU。</p><h4 id="减少内存"><a href="#减少内存" class="headerlink" title="减少内存"></a>减少内存</h4><p>将反向传播后得到的梯度，以及更新梯度所需要的计算和存储空间，写遭到CPU上，可以节省最多的显存使用。</p><h2 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h2><h3 id="扩展性强"><a href="#扩展性强" class="headerlink" title="扩展性强"></a>扩展性强</h3><p>对于任何模型，其优化算法的优化参数对于ZeRO-Offload来说并不关键，其只是需要把fp32的计算内容单独放在CPU中。</p><h3 id="支持并行"><a href="#支持并行" class="headerlink" title="支持并行"></a>支持并行</h3><p>对多个GPU而言。ZeRO-Offload基于ZeRO-2，因此可以将分区的参数分配给多个GPU。</p><h3 id="模型并行"><a href="#模型并行" class="headerlink" title="模型并行"></a>模型并行</h3><p>ZeRO-Offload还可以用模型并行来实现更好的并行性。通过给cpu卸载梯度、优化器状态和优化器计算来和模型并行计算相适应。在这个情况下，首先，借由更难耗尽内存，可以使用更大的批次大小。其次，可以使用更多的GPU来进行模型并行计算。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>周报</tag>
      
      <tag>课题组</tag>
      
      <tag>神经网络</tag>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>课题组第一周学习</title>
    <link href="/2023/09/30/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E4%B8%80%E5%91%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2023/09/30/%E8%AF%BE%E9%A2%98%E7%BB%84%E7%AC%AC%E4%B8%80%E5%91%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="理论学习"><a href="#理论学习" class="headerlink" title="理论学习"></a>理论学习</h1><h2 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h2><p>反向传播是一种基于有监督学习，用于根据误差和损失函数调整网络权重的算法。反向传播算法的核心思想是通过链式法则计算损失函数对于每个权重的梯度，然后使用梯度下降法更新权重。<br>过程：</p><ul><li>首先通过正向传播，根据输入数据得到一个网络的激励</li><li>根据得到的激励与目标值计算损失函数</li><li>根据损失函数，从输出层开始，依次沿着计算图反向计算每个权重的梯度</li><li>根据得到的梯度调整权重<br>[1] <a href="https://books.google.com/books/about/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8.html?id=2-PWvQEACAAJ">深度学习入门: 基于Python的理论与实现[M]. 人民邮电出版社, 2018.(p.121,161)</a><h2 id="前馈"><a href="#前馈" class="headerlink" title="前馈"></a>前馈</h2>前馈神经网络是一种最简单的神经网络，它的每个神经元都是前一层神经元的输出。前馈神经网络的每个神经元都是前一层神经元的输出，因此它的输出不会反馈到输入层，这种网络结构也被称为前馈神经网络。</li></ul><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>卷积（convolution）是一种数学运算，主要应用于信号处理中对系统响应的计算。卷积运算可以将某个冲激响应针对任意输入进行计算，得到对应的响应结果。卷积运算的公式如下：<br>$$<br>y(t) &#x3D; \int_{-\infty}^{\infty} x(a)h(t-a)da<br>$$<br>其中，$x(t)$为输入信号，$h(t)$为系统响应，$y(t)$为输出信号。</p><h3 id="二维离散卷积"><a href="#二维离散卷积" class="headerlink" title="二维离散卷积"></a>二维离散卷积</h3><p>对于图像处理来说，卷积需要用到二维矩阵的滑动窗口来进行卷积运算。二维离散卷积的公式如下：<br>$$<br>y(i,j) &#x3D; \sum_{m&#x3D;-\infty}^{\infty}\sum_{n&#x3D;-\infty}^{\infty}x(m,n)h(i-m,j-n)<br>$$<br>其中，$x(m,n)$为输入图像，$h(i,j)$为卷积核，$y(i,j)$为输出图像。</p><h3 id="卷积神经网络-1"><a href="#卷积神经网络-1" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><p>卷积神经网络（CNN）中，增加了卷积层和池化层。其可以从原本多维度的数据中提取欧氏距离较近的单元之间蕴含的信息。</p><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p>在卷积层中，当输入数据是图像时，卷积层会以三维数据形式接收数据，并以三维数据形式传输到下一层，输入输出数据称为特征图（feature map）。其中，卷积层的输入数据称为输入特征图（input feature map），输出数据称为输出特征图（output feature map）。</p><h4 id="CNN的处理流"><a href="#CNN的处理流" class="headerlink" title="CNN的处理流"></a>CNN的处理流</h4><p>针对一个图像，有三维的信息（长、宽、通道），同样，对这个图像进行处理的卷积核也是三维的。但是最终卷积得到的输出结果是二维的（每个通道卷积的结果加在一起）。在CNN中，针对多个卷积核，会得到多个二维的输出结果，这些输出结果会被叠加在一起，得到一个三维的输出结果。这个结果传递给下一层。同时，对多个数据，即批处理，卷积层将多个样本汇总成一次处理，传递中综合成四维的数据。</p><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p>池化层是一种降低数据大小的方法，它可以减少数据的大小，同时也可以防止过拟合。池化层的处理流程如下：</p><ul><li>按照设定的步长，从输入数据中提取数据块</li><li>例如MAX池化，将数据块中的最大值作为输出结果</li><li>输出结果的规模即随步长变大而缩小<br>同时，池化层输入数据和输出数据的维度相同<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2>循环神经网络常用于nlp领域。它和前馈神经网络或CNN的主要区别在于循环神经网络（RNN）的隐藏层的输出不仅仅取决于当前的输入，还取决于前一时刻的隐藏层的输出。因此，RNN具有某种程度上的“记忆”能力。<br>另一个显著特征在于它们在每个网络层共享参数，RNN在每一层都共享相同的参数，这使得它们可以处理任意长度的序列。<br>然而，RNN在反向传播的过程中，梯度会随着时间的推移而消失或爆炸，这使得它们很难学习长期依赖关系。<h2 id="注意力机制"><a href="#注意力机制" class="headerlink" title="注意力机制"></a>注意力机制</h2>注意力机制可以增强神经网络输入数据中某些部分的权重，同时减弱其他部分的权重。<br>例如对一个翻译句子的网络，普通的逐个词翻译会在每一轮翻译过程中对单词序列依次提高注意力，也就是其注意力矩阵会是一个对角线上权值高的矩阵。但是在注意力机制下，每一轮翻译过程中，网络会根据上一轮的翻译结果，对输入句子中的某些部分进行更多的关注，即其权值的最大值不一定在对角线。从而提高翻译的连贯性。<h2 id="并行计算"><a href="#并行计算" class="headerlink" title="并行计算"></a>并行计算</h2>并行计算对计算任务进行拆分，将同时进行的计算任务分配到不同的计算单元上，从而提高计算速度。拆分的方式统称为并行方式，并行计算后的结果重新聚合的方式称为模型更新传递方式。<br>常见的并行方式有：</li><li>数据并行：把数据集切分放到各个计算节点，并在哥哥节点之间传递模型参数</li><li>模型并行：把模型切分放到各个计算节点，并在各个节点之间传递数据。一般把单个算子分配在配置相同的几个硬件上进行模型存储和计算。</li><li>流水线并行：将模型切分成多个阶段，每个阶段在不同的计算节点上进行计算，每个阶段的计算结果传递给下一个阶段。<br>另外，如何更新模型参数也是并行计算的一个重要问题。在硬件组织架构方面，分为参数服务器架构和collective架构。在更新参数方面分为同步和异步更新<a href="https://zhuanlan.zhihu.com/p/350501860">参考内容</a><h3 id="allreduce训练"><a href="#allreduce训练" class="headerlink" title="allreduce训练"></a>allreduce训练</h3>在同步更新参数的训练中，利用AllReduce来整合不同worker的梯度数据。AllReduce有很多种类的实现，主要关注的问题在于不同worker之间传递信息的拓扑结构。例如，对于一个有4个worker的集群，有以下几种拓扑结构：</li><li><strong>ring</strong>：每个worker只和相邻的worker通信</li><li><strong>mesh</strong>：每个worker和所有其他worker通信，但是效率比较低。</li><li><strong>Master-Worker</strong>：一个worker作为master，其他worker作为worker，master和每个worker通信，worker之间不通信。<br>举N个worker的ring结构为例，考察这个结构的工作过程：</li><li>每个worker计算自己的梯度</li><li>每个worker把数据分成N份</li><li>第k个worker把其第k份数据发送给第k+1个worker</li><li>第k个worker把其第k-1份数据和第k-1个worker发送的数据整合，再发给下一个worker</li><li>循环N次之后，每个worker包含最终整合结果的1份</li><li>每个worker把自己的数据发送给下一个worker，收到数据后，每个worker的数据都是最终整合结果<br>这个结构的AllReduce的优势在于发送的数据量是固定的，和worker数量无关，避免了网络拥塞。<a href="https://zhuanlan.zhihu.com/p/100012827">参考内容</a><h1 id="实践内容"><a href="#实践内容" class="headerlink" title="实践内容"></a>实践内容</h1><h2 id="lenet5"><a href="#lenet5" class="headerlink" title="lenet5"></a>lenet5</h2>lenet5是进行手写数字识别的CNN，它的结构如下：<br>输入层-&gt;卷积层-&gt;池化层-&gt;卷积层-&gt;池化层-&gt;全连接层-&gt;全连接层-&gt;输出层（高斯连接）<br>与CNN不同的地方在于，LeNet使用sigmoid函数而非reLU函数。<br>lenet5网络的实现代码如下：<figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LeNet</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(LeNet, self).__init__()<br>        self.conv = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">6</span>, <span class="hljs-number">5</span>), <span class="hljs-comment"># in_channels, out_channels, kernel_size</span><br>            nn.Sigmoid(),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>), <span class="hljs-comment"># kernel_size, stride</span><br>            nn.Conv2d(<span class="hljs-number">6</span>, <span class="hljs-number">16</span>, <span class="hljs-number">5</span>),<br>            nn.Sigmoid(),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)<br>        )<br>        self.fc = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">16</span>*<span class="hljs-number">4</span>*<span class="hljs-number">4</span>, <span class="hljs-number">120</span>),<br>            nn.Sigmoid(),<br>            nn.Linear(<span class="hljs-number">120</span>, <span class="hljs-number">84</span>),<br>            nn.Sigmoid(),<br>            nn.Linear(<span class="hljs-number">84</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, img</span>):</span><br>        feature = self.conv(img)<br>        output = self.fc(feature.view(img.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>))<br>        <span class="hljs-keyword">return</span> output<br><br></code></pre></td></tr></table></figure>这个网络定义了两个部分，一个是卷积层，一个是全连接层。卷积层的输入是一个1通道的图像，输出是一个6通道的图像，卷积核的大小为5*5。全连接层的输入是16*4*4的数据，输出是10个类别的概率。<h2 id="resnet"><a href="#resnet" class="headerlink" title="resnet"></a>resnet</h2>ResNet主要用于解决深度神经网络无法找到更好的解的问题。在深层网络中，梯度消失或爆炸的问题会导致网络无法训练。ResNet通过引入残差块（residual block）来解决这个问题。ResNet将堆叠的几个隐含层作为一个残差块，用残差块拟合的函数从原本的f(x)变为f(x)+x。<br>[4]<a href="https://arxiv.org/abs/1512.03385">HE K, ZHANG X, REN S, et al. Deep residual learning for image recognition[C]. Proceedings of the IEEE conference on computer vision and pattern recognition, 2016:770-778.</a><br>通过每个block中残差路径和shortcut路径的设计，可以实现不同的ResNet网络。事实证明，不断增加ResNet的深度，也没有发生解的退化，反而可以提高网络的性能。因此ResNet可以实现如下的网络结构：<br><img src="https://raw.githubusercontent.com/lianga1/picGo_test/main/3u8Wwj.png" alt="resnet"><h3 id="实际部署"><a href="#实际部署" class="headerlink" title="实际部署"></a>实际部署</h3>残差块类定义如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Bottleneck</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-comment"># 残差块定义</span><br>    extention = <span class="hljs-number">4</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, inplanes, planes, stride, downsample=<span class="hljs-literal">None</span></span>):</span><br>        <span class="hljs-built_in">super</span>(Bottleneck, self).__init__()<br>        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=<span class="hljs-number">1</span>, stride=stride, bias=<span class="hljs-literal">False</span>)<br>        self.bn1 = nn.BatchNorm2d(planes)<br><br>        self.conv2 = nn.Conv2d(planes, planes, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br>        self.bn2 = nn.BatchNorm2d(planes)<br><br>        self.conv3 = nn.Conv2d(planes, planes * self.extention, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br>        self.bn3 = nn.BatchNorm2d(planes * self.extention)<br><br>        self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br><br>        self.downsample = downsample<br>        self.stride = stride<br></code></pre></td></tr></table></figure>ResNet网络定义如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ResNet50</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, block, layers, num_class</span>):</span><br>        self.inplane = <span class="hljs-number">64</span><br>        <span class="hljs-built_in">super</span>(ResNet50, self).__init__()<br><br>        self.block = block<br>        self.layers = layers<br><br>        self.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, self.inplane, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>, bias=<span class="hljs-literal">False</span>)<br>        self.bn1 = nn.BatchNorm2d(self.inplane)<br>        self.relu = nn.ReLU()<br>        self.maxpool = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br><br>        self.stage1 = self.make_layer(self.block, <span class="hljs-number">64</span>, layers[<span class="hljs-number">0</span>], stride=<span class="hljs-number">1</span>)<br>        self.stage2 = self.make_layer(self.block, <span class="hljs-number">128</span>, layers[<span class="hljs-number">1</span>], stride=<span class="hljs-number">2</span>)<br>        self.stage3 = self.make_layer(self.block, <span class="hljs-number">256</span>, layers[<span class="hljs-number">2</span>], stride=<span class="hljs-number">2</span>)<br>        self.stage4 = self.make_layer(self.block, <span class="hljs-number">512</span>, layers[<span class="hljs-number">3</span>], stride=<span class="hljs-number">2</span>)<br><br>        self.avgpool = nn.AvgPool2d(<span class="hljs-number">7</span>)<br>        self.fc = nn.Linear(<span class="hljs-number">512</span> * block.extention, num_class)<br><br><br></code></pre></td></tr></table></figure>在30Epoch后，在测试集的准确度达到了75%。</li></ul><h2 id="BERT"><a href="#BERT" class="headerlink" title="BERT"></a>BERT</h2><p>BERT是基于Transformer的预训练模型，主要用于自然语言处理，它能够预测句子中缺失的词语。以及判断两个句子是不是上下句。<br>整个框架由多层transformer的encoder堆叠而成。encoder由注意力层和feed-forward层组成。<br>BERT中，输入由三种不同embedding组成：</p><ul><li><p>wordpiece embedding：由但词向量组成将单词划分成一组有限公共子词单元。</p></li><li><p>position embedaang：将单词的位置信息编码成特征向量。Transformer通过制定规则来构建一个position embedding</p></li><li><p>segment embedding：用于区分两个句子的向量表示。用于区别问答等非对称子句。</p><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><p>BERT的主要结构是Transformer，Transformer结构如下图所示：<br><img src="https://raw.githubusercontent.com/lianga1/picGo_test/main/20200814234510853.jpg" alt="transformer"><br>其中左侧部分即为encoder部分。<br>encoder单元由一个multi-head-Attention + Layer Normalization + feedforword + Layer Normalization 叠加产生。<br>在比较大的BERT模型中，有24层encoder，每层有16个Attention，词向量维度1024。在较小情况下，有12层encoder，每层12个Attention，词向量维度768。<br>任何时候feed-forward大小都是词向量维度的4倍。</p><h4 id="Attention-Layer"><a href="#Attention-Layer" class="headerlink" title="Attention Layer"></a>Attention Layer</h4><p>这一层的输入是由X &#x3D; (batch_size,max_len_embedding)构成的。<br>单个self-attention 计算过程是输入X分别和三个矩阵Wq,Wk,Wv相乘，得到Q,K,V。然后计算Q和K的点积，再除以$\sqrt{d_k}$，再经过softmax函数，得到attention矩阵。最后将attention矩阵和V相乘即加权求和，得到输出。<br>multi-head-Attention将多个不同的self-attention输出进行拼接，然后再乘以一个矩阵W0，得到最终的输出output_sum &#x3D; (batch_size,max_len,n*w_length)这个结果再经过一个全连接层就是整个multi-head-Attention的输出。</p><h4 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h4><p>这个层相当于对每句话的embedding做归一化，所以用LN而非Batch Normalization</p><h4 id="BERT每一层的学习"><a href="#BERT每一层的学习" class="headerlink" title="BERT每一层的学习"></a>BERT每一层的学习</h4><p>从浅层到深层分别可以学习到surface，短语，语法和语义的信息。</p><h3 id="BERT的训练"><a href="#BERT的训练" class="headerlink" title="BERT的训练"></a>BERT的训练</h3><p>定义几个层的类如下：</p></li><li><p>Embedding：输入的embedding层，包括wordpiece embedding，position embedding，segment embedding</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Embeddings</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(Embeddings, self).__init__()<br>        self.seg_emb = nn.Embedding(n_segs, d_model)<br>        self.word_emb = nn.Embedding(max_vocab, d_model)<br>        self.pos_emb = nn.Embedding(max_len, d_model)<br>        self.norm = nn.LayerNorm(d_model)<br>        self.dropout = nn.Dropout(p_dropout)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x, seg</span>):</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        x: [batch, seq_len]</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        word_enc = self.word_emb(x)<br><br>        <span class="hljs-comment"># positional embedding</span><br>        pos = torch.arange(x.shape[<span class="hljs-number">1</span>], dtype=torch.long, device=device)<br>        pos = pos.unsqueeze(<span class="hljs-number">0</span>).expand_as(x)<br>        pos_enc = self.pos_emb(pos)<br><br>        seg_enc = self.seg_emb(seg)<br>        x = self.norm(word_enc + pos_enc + seg_enc)<br>        <span class="hljs-keyword">return</span> self.dropout(x)<br>        <span class="hljs-comment"># return: [batch, seq_len, d_model]</span><br></code></pre></td></tr></table></figure></li><li><p>Multi-Head-Attention层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">ScaledDotProductAttention</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(ScaledDotProductAttention, self).__init__()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, Q, K, V, attn_mask</span>):</span><br>        scores = torch.matmul(Q, K.transpose(-<span class="hljs-number">1</span>, -<span class="hljs-number">2</span>) / msqrt(d_k))<br>        <span class="hljs-comment"># scores: [batch, n_heads, seq_len, seq_len]</span><br>        scores.masked_fill_(attn_mask, -<span class="hljs-number">1e9</span>)<br>        attn = nn.Softmax(dim=-<span class="hljs-number">1</span>)(scores)<br>        <span class="hljs-comment"># context: [batch, n_heads, seq_len, d_v]</span><br>        context = torch.matmul(attn, V)<br>        <span class="hljs-keyword">return</span> context<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MultiHeadAttention</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(MultiHeadAttention, self).__init__()<br>        self.W_Q = nn.Linear(d_model, d_k * n_heads, bias=<span class="hljs-literal">False</span>)<br>        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=<span class="hljs-literal">False</span>)<br>        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=<span class="hljs-literal">False</span>)<br>        self.fc = nn.Linear(n_heads * d_v, d_model, bias=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, Q, K, V, attn_mask</span>):</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        Q, K, V: [batch, seq_len, d_model]</span><br><span class="hljs-string">        attn_mask: [batch, seq_len, seq_len]</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        batch = Q.size(<span class="hljs-number">0</span>)<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        split Q, K, V to per head formula: [batch, seq_len, n_heads, d_k]</span><br><span class="hljs-string">        Convenient for matrix multiply opearation later</span><br><span class="hljs-string">        q, k, v: [batch, n_heads, seq_len, d_k / d_v]</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        per_Q = self.W_Q(Q).view(batch, -<span class="hljs-number">1</span>, n_heads, d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        per_K = self.W_K(K).view(batch, -<span class="hljs-number">1</span>, n_heads, d_k).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        per_V = self.W_V(V).view(batch, -<span class="hljs-number">1</span>, n_heads, d_v).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br><br>        attn_mask = attn_mask.unsqueeze(<span class="hljs-number">1</span>).repeat(<span class="hljs-number">1</span>, n_heads, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># context: [batch, n_heads, seq_len, d_v]</span><br>        context = ScaledDotProductAttention()(per_Q, per_K, per_V, attn_mask)<br>        context = context.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).contiguous().view(<br>            batch, -<span class="hljs-number">1</span>, n_heads * d_v)<br><br>        <span class="hljs-comment"># output: [batch, seq_len, d_model]</span><br>        output = self.fc(context)<br>        <span class="hljs-keyword">return</span> output<br></code></pre></td></tr></table></figure></li><li><p>其余层，包括FeedForword层和池化层</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FeedForwardNetwork</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(FeedForwardNetwork, self).__init__()<br>        self.fc1 = nn.Linear(d_model, d_ff)<br>        self.fc2 = nn.Linear(d_ff, d_model)<br>        self.dropout = nn.Dropout(p_dropout)<br>        self.gelu = gelu<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        x = self.fc1(x)<br>        x = self.dropout(x)<br>        x = self.gelu(x)<br>        x = self.fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Pooler</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(Pooler, self).__init__()<br>        self.fc = nn.Linear(d_model, d_model)<br>        self.tanh = nn.Tanh()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x</span>):</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        x: [batch, d_model] (first place output)</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        x = self.fc(x)<br>        x = self.tanh(x)<br>        <span class="hljs-keyword">return</span> x<br><br></code></pre></td></tr></table></figure></li><li><p>Encoder层和组合而成的BERT网络</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">EncoderLayer</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-built_in">super</span>(EncoderLayer, self).__init__()<br>        self.norm1 = nn.LayerNorm(d_model)<br>        self.norm2 = nn.LayerNorm(d_model)<br><br>        self.enc_attn = MultiHeadAttention()<br>        self.ffn = FeedForwardNetwork()<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, x, pad_mask</span>):</span><br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">        pre-norm</span><br><span class="hljs-string">        see more detail in https://openreview.net/pdf?id=B1x8anVFPr</span><br><span class="hljs-string"></span><br><span class="hljs-string">        x: [batch, seq_len, d_model]</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        residual = x<br>        x = self.norm1(x)<br>        x = self.enc_attn(x, x, x, pad_mask) + residual<br>        residual = x<br>        x = self.norm2(x)<br>        x = self.ffn(x)<br>        <span class="hljs-keyword">return</span> x + residual<br><br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BERT</span>(<span class="hljs-params">nn.Module</span>):</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self, n_layers</span>):</span><br>        <span class="hljs-built_in">super</span>(BERT, self).__init__()<br>        self.embedding = Embeddings()<br>        self.encoders = nn.ModuleList([<br>            EncoderLayer() <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n_layers)<br>        ])<br><br>        self.pooler = Pooler()<br><br>        self.next_cls = nn.Linear(d_model, <span class="hljs-number">2</span>)<br>        self.gelu = gelu<br><br>        shared_weight = self.pooler.fc.weight<br>        self.fc = nn.Linear(d_model, d_model)<br>        self.fc.weight = shared_weight<br><br>        shared_weight = self.embedding.word_emb.weight<br>        self.word_classifier = nn.Linear(d_model, max_vocab, bias=<span class="hljs-literal">False</span>)<br>        self.word_classifier.weight = shared_weight<br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span>(<span class="hljs-params">self, tokens, segments, masked_pos</span>):</span><br>        output = self.embedding(tokens, segments)<br>        enc_self_pad_mask = get_pad_mask(tokens)<br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.encoders:<br>            output = layer(output, enc_self_pad_mask)<br>        <span class="hljs-comment"># output: [batch, max_len, d_model]</span><br><br>        <span class="hljs-comment"># NSP Task</span><br>        hidden_pool = self.pooler(output[:, <span class="hljs-number">0</span>])<br>        logits_cls = self.next_cls(hidden_pool)<br><br>        <span class="hljs-comment"># Masked Language Model Task</span><br>        <span class="hljs-comment"># masked_pos: [batch, max_pred] -&gt; [batch, max_pred, d_model]</span><br>        masked_pos = masked_pos.unsqueeze(-<span class="hljs-number">1</span>).expand(-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, d_model)<br><br>        <span class="hljs-comment"># h_masked: [batch, max_pred, d_model]</span><br>        h_masked = torch.gather(output, dim=<span class="hljs-number">1</span>, index=masked_pos)<br>        h_masked = self.gelu(self.fc(h_masked))<br>        logits_lm = self.word_classifier(h_masked)<br>        <span class="hljs-comment"># logits_lm: [batch, max_pred, max_vocab]</span><br>        <span class="hljs-comment"># logits_cls: [batch, 2]</span><br><br>        <span class="hljs-keyword">return</span> logits_cls, logits_lm<br><br></code></pre></td></tr></table></figure><p>batch-size设为6<br>训练300个Epoch<br>训练结果进行预测例句<br>结果如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs routeros">========================================================<br>Masked data:<br>[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;[MASK]&#x27;</span>, <span class="hljs-string">&#x27;[MASK]&#x27;</span>, <span class="hljs-string">&#x27;you&#x27;</span>, <span class="hljs-string">&#x27;too&#x27;</span>, <span class="hljs-string">&#x27;how&#x27;</span>, <span class="hljs-string">&#x27;are&#x27;</span>, <span class="hljs-string">&#x27;you&#x27;</span>, <span class="hljs-string">&#x27;today&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>, <span class="hljs-string">&#x27;great&#x27;</span>,<br> <span class="hljs-string">&#x27;my&#x27;</span>, <span class="hljs-string">&#x27;baseball&#x27;</span>, <span class="hljs-string">&#x27;team&#x27;</span>, <span class="hljs-string">&#x27;won&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;competition&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]<br>BERT reconstructed:<br>[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;nice&#x27;</span>, <span class="hljs-string">&#x27;meet&#x27;</span>, <span class="hljs-string">&#x27;you&#x27;</span>, <span class="hljs-string">&#x27;too&#x27;</span>, <span class="hljs-string">&#x27;how&#x27;</span>, <span class="hljs-string">&#x27;are&#x27;</span>, <span class="hljs-string">&#x27;you&#x27;</span>, <span class="hljs-string">&#x27;today&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>, <span class="hljs-string">&#x27;great&#x27;</span>,<br> <span class="hljs-string">&#x27;my&#x27;</span>, <span class="hljs-string">&#x27;baseball&#x27;</span>, <span class="hljs-string">&#x27;team&#x27;</span>, <span class="hljs-string">&#x27;won&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;competition&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]<br>Original sentence:<br>[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;nice&#x27;</span>, <span class="hljs-string">&#x27;meet&#x27;</span>, <span class="hljs-string">&#x27;you&#x27;</span>, <span class="hljs-string">&#x27;too&#x27;</span>, <span class="hljs-string">&#x27;how&#x27;</span>, <span class="hljs-string">&#x27;are&#x27;</span>, <span class="hljs-string">&#x27;you&#x27;</span>, <span class="hljs-string">&#x27;today&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>, <span class="hljs-string">&#x27;great&#x27;</span>,<br> <span class="hljs-string">&#x27;my&#x27;</span>, <span class="hljs-string">&#x27;baseball&#x27;</span>, <span class="hljs-string">&#x27;team&#x27;</span>, <span class="hljs-string">&#x27;won&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;competition&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]<br>===============Next Sentence <span class="hljs-attribute">Prediction</span>===============<br>Two sentences are continuous? <span class="hljs-literal">True</span><br>BERT predict: <span class="hljs-literal">True</span><br></code></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>科研</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>周报</tag>
      
      <tag>课题组</tag>
      
      <tag>神经网络</tag>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于selenium包安装运行的问题排除</title>
    <link href="/2023/09/24/%E5%85%B3%E4%BA%8Eselenium%E5%8C%85%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E9%99%A4/"/>
    <url>/2023/09/24/%E5%85%B3%E4%BA%8Eselenium%E5%8C%85%E5%AE%89%E8%A3%85%E8%BF%90%E8%A1%8C%E7%9A%84%E9%97%AE%E9%A2%98%E6%8E%92%E9%99%A4/</url>
    
    <content type="html"><![CDATA[<h1 id="selenium-包安装"><a href="#selenium-包安装" class="headerlink" title="selenium 包安装"></a>selenium 包安装</h1><p>首先是想要在base环境下安装的，但是因为base环境的内容太多，solve解决依赖问题耗时过长，所以考虑新建环境。</p><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">conda create -n webdriver python=3.7<br>conda activate webdriver<br>conda install selenium<br></code></pre></td></tr></table></figure><h1 id="出现问题"><a href="#出现问题" class="headerlink" title="出现问题"></a>出现问题</h1><p>在按照例程运行代码时，出现了以下问题：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> platform<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> os<br>chromedriver = os.path.abspath(<span class="hljs-string">&#x27;C:\\Users\\18381\\anaconda3\\Scripts\\chromedriver.exe&#x27;</span>)<br>os.environ[<span class="hljs-string">&quot;webdriver.chrome.driver&quot;</span>] = chromedriver<br>driver = webdriver.Chrome()<br></code></pre></td></tr></table></figure><p>出现了以下错误：<br>Unable to obtain driver using Selenium Manager: C:\Users\18381\anaconda3\envs\webdriver\lib\site-packages\selenium\webdriver\common\windows\selenium-manager.exe is missing.</p><p>因此，查阅github上有关issue，发现是conda打包问题，没有打包这个可执行文件。因此，需要手动下载这个文件，放到对应的目录下。<br><a href="https://github.com/SeleniumHQ/selenium/tree/trunk/common/manager">下载文件</a></p><h1 id="其他需要注意的地方"><a href="#其他需要注意的地方" class="headerlink" title="其他需要注意的地方"></a>其他需要注意的地方</h1><p>比如求解器，可以使用新的求解器例如<a href="https://www.anaconda.com/blog/a-faster-conda-for-a-growing-community">libmamba</a><br>虽然我还没完全搞懂这个东西如何使用</p><p>需要先安装chrome和对应的chromedriver<br><a href="https://chromedriver.chromium.org/downloads">chromedriver</a></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>python</category>
      
      <category>web</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>世界观其一</title>
    <link href="/2023/08/20/%E4%B8%96%E7%95%8C%E8%A7%82%E5%85%B6%E4%B8%80/"/>
    <url>/2023/08/20/%E4%B8%96%E7%95%8C%E8%A7%82%E5%85%B6%E4%B8%80/</url>
    
    <content type="html"><![CDATA[<h1 id="写在最前面"><a href="#写在最前面" class="headerlink" title="写在最前面"></a>写在最前面</h1><p>这篇文章主要是在闲极无聊学sql时，看到不同版本sql语法不兼容时感到的一种割裂感，进而想到用ai创作一幅表达我心态的画。从这里又跳跃到，如果在未来，ai创作一幅画仅需要一念，那么对生活又是一种什么样颠覆的改变呢。于是乎，在这种想法的引导下决定试着写一写自己心目中近未来世界的一些简单的世界观。</p><h1 id="居家生活"><a href="#居家生活" class="headerlink" title="居家生活"></a>居家生活</h1><h2 id="房间的装潢"><a href="#房间的装潢" class="headerlink" title="房间的装潢"></a>房间的装潢</h2><p>对于一个生活在不远的未来的人来说，由于世界范围内开源运动与算力共享运动的蓬勃发展，开源软件的交互界面在人工智能辅助设计（AAD）的加持下变得更加易于操作。在房间装潢方面，具有初步功能的脑机接口，可以检测大脑的情绪反应，搭配心理判断系统的语言+画面交互，可以实现对使用者思维中对房间装潢需要的画面进行复现与自动优化，并搭配墙纸（以柔性半主动发光材料制成）进行显示，从而完成房间装潢的快速个性化配置。</p>]]></content>
    
    
    <categories>
      
      <category>写作</category>
      
      <category>科幻小说</category>
      
      <category>近未来主题</category>
      
      <category>世界观</category>
      
    </categories>
    
    
    <tags>
      
      <tag>写作</tag>
      
      <tag>科幻</tag>
      
      <tag>世界观</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-27</title>
    <link href="/2023/07/27/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-27/"/>
    <url>/2023/07/27/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-27/</url>
    
    <content type="html"><![CDATA[<h2 id="赛程"><a href="#赛程" class="headerlink" title="赛程"></a>赛程</h2><p>9-11号作品测评<br>2号早晨7点半到413，放题</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-19</title>
    <link href="/2023/07/19/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-19/"/>
    <url>/2023/07/19/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-19/</url>
    
    <content type="html"><![CDATA[<h1 id="pid控制系统"><a href="#pid控制系统" class="headerlink" title="pid控制系统"></a>pid控制系统</h1><h2 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h2><p>$$ u(t)&#x3D;K_p e(t)+K_i \int_0^t e(\tau) d\tau + K_d \frac{de(t)}{dt} $$</p><h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><ul><li>比例项：减小误差</li><li>积分项：消除稳态误差</li><li>微分项：减小超调量</li></ul><h3 id="超调量"><a href="#超调量" class="headerlink" title="超调量"></a>超调量</h3><p>$$ \xi &#x3D; \frac{e^{-\frac{\pi \zeta}{\sqrt{1-\zeta^2}}}}{\sqrt{1-\zeta^2}} $$<br>超调量的意义在于：在没有积分项的情况下，超调量越大，系统的响应越快，但是超调量越大，系统的稳定性越差<br>其中 $\zeta$ 是阻尼系数，$\zeta$ 越大，超调量越小，系统越稳定</p><h2 id="误差"><a href="#误差" class="headerlink" title="误差"></a>误差</h2><p>低频抖动：积分项过大<br>高频抖动：微分项过大</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>状态量：超声波，速度，MPU6050姿态，</p><h1 id="卡尔曼滤波"><a href="#卡尔曼滤波" class="headerlink" title="卡尔曼滤波"></a>卡尔曼滤波</h1><h2 id="作用-1"><a href="#作用-1" class="headerlink" title="作用"></a>作用</h2><p>利用间接测量值，计算最优估算，组合各种可能受到噪音影响的数据源。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="状态观察"><a href="#状态观察" class="headerlink" title="状态观察"></a>状态观察</h3><p>状态观察是指，通过测量值，计算出状态量的过程，<br>状态观测器得到的估计状态表示为$ \hat{x}  $</p><h3 id="状态预测"><a href="#状态预测" class="headerlink" title="状态预测"></a>状态预测</h3><p>根据数学模型，从已有的状态量，通过计算得到了一个估计量$ \hat{x} $<br>然而，数学模型的预测有其局限性，初值条件不同所以不能得到相同的结果。<br>所以需要状态估算器</p><h3 id="状态估算"><a href="#状态估算" class="headerlink" title="状态估算"></a>状态估算</h3><p>需要估算值收敛到实际值，所以需要反馈，反馈误差为e<br>$$ e &#x3D; x - \hat{x} $$假设一个微分方程：<br>$$ \dot{x} &#x3D; Ax + Bu $$$$ y &#x3D; Cx $$以上是一个真实系统<br>$$ \dot{\hat{x}} &#x3D; A\hat{x} + Bu + Ke$$$$ \hat{y} &#x3D; C\hat{x} $$这是系统估算模型</p><p>两方程分别相减得到：<br>$$ \dot{e} &#x3D;(A- KC)·e$$$$ y-\hat{y} &#x3D; C·e$$<br>解得:<br>$$e(t) &#x3D; e^{A-KC} ·e(0)$$<br>若A-KC的值小于0，那么e(t)会收敛到0，即估算值收敛到实际值，实际上，k可以加速收敛过程。</p><h3 id="例子-1"><a href="#例子-1" class="headerlink" title="例子"></a>例子</h3><p>$$ \dot{x} &#x3D; Ax + Bu + w$$$$ y &#x3D; Cx + v$$<br>w是过程噪声，v是测量噪声，他们都服从高斯分布，且互相独立。<br>在初始条件下，状态估算器估计了$\hat{x}$，真实值在这个中心的正态分布周围<br>在多轮预测后，估计值的分布会比初始条件下的估计分布更大，同时，还有一个测量方程得到的均值与方差都不同的分布，这两个分布的相乘就得到优化估计。<br>事实上，卡尔曼滤波器方程是一个随机系统的状态观测器<br>公式如下：<br>$$ \hat{x}<em>k&#x3D;A·\hat{x}</em>{k-1} +B·u_k +K_k(y_k - C(A·\hat{x}+B·u_k)) $$<br>其中$\hat{x_k^-}$是前项估测，代表前两项的和，所以公式写为：<br>$$ \hat{x}_k^ &#x3D; A·\hat{x_k^-} ++K_k(y_k - C\hat{x_k^-}) $$</p><p>所以结果成为后验估值。</p><p>误差协方差矩阵P<br>$$ P_k^- &#x3D; AP_{k-1}A^T +Q$$<br>这个就是对矩阵P的估值</p><p>第二步，更新状态<br>$$ K_k &#x3D; \frac{P_k^-C^T}{(CP_k^-C^T+R)} $$<br>这个是卡尔曼增益，使得更新K后误差协方差最小<br>$$ P_k &#x3D; (I-K_kC)P_k^- $$</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-18</title>
    <link href="/2023/07/18/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-18/"/>
    <url>/2023/07/18/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-18/</url>
    
    <content type="html"><![CDATA[<h1 id="arduino小车测速"><a href="#arduino小车测速" class="headerlink" title="arduino小车测速"></a>arduino小车测速</h1><h2 id="霍尔编码器"><a href="#霍尔编码器" class="headerlink" title="霍尔编码器"></a>霍尔编码器</h2><h2 id="外部中断"><a href="#外部中断" class="headerlink" title="外部中断"></a>外部中断</h2><p>一个霍尔编码器如果有两个传感器传出两路信号，就能根据相位差同时测量速度和方向<br>但是arduino只有两个硬件中断管脚，同时还要使能计时器中断，所以需要一个外部中断库<br>PinChangeInterrupt库</p><h2 id="定时中断"><a href="#定时中断" class="headerlink" title="定时中断"></a>定时中断</h2><p>atmel内部有三个定时器</p><ul><li>Timer0是delay用的</li><li>Timer1是pwm用的</li><li>只有Timer2可以使用来进行定时中断<br>因此，需要使用MsTimer2库来实现定时中断</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-14</title>
    <link href="/2023/07/14/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-14/"/>
    <url>/2023/07/14/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-14/</url>
    
    <content type="html"><![CDATA[<h1 id="PWM"><a href="#PWM" class="headerlink" title="PWM"></a>PWM</h1><h2 id="通用定时器"><a href="#通用定时器" class="headerlink" title="通用定时器"></a>通用定时器</h2><h3 id="预分频"><a href="#预分频" class="headerlink" title="预分频"></a>预分频</h3><p>通过对时钟频率进行分频，实现了让计数器可以计数更长的时间。</p><h2 id="占空比"><a href="#占空比" class="headerlink" title="占空比"></a>占空比</h2><p>占空比的实现是通过调节计数器到达翻转电平的值的大小来实现的。<br>利用的是计数器的比较功能<br>通过调节一个计数器不同的值，可以同时实现多个pwm的多个占空比的调节。但是他们的频率是相同的，若想要不同频率需要使用不同的计时器。<br>TIM3&#x2F;4通道数较多</p><h2 id="捕获模式"><a href="#捕获模式" class="headerlink" title="捕获模式"></a>捕获模式</h2><p>捕获模式可以用来测量信号的频率，占空比等。</p><h2 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h2><p>打开对应channel的pwm生成，设定预分频和counter值（推荐一个方便运算占空比的值）</p><h2 id="作业"><a href="#作业" class="headerlink" title="作业"></a>作业</h2><ul><li>需要实现通过按键增加占空比</li><li>用捕获模式测量发生的PWM波频率和占空比</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-13</title>
    <link href="/2023/07/13/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-13/"/>
    <url>/2023/07/13/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-13/</url>
    
    <content type="html"><![CDATA[<h1 id="stm32串口通信"><a href="#stm32串口通信" class="headerlink" title="stm32串口通信"></a>stm32串口通信</h1><h1 id="定时器"><a href="#定时器" class="headerlink" title="定时器"></a>定时器</h1><h2 id="通用定时器"><a href="#通用定时器" class="headerlink" title="通用定时器"></a>通用定时器</h2><p>采用apb1&#x2F;apb2总线</p><h3 id="预分频"><a href="#预分频" class="headerlink" title="预分频"></a>预分频</h3><p>计时时长&#x3D; (预分频+1) * (计数器值+1) &#x2F; 时钟频率</p><h3 id="中断回调"><a href="#中断回调" class="headerlink" title="中断回调"></a>中断回调</h3><p>HAL_TIM_PeriodElapsedCallback(TIM_HandleTypeDef *htim)<br>这个函数可以复制到it文件中，定义这个函数即可在中断中调用这个函数。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-12</title>
    <link href="/2023/07/12/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-12/"/>
    <url>/2023/07/12/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-12/</url>
    
    <content type="html"><![CDATA[<h1 id="stm32定时器"><a href="#stm32定时器" class="headerlink" title="stm32定时器"></a>stm32定时器</h1><p>SysTick控制寄存器：<br>在SysTick_Config函数中，需要传进一个参数，代表着多少个tick触发一次中断。这个参数是一个32位的寄存器，但是只有24位有效，因此最大值是2^24-1，也就是16777215，也就是16Mhz的时钟下，最大延时是1s。如果需要更长的延时，需要自己写一个计数器，然后在中断中进行判断。<br>有一个变量是SystemCoreClock，代表当前时钟速度。把这个变量除以多少，就是把一秒分成多少份来计时。<br>在SysTick_Handler这个函数中，每次计时器触发中断都会调用这个函数，可以设置一个静态变量来进行计数，例如每1ms触发中断，就让这个函数每500次进入中断才执行某个行为，就能实现每500ms执行一次某个行为。</p><h1 id="按键中断"><a href="#按键中断" class="headerlink" title="按键中断"></a>按键中断</h1>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-11</title>
    <link href="/2023/07/11/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-11/"/>
    <url>/2023/07/11/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-11/</url>
    
    <content type="html"><![CDATA[<h1 id="stm32-开发"><a href="#stm32-开发" class="headerlink" title="stm32 开发"></a>stm32 开发</h1><h2 id="配置内容"><a href="#配置内容" class="headerlink" title="配置内容"></a>配置内容</h2><p>main.c中的user code 注释中间是不会被cube重新生成的</p><h2 id="时钟树"><a href="#时钟树" class="headerlink" title="时钟树"></a>时钟树</h2><h2 id="第一个hal函数"><a href="#第一个hal函数" class="headerlink" title="第一个hal函数"></a>第一个hal函数</h2><p>HAL_GPIO_WritePin(GPIOF,LED0_PIN|LED1_PIN, GPIO_PIN_SET);<br>HAL_Delay(ms);</p><h2 id="板载按钮"><a href="#板载按钮" class="headerlink" title="板载按钮"></a>板载按钮</h2><p>PE4作为ButtonPin，使能需要一个上拉电阻</p><h2 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h2><p>可以在cube中更改引脚为外部中断，可以调节中断触发模式</p><h1 id="stm32用于clion的诸多问题"><a href="#stm32用于clion的诸多问题" class="headerlink" title="stm32用于clion的诸多问题"></a>stm32用于clion的诸多问题</h1><ol><li>Error: libusb_open() failed with LIBUSB_ERROR_NOT_SUPPORTED<br>初步估计是usb驱动问题，因此计划使用zadig重装驱动，libusb</li><li>Error:Error: timed out while waiting for target halted<br>似乎是在等待重启的过程中超时，难道是没有设置重启？<br><strong>解决了，忘了换配置文件了，老配置文件没问题</strong></li><li>问题又来了，Initfailed，连接不到target，先用的玄学方法：按住rst按键，再烧录，就用这种笨方法至少可以烧录了<br>作为重置方法，接下来有一个比较好的解决方案，就是再cubemx中，pinout设置栏，再systemcore的sys部分里，有一个debug模式选择，之前一直是disable，所以拒绝再外部烧写，现在改成serial wire，就可以了。</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-10</title>
    <link href="/2023/07/10/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-10/"/>
    <url>/2023/07/10/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-10/</url>
    
    <content type="html"><![CDATA[<h1 id="spi与i2c"><a href="#spi与i2c" class="headerlink" title="spi与i2c"></a>spi与i2c</h1><h2 id="iic通信"><a href="#iic通信" class="headerlink" title="iic通信"></a>iic通信</h2><p>i2c是一种用于设备间通讯的两线协议<br>硬件和软件实现都通过machine.I2C和machine.SoftI2C来实现。<br>硬件I2c优势在于速度快，但是对使用的引脚有限制。<br>软件I2C优势在于兼容性强，但是速度慢<br>函数：</p><ul><li>硬件I2C：使用以下参数来构造I2C对象<ul><li>id表示特定的外设，取决于特定板子</li><li>scl：时钟线引脚，Pin</li><li>sda：数据线引脚，Pin</li><li>freq：时钟频率，整数</li></ul></li></ul><p><strong>注意接线先关注缺少的端口例如I2C或uart，之后再关注gpio</strong></p><ul><li>软件I2C：使用以下参数来构造I2C对象<ul><li>scl：时钟线引脚，Pin</li><li>sda：数据线引脚，Pin</li><li>freq：时钟频率，整数</li><li>timeout：超时时间，整数</li></ul></li><li>init函数可以重新定义</li><li>I2C.start()：开始通信</li><li>I2C.stop()：结束通信</li><li>I2C.readint(buf,nack&#x3D;True):读取字节存储到buf中，字节长度是buf长度，收到出最后一个字节以外所有子接后，将发送ack，如果设置nack则发送nack，ack代表着以后还会传输，nack代表着这是最后一个字节</li><li>I2C.write(buf)：将buf中的字节写入到总线上，检查每个字节是否收到ack</li><li>I2C.readfrom(addr,nbytes,stop&#x3D;True):从addr地址读取nbytes个字节，如果stop为True则在输入结束时发送stop信号。</li><li>I2c.readfrom_into(adr,)</li><li>I2c.writeto(addr,buf,stop&#x3D;True)</li><li>I2c.writevto(addr,vector,stop&#x3D;True)将vector中包含的字节写入addr指定的从站，vector应该具有缓冲协议的元组或对象列表</li><li>I2c.readfrom_mem(addr,memaddr,nbytes,addrsize&#x3D;8)从memaddr指定的内存地址开始，从addr指定的从站读出nbytes。参数addrsize以位为单位指定地址大小，返回读取数据bytes对象。</li><li><h3 id="硬件I3c外设"><a href="#硬件I3c外设" class="headerlink" title="硬件I3c外设"></a>硬件I3c外设</h3>任何可用的输出引脚都可以用于scl和sda，默认情况下，I2C对象使用id 0，scl引脚为22，sda引脚为21，时钟频率为400kHz。</li></ul><h2 id="spi通信"><a href="#spi通信" class="headerlink" title="spi通信"></a>spi通信</h2><p>spi是一种由主机驱动的同步串行协议。在物理层概念，一条总线有三条线路组成：SCK，MOSI、MISO，多个设备可以共享一条总线。每个设备有一个单独的第四个信号SS（从设备选择），来选择总线上的特定设备并与之通信。</p><figure class="highlight gml"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs gml">machine.SPI(<span class="hljs-symbol">id</span>)# 在给定的总线<span class="hljs-symbol">id</span>上构造一个SPI对象。<span class="hljs-symbol">id</span>的值取决于特定端口以及硬件<br></code></pre></td></tr></table></figure><h1 id="stm32"><a href="#stm32" class="headerlink" title="stm32"></a>stm32</h1><h2 id="引脚"><a href="#引脚" class="headerlink" title="引脚"></a>引脚</h2><p>在cubemx中，浅黄色是不能修改定义的，深黄色也是默认的。</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>引脚配置，在pinout_configuration中，如下图所示：<br><img src="/2023/07/10/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-10/GPIO_conf.png" alt="引脚配置"><br>可以配置其中每个引脚的功能，例如GPIO、SPI、I2C等等。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-07</title>
    <link href="/2023/07/07/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-07/"/>
    <url>/2023/07/07/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-07/</url>
    
    <content type="html"><![CDATA[<h1 id="串口通信"><a href="#串口通信" class="headerlink" title="串口通信"></a>串口通信</h1><h2 id="串行vs并行"><a href="#串行vs并行" class="headerlink" title="串行vs并行"></a>串行vs并行</h2><p>并行优点：快，效率高<br>缺点：需要端口多<br>串行优点：只需要一个端口<br>缺点：慢，效率低，且需要明确数据拍成一串的规则<br>（大端法vs小端法）</p><h2 id="通信"><a href="#通信" class="headerlink" title="通信"></a>通信</h2><p>串行通信每次只发送一个字节，对于字节内部发送bit的顺序，每个通讯协议都是相同的，但是字节的顺序却不一定相同，这就是大端法和小端法的区别。</p><h3 id="I2C通信"><a href="#I2C通信" class="headerlink" title="I2C通信"></a>I2C通信</h3><p>一个通信口可以和多个设备进行传输，只需要SDA和SCL两个数据线即可，SDA为数据线，SCL为时钟线，时钟线由主设备控制，主设备为发送方，从设备为接收方，从设备的地址由主设备指定，主设备发送数据时，从设备会返回一个ACK信号，表示接收成功，如果没有返回ACK信号，主设备会认为发送失败，重新发送。<br>但是，I2C驱动能力较弱，需要在数据线加上拉电阻，且所有设备必须有不同地址。</p><h3 id="SPI通信"><a href="#SPI通信" class="headerlink" title="SPI通信"></a>SPI通信</h3><p>不需要考虑地址为问题，可以一个Master带多个slave。<br>缺点：每多一个从机，就需要有一个IO口作为片选信号，且需要一个时钟信号，所以需要的IO口较多。</p><h3 id="UART通信"><a href="#UART通信" class="headerlink" title="UART通信"></a>UART通信</h3><p>接线非常简单，且双方对等，谁都可以随时发送信息。<br>缺点：容易接错，且难实现多个设备同时通信。而且功耗较大，所以很多传感器上不配备。<br>波特率：每个位对应时间长度的倒数<br>uart通信有起始位，数据位，校验位，停止位，所以每个字节需要10个bit，所以波特率为115200时，每秒可以传输11520个字节。</p><h4 id="电平标准"><a href="#电平标准" class="headerlink" title="电平标准"></a>电平标准</h4><p>usb标准：看D+和D-的电平差，差大是1，小是0<br>TTL电平：0v是低电平，5&#x2F;3.3v是高电平<br>RS232电平：-3v<del>-15v是低电平，3v</del>15v是高电平</p><h4 id="Arduino的uart"><a href="#Arduino的uart" class="headerlink" title="Arduino的uart"></a>Arduino的uart</h4><p>ttl电平5v<br>1为tx<br>0为rx<br>内部已通过ch340g串口转usb，与usb相连，arduino用uart串口发送信息时，会通过ch340g转换为usb信号，所以可以通过usb接收信息。<br>函数：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Serial</span>.</span></span><span class="hljs-keyword">begin</span>(baudrate)：设置波特率<br><span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Serianl</span>.</span></span>print(content,选项)：发送信息,可以是数字，字符串，数组，对象，选项可以是DEC，BIN，OCT，HEX，BYTE，WORD，FLOAT，STRING，可以指定发送的进制，或者发送字符串。<br><span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Serial</span>.</span></span>println(content,选项)：发送信息，与print不同的是，会在最后加上换行符。<br><span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Serial</span>.</span></span>available<span class="hljs-literal">()</span>：返回接收缓冲区中的字节数<br><span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Serial</span>.</span></span>read<span class="hljs-constructor">Bytes(<span class="hljs-params">char</span>类型数组名，最大读取长度)</span><br><span class="hljs-module-access"><span class="hljs-module"><span class="hljs-identifier">Serial</span>.</span></span>write(<span class="hljs-built_in">char</span>类型数组名，写入长度)：总共能发送数据长度个字节。按照数组中每个原始值诸葛发送，可以借助这个功能，对<span class="hljs-keyword">struct</span>结构体中相关数据作为一个整体，将结构体指针强制转型为byte*类型，后面数据长度用sizeof(<span class="hljs-keyword">struct</span>),这样就可以将结构体作为一个整体发送。<br></code></pre></td></tr></table></figure><h4 id="Arduino的uart工具"><a href="#Arduino的uart工具" class="headerlink" title="Arduino的uart工具"></a>Arduino的uart工具</h4><ul><li>串口绘图仪：可以发送数据时利用数据名：数据的格式，将以时间为横轴，数值为纵轴，根据格式中构成的变量数量，以不同颜色的线段，随时间变化的情况进行绘图。</li><li>BYSerial<br>串口不能同时被多个程序打开。<h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2>基本概念：</li><li>TCP&#x2F;IP协议：定义了设备如何连接如互联网</li><li>TCP：信息必须齐全的网络通信的基础</li><li>UDP：信息可以缺少或者需要广播的网络通信的基础</li><li>IP：计算机之间用于识别身份的临时位置编号</li><li>ICMP：网络控制信号协议</li><li>DHCP：动态分配ip地址协议</li><li>一个能连接互联网的网课出厂自带的编号。<h3 id="ipv4"><a href="#ipv4" class="headerlink" title="ipv4"></a>ipv4</h3>ipv4定义了32位二进制地址<br>同时，ipv4定义了一些只会用于内部网络的地址编号，称为私网ip段，剩下的都是用于全球公网ip。<br>例如</li></ul><p>10.0.0.0-10.255.255.255<br>172.16.0.0-172.31.255.255<br>192.168.0.0-192.168.255.255</p><h3 id="ipv6"><a href="#ipv6" class="headerlink" title="ipv6"></a>ipv6</h3><p>ipv6定义了128位二进制地址</p><h3 id="子网掩码"><a href="#子网掩码" class="headerlink" title="子网掩码"></a>子网掩码</h3><p>子网掩码用于判断ip地址的前几位是网络号，后几位是主机号。<br>32个二进制位表示ip地址截止到哪里，只要相同就认为在同一个子网内，可以直接通信无需交给网关做转发。要求必须1卡头，连续多个1，剩下的是0。255.255.255.0对于这个设备，前面三个点分十进制数相同，那就认为是在同一个网络下，因此会直接连接而不会寻求网关。</p><h3 id="tcp协议"><a href="#tcp协议" class="headerlink" title="tcp协议"></a>tcp协议</h3><p>传输控制协议，是面向连接的，可靠的，基于字节流的传输层通信协议，一个tcp连接需要有：</p><ol><li>在一个网络色悲伤，特定的网络端口如8080（最好大于1023）上开创一个tcp server，这个过程叫做绑定端口，并开始监听端口。</li><li>得到该网络设备的ip地址，因此需要体现获得server的ipv4地址，以及开启tcp监听端口。<h3 id="udp协议"><a href="#udp协议" class="headerlink" title="udp协议"></a>udp协议</h3>无连接的传输协议，成为用户数据报协议<br>udp提供了一个无需链接就能发送封装的ip数据包的方法，建立一套tcp连接需要有：</li><li>在一个网络设备上，特定的网络端口如8080（最好大于1023）上开创一个udp socket</li><li>设定好目的地IP地址和端口便可以随心所欲发送数据</li><li>目的地ip地址对应网络设备B，如果尝试在自己9090端口上开创一个udp socket，且A正好在发送信息，那么此时就能受到A发送的信息。</li></ol><h2 id="wifi连接"><a href="#wifi连接" class="headerlink" title="wifi连接"></a>wifi连接</h2><h3 id="station终端"><a href="#station终端" class="headerlink" title="station终端"></a>station终端</h3><p>新建station</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> network<br>wlan - network.WLAN(network.STA.<span class="hljs-keyword">IF</span>)# <span class="hljs-keyword">create</span> station<br>wlan.active(<span class="hljs-keyword">True</span>)<br>wlan.scan() #scan <span class="hljs-keyword">for</span> acess points(AP)<br>wlan.isconnected() #<span class="hljs-keyword">check</span> <span class="hljs-keyword">if</span> the station <span class="hljs-keyword">is</span> connected <span class="hljs-keyword">to</span> an AP<br><br>wlan.<span class="hljs-keyword">connect</span>(<span class="hljs-string">&#x27;ssid&#x27;</span>, <span class="hljs-string">&#x27;key&#x27;</span>) #<span class="hljs-keyword">connect</span> <span class="hljs-keyword">to</span> an AP<br>wlan.config(<span class="hljs-string">&#x27;mac&#x27;</span>) #<span class="hljs-keyword">get</span> the interfac<span class="hljs-string">e&#x27;s MAC address</span><br><span class="hljs-string">wlan.ifconfig() #get the interface&#x27;</span>s IP/netmask/gw/DNS addresses<br></code></pre></td></tr></table></figure><p>新建AP</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> network<br>ap = network.WLAN(network.AP_IF) # <span class="hljs-keyword">create</span> acess <span class="hljs-type">point</span> interface<br>ap.config(ssid=<span class="hljs-string">&#x27;ESP-AP&#x27;</span>) #<span class="hljs-keyword">set</span> the SSID <span class="hljs-keyword">of</span> the <span class="hljs-keyword">access</span> <span class="hljs-type">point</span><br>ap.config(max_clients=<span class="hljs-number">10</span>) #<span class="hljs-keyword">set</span> how many clients can <span class="hljs-keyword">connect</span> <span class="hljs-keyword">to</span> the <span class="hljs-keyword">access</span> <span class="hljs-type">point</span><br>ap.active(<span class="hljs-keyword">True</span>)<br></code></pre></td></tr></table></figure><p>tcp通讯：</p><ol><li>连接wifi</li><li>获取本地ip</li><li>创建tcp</li><li>绑定本地ip和端口</li><li>设定最大连接数</li><li>配置tcp选项</li><li>用户进入获取用户组</li><li>读取用户信息，</li><li>发送接收到的数据给发送者</li></ol><p>udp通讯：server</p><ol><li>创建socket对象要设置udp模式</li></ol><p>udp通信：client</p><ol><li>判断wifi连接</li><li>发送使用sendto函数</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-06</title>
    <link href="/2023/07/06/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-06/"/>
    <url>/2023/07/06/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-06/</url>
    
    <content type="html"><![CDATA[<h1 id="ESP32"><a href="#ESP32" class="headerlink" title="ESP32"></a>ESP32</h1><h2 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h2><p>中断处理程序不要运行时间过长，不要分配内存</p><h3 id="紧急异常缓冲区"><a href="#紧急异常缓冲区" class="headerlink" title="紧急异常缓冲区"></a>紧急异常缓冲区</h3><p>如果ISR中发生错误，MicroPython无法生成错误报告<br>除非创建特殊缓冲区</p><figure class="highlight elm"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">import</span> micropython<br><span class="hljs-title">micropython</span>.alloc_emergency_exception_buf(<span class="hljs-number">100</span>)<br></code></pre></td></tr></table></figure><h2 id="UART"><a href="#UART" class="headerlink" title="UART"></a>UART</h2><p>esp32有三个硬件UART，分别是UART0，UART1，UART2<br>各自分配了默认GPIO<br>TX：当前设备的发送<br>RX：当前设备的接收<br>串口中不分主从</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">from</span> machine import UART<br><span class="hljs-attribute">uart1</span> = (<span class="hljs-number">1</span>,baudrate=<span class="hljs-number">9600</span>,tx=<span class="hljs-number">33</span>,rx=<span class="hljs-number">32</span>)#指定了id<br><br></code></pre></td></tr></table></figure><p>任何GPIO都可以用于使用GPIO矩阵的硬件UART，除了可以用作rx的仅输入引脚34-39<br>发送与接受的波特率一样</p><p>一种调试方法：不能使用调试器时，可以利用串口输出进行调试。</p><h2 id="ADC"><a href="#ADC" class="headerlink" title="ADC"></a>ADC</h2><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">from machine import ADC<br>adc = <span class="hljs-constructor">ADC(<span class="hljs-params">pin</span>)</span><br><span class="hljs-keyword">val</span> = adc.read<span class="hljs-constructor">_u16()</span><br><span class="hljs-keyword">val</span> = adc.read<span class="hljs-constructor">_uv()</span># <span class="hljs-keyword">to</span> microvolts<br></code></pre></td></tr></table></figure><p><strong>ADC2也被wifi使用，所以开启wifi时会发生adc2异常</strong></p><h2 id="定时器"><a href="#定时器" class="headerlink" title="定时器"></a>定时器</h2><p>Timer.init(*,mode&#x3D;Timer.PERIODIC,period&#x3D;-1,callback&#x3D;None)</p><ul><li>mode 可以是ONE_SHOT或PERIODIC（单次或周期计时）</li></ul><h2 id="PWM"><a href="#PWM" class="headerlink" title="PWM"></a>PWM</h2>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>电赛培训-23-07-05</title>
    <link href="/2023/07/05/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-05/"/>
    <url>/2023/07/05/%E7%94%B5%E8%B5%9B%E5%9F%B9%E8%AE%AD-23-07-05/</url>
    
    <content type="html"><![CDATA[<h1 id="Arduino"><a href="#Arduino" class="headerlink" title="Arduino"></a>Arduino</h1><p>软件：使用Arduino IDE，以C++风格语言编写相关库。<br>利用IDE编译固件下载到Arduino的前提条件是有bootloader程序。<br>所以从程序到固件的关键在于bootloader，其他单片机也可以装载bootloader固件，然后使用arduino库。</p><h2 id="硬件-uno板"><a href="#硬件-uno板" class="headerlink" title="硬件 uno板"></a>硬件 uno板</h2><p>工作电压5v,可以typeB，DC5.5，或者跳线接入<br>共有14个数字输入输出（6个PWM口），6个模拟输入输出</p><h2 id="系统指示灯"><a href="#系统指示灯" class="headerlink" title="系统指示灯"></a>系统指示灯</h2><ul><li>ON：系统指示灯</li><li>RX：接收指示灯</li><li>TX：发送指示灯</li><li>L：内置LED，对应13号数字口<h2 id="开始编写代码"><a href="#开始编写代码" class="headerlink" title="开始编写代码"></a>开始编写代码</h2>有两个一定会有的函数，void setup()和void loop()，分别是初始化和循环函数。<br>setup会执行一次，loop在setup后会自动循环<h3 id="setup函数"><a href="#setup函数" class="headerlink" title="setup函数"></a>setup函数</h3>setup中用pinMode配置管脚模式为输出<br>pinMode(pin编号，INPUT)：高阻态，可认为是100m欧姆，电平不定。<br>pinMode(pinnum,INPUT_PULLUP):内置上拉输入，无外部信号默认高电平。<br>pinMode(pinnum,OUTPUT):输出模式，uno上高电平5v，电流&lt;40mA</li></ul><h3 id="loop函数"><a href="#loop函数" class="headerlink" title="loop函数"></a>loop函数</h3><ul><li>digitalWrite(pinnum,HIGH&#x2F;LOW):输出高低电平，只对output模式有效</li><li>digitalRead(pinnum):读取高低电平,返回HIGH&#x2F;LOW两种电平</li><li>analogRead(anaPinNum)：读取模拟输入电平，返回0-1023的数字，对应0-5v的电压</li><li>analogWrite(pwmPinNum,0-255)：输出PWM波，对应0-5v的电压，频率为490Hz(3,9,10,11pin),或980Hz(5,6pin)</li><li>analogReference(AD参考电压输入来源)：切换AD参考电压输入来源，有默认值，一般不用，可以让输出更加精细。</li></ul><h3 id="中断和轮询"><a href="#中断和轮询" class="headerlink" title="中断和轮询"></a>中断和轮询</h3><p>轮询：不断重复读取某个状态值，缺点是占用资源<br>中断：可以通过某个状态改变来发送信号，然后发送信号后可以执行其他操作，之后再恢复到发送信号之前的状态。<br>管脚中断：attachInterrupt(digitalPinToInterrupt(pinnum),ISR,mode),第一个参数是中断管脚号（uno为2，3），第二个参数是中断服务函数（可以自定义），第三个参数是中断模式，有LOW，RISING，FALLING，CHANGE四种模式。</p><ul><li>LOW：低电平触发</li><li>RISING：上升沿触发</li><li>FALLING：下降沿触发</li><li>CHANGE：任意电平变化触发</li></ul><p><strong>注意，终端服务函数应当很短，而且不能使用其他中断实现的函数，延时需要delayMicroseconds(us)</strong><br><strong>修改全局变量应当用volatile修饰，防止编译器优化</strong></p><h1 id="ESP32"><a href="#ESP32" class="headerlink" title="ESP32"></a>ESP32</h1><h2 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h2><p>esp32-WROOM-32<br>串口芯片：CP2102<br>核心频率240mHz<br>WiFi IEEE 802.11 b&#x2F;g&#x2F;n 2.4GHz<br>BLuetooth 4.2 BR&#x2F;EDR and BLE<br>520k SRAM 448kB ROM<br>2个I2S，RMT远程控制，LED PWM，1个host SD&#x2F;eMMC&#x2F;SDIO，一个slave SDIO&#x2F;SPI. TWAI(CAN),12bitADC,Ethernet</p><h2 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h2><p>MicroPython+Thonny</p><h3 id="常用库"><a href="#常用库" class="headerlink" title="常用库"></a>常用库</h3><h3 id="GPIO"><a href="#GPIO" class="headerlink" title="GPIO"></a>GPIO</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">from</span> machine <span class="hljs-keyword">import</span> Pin<br><br>p0 = Pin(<span class="hljs-number">0</span>,Pin.<span class="hljs-keyword">OUT</span>) # <span class="hljs-keyword">create</span> output pin <span class="hljs-keyword">on</span> GPIO0<br>p0.<span class="hljs-keyword">on</span>() # <span class="hljs-keyword">set</span> pin <span class="hljs-keyword">to</span> &quot;on&quot; (high) <span class="hljs-keyword">level</span><br>p0.<span class="hljs-keyword">off</span>() # <span class="hljs-keyword">set</span> pin <span class="hljs-keyword">to</span> &quot;off&quot; (low) <span class="hljs-keyword">level</span><br>p0.<span class="hljs-keyword">value</span>(<span class="hljs-number">1</span>) # <span class="hljs-keyword">set</span> pin <span class="hljs-keyword">to</span> <span class="hljs-keyword">on</span>/high<br>p0.init(p0.<span class="hljs-keyword">IN</span>,p0.PULL_DOWN) # <span class="hljs-keyword">set</span> pin <span class="hljs-keyword">to</span> <span class="hljs-keyword">input</span> <span class="hljs-keyword">with</span> a pull-down resistor<br></code></pre></td></tr></table></figure><p>init函数中，id是强制的</p><ul><li><p>mode指定引脚模式，有IN，OUT，OPEN_DRAIN，AF_OPEN_DRAIN四种模式</p></li><li><p>pull指定引脚是否连接弱上拉电阻，有None，PULL_UP，PULL_DOWN三种模式<br>弱上拉指上拉电阻阻值较大，高电平很容易因为外部电流驱动而拉低。</p></li><li><p>drive具有不同的最大安全电流的限制，有DRIVE_0-3四种选择</p></li><li><p>alt为引脚的备用功能，仅对alt和alt_open_drain两种模式有效，有0-7八种选择</p></li></ul><p>value函数中，如果不带参数，就是得到当前状态，如果在输出模式，需要带参数，变为设置电平</p><p>配置在引脚的触发源处于活动状态时要调用中断处理程序，如果引脚模式为Pin.IN，可以使用irq函数，如果引脚模式为Pin.IN，可以使用Pin.IRQ_RISING，Pin.IRQ_FALLING，Pin.IRQ_ANY三种模式，分别对应上升沿，下降沿，任意电平变化触发中断。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>电赛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于解决WSL_Ubuntu找不到sys/time.h的问题</title>
    <link href="/2023/05/29/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3WSL-Ubuntu%E6%89%BE%E4%B8%8D%E5%88%B0sys-time-h%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2023/05/29/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3WSL-Ubuntu%E6%89%BE%E4%B8%8D%E5%88%B0sys-time-h%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h1><p>在使用WSL_Ubuntu的时候，编译C代码时，出现了找不到sys&#x2F;time.h的问题</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><h2 id="第一次失败"><a href="#第一次失败" class="headerlink" title="第一次失败"></a>第一次失败</h2><p>网上的一个直接解决方案是安装libc6-dev-amd64<br>但是问题又一次出现，当输入指令<br><code>sudo apt-get install libc6-dev-amd64</code><br>发生报错 unable to locate package</p><h2 id="第二次失败"><a href="#第二次失败" class="headerlink" title="第二次失败"></a>第二次失败</h2><p>于是转而解决无法定位包的问题，根据查找发现需要在&#x2F;etc&#x2F;apt&#x2F;sources.list中添加源,添加了清华源、阿里源后输入<br><code>sudo apt-get update</code><br>更新完成后再次尝试安装libc6-dev-amd64，但是问题依旧存在</p><h2 id="第三次解决"><a href="#第三次解决" class="headerlink" title="第三次解决"></a>第三次解决</h2><p>这次发现libc6-dev-amd64是一个需要在i386架构下安装的包，于是尝试添加i386架构，运行指令<br><code>dpkg --add-architecture i386</code><br>添加成功后再次输入<br><code>sudo apt-get update</code><br>更新完成后再次尝试安装libc6-dev-amd64，问题解决</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>WSL</tag>
      
      <tag>Linux</tag>
      
      <tag>编译</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>电赛学习笔记-机器视觉</title>
    <link href="/2023/05/14/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/"/>
    <url>/2023/05/14/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/</url>
    
    <content type="html"><![CDATA[<h1 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h1><h2 id="安装opencv"><a href="#安装opencv" class="headerlink" title="安装opencv"></a>安装opencv</h2><h2 id="开发板：STM32F407"><a href="#开发板：STM32F407" class="headerlink" title="开发板：STM32F407"></a>开发板：STM32F407</h2><h2 id="IDE：STM32CubeIDE"><a href="#IDE：STM32CubeIDE" class="headerlink" title="IDE：STM32CubeIDE"></a>IDE：STM32CubeIDE</h2><h2 id="配置过程"><a href="#配置过程" class="headerlink" title="配置过程"></a>配置过程</h2><p>配置工程ioc文件，配置好基础外设后，再packs中安装X-CUBE-AI组件包，在软件包外设中添加模型文件，设置压缩倍数，导入测试集验证准确率</p><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><h3 id="yolo"><a href="#yolo" class="headerlink" title="yolo"></a>yolo</h3><p>利用mobilenet yolo50k模型可以导入到单片机中，只需要较少内存即可实现实时运行，实现人脸识别的功能</p><h3 id="openmv"><a href="#openmv" class="headerlink" title="openmv"></a>openmv</h3><h2 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h2><p>正点原子ov7725摄像头<br>yolo50k</p><h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="https://www.bilibili.com/video/BV1Bt411w77m/?share_source=copy_web&vd_source=4ed5c2c0429d7681216f506ac1e74065">稚晖君</a><br><a href="https://github.com/dog-qiuqiu/MobileNet-Yolo">yolo50k仓库</a><br><a href="https://www.bilibili.com/video/BV1FL411u72p/?share_source=copy_web&vd_source=4ed5c2c0429d7681216f506ac1e74065">实时运行案例</a></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>电赛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>电赛学习笔记-micropython</title>
    <link href="/2023/05/14/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-micropython/"/>
    <url>/2023/05/14/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-micropython/</url>
    
    <content type="html"><![CDATA[<h1 id="micropython简介"><a href="#micropython简介" class="headerlink" title="micropython简介"></a>micropython简介</h1><p>micropython是一个能够利用python进行单片机开发的固件，目前主要是在esp32平台上进行的开发</p><h1 id="micropython安装"><a href="#micropython安装" class="headerlink" title="micropython安装"></a>micropython安装</h1><ul><li>在micropython官网找到对应的单片机的型号的固件文件（.bin），下载到对应位置</li><li>pip install esptool</li><li>连接esp32单片机，查看端口号</li><li>根据micropython官网的指示，利用esptool.py文件，清除单片机flash，再部署固件到单片机。</li><li>安装uPyCraft IDE，选择好开发板类型和端口号后，<h1 id="micropython使用"><a href="#micropython使用" class="headerlink" title="micropython使用"></a>micropython使用</h1>需要根据单片机自带的库函数，进行python文档的开发<h1 id="micropython的优点"><a href="#micropython的优点" class="headerlink" title="micropython的优点"></a>micropython的优点</h1>代码量少，配置简单</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>电赛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>电赛学习笔记（1）——stm32学习笔记</title>
    <link href="/2023/05/11/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/"/>
    <url>/2023/05/11/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="stm32基础"><a href="#stm32基础" class="headerlink" title="stm32基础"></a>stm32基础</h1><h2 id="关于stm32产品线"><a href="#关于stm32产品线" class="headerlink" title="关于stm32产品线"></a>关于stm32产品线</h2><h3 id="stm32f1系列-cortex-m3"><a href="#stm32f1系列-cortex-m3" class="headerlink" title="stm32f1系列 cortex-m3"></a>stm32f1系列 cortex-m3</h3><h3 id="stm32f4系列-cortex-m4"><a href="#stm32f4系列-cortex-m4" class="headerlink" title="stm32f4系列 cortex-m4"></a>stm32f4系列 cortex-m4</h3><ul><li>内置了rgb lcd驱动</li><li>加入了DSP与FPU模块<h3 id="stm32f7系列-cortex-m7"><a href="#stm32f7系列-cortex-m7" class="headerlink" title="stm32f7系列 cortex-m7"></a>stm32f7系列 cortex-m7</h3></li><li>高速内存得到应用 <h2 id="寄存器编程"><a href="#寄存器编程" class="headerlink" title="寄存器编程"></a>寄存器编程</h2></li></ul><p><strong>关键字volatile</strong>需要在声明寄存器变量的时候添加，因为要防止编译器自行优化。</p><h2 id="HAL库"><a href="#HAL库" class="headerlink" title="HAL库"></a>HAL库</h2><p>硬件抽象层，可以将不同产品线的芯片的寄存器操作抽象为函数，方便移植<br><strong><font color="red">本笔记使用HAL库进行编程</font></strong><br>相对的，HAL库会产生大量的判断来降低代码运行效率<br>但是，还有另一个Low Layer库（LL），这个库可以提高效率</p><h2 id="stm32cubeMX配置"><a href="#stm32cubeMX配置" class="headerlink" title="stm32cubeMX配置"></a>stm32cubeMX配置</h2><h2 id="stm32计时器"><a href="#stm32计时器" class="headerlink" title="stm32计时器"></a>stm32计时器</h2><h3 id="PWM调制输出"><a href="#PWM调制输出" class="headerlink" title="PWM调制输出"></a>PWM调制输出</h3><h4 id="几个重要参数"><a href="#几个重要参数" class="headerlink" title="几个重要参数"></a>几个重要参数</h4><ul><li>占空比：高电平占整个周期的比例</li><li>频率：整个PWM周期的倒数</li><li>分辨率：占空比变化步长 <h4 id="PWM实现方法"><a href="#PWM实现方法" class="headerlink" title="PWM实现方法"></a>PWM实现方法</h4>输出比较模式，依靠内部计数器cnt和ccr设置的数值的比较来进行输出电平的控制，常用的有匹配时电平翻转和PWM模式<br>PWM占空比：$$DutyCycle&#x3D;\frac{CCR}{ARR}$$<br>PWM频率：$$Freq&#x3D;\frac{F_{clk}}{ARR}$$<br>PWM分辨率：$$Resolution&#x3D;\frac{ARR}{2^{n}}$$<h4 id="高级定时器"><a href="#高级定时器" class="headerlink" title="高级定时器"></a>高级定时器</h4>死区生成：可以避免推挽电路上下管同时打开导致短路<h3 id="PWM控制电机"><a href="#PWM控制电机" class="headerlink" title="PWM控制电机"></a>PWM控制电机</h3>舵机是根据pwm信号控制舵机转动角度的，内部有直流电机<h4 id="电机驱动芯片"><a href="#电机驱动芯片" class="headerlink" title="电机驱动芯片"></a>电机驱动芯片</h4>利用H桥，可以控制电机转动方向。四个开关管可以构成两个推挽电路，使得电机可以获得两个方向的电流。<br>电机需要的电源一般是大功率的，不能直接通过gpio驱动，因此可以通过让stlink的5v口接入电机驱动芯片来获得电源。但是注意，pwm信号的地应当和电机电源的地相连，否则会出现电平不稳定的情况。<h3 id="PWM代码"><a href="#PWM代码" class="headerlink" title="PWM代码"></a>PWM代码</h3>pwm的激活结构如下：<br><img src="/2023/05/11/%E7%94%B5%E8%B5%9B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%881%EF%BC%89/PWM_Structure.jpg" alt="PWM_Structure"></li><li>RCC开启时钟</li><li>配置时基单元</li><li>配置输出比较单元</li><li>配置GPIO，设置为复用推挽输出</li><li>运行控制，启动计数器<h4 id="TIM库函数"><a href="#TIM库函数" class="headerlink" title="TIM库函数"></a>TIM库函数</h4>在hal库中，tim相关库函数在stm32f1xx_hal_tim.h文件中<br>其中有关输出比较的内容有：</li><li>TIM_OC_InitTypeDef: 输出比较初始化结构体</li><li>HAL_StatusTypeDef HAL_TIM_OC_Init(TIM_HandleTypeDef *htim)：输出比较初始化函数</li><li>HAL_StatusTypeDef HAL_TIM_OC_ConfigChannel(TIM_HandleTypeDef *htim, TIM_OC_InitTypeDef *sConfig, uint32_t Channel)：配置输出通道函数</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>电赛</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>电赛</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于计算机所代表的理性世界的真实性讨论</title>
    <link href="/2023/02/11/%E5%85%B3%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%89%80%E4%BB%A3%E8%A1%A8%E7%9A%84%E7%90%86%E6%80%A7%E4%B8%96%E7%95%8C%E7%9A%84%E7%9C%9F%E5%AE%9E%E6%80%A7%E8%AE%A8%E8%AE%BA/"/>
    <url>/2023/02/11/%E5%85%B3%E4%BA%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%89%80%E4%BB%A3%E8%A1%A8%E7%9A%84%E7%90%86%E6%80%A7%E4%B8%96%E7%95%8C%E7%9A%84%E7%9C%9F%E5%AE%9E%E6%80%A7%E8%AE%A8%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="写在这里的原因"><a href="#写在这里的原因" class="headerlink" title="写在这里的原因"></a>写在这里的原因</h1><p>我刚刚在看关于量子计算机的推送时。因为那个推送里说到，数字计算机需要大量参数参与运算的一个漫长的过程，能够被一个模拟计算机（甚至例如两球相撞）在一瞬间解决出来，并且能够以高得多的精度呈现。因此不考虑量子计算的真实内容（是根据量子定律的量子比特和量子纠缠进行计算，而不是依靠量子的物理性质进行模拟过程），我在想的是，我最近如此沉迷于计算机的世界，这个虚拟的世界真的能给我提供等同于现实生活的精神支持吗？</p><p>这个问题并不适合在日记中讨论，因此我写在这里。</p><h1 id="关于这个问题"><a href="#关于这个问题" class="headerlink" title="关于这个问题"></a>关于这个问题</h1><h2 id="我的第一个念头"><a href="#我的第一个念头" class="headerlink" title="我的第一个念头"></a>我的第一个念头</h2><p>我想到的是，真实世界的一举一动，一个石头落地，一些劳动的技巧，是计算机不能以相同的效率模拟出来的，所以真实世界的物质是无可替代的</p><blockquote><p>在这里引出另一个想法，那就是，计算机世界，是完全数字化的，那么是否可以在某种程度上，认为这是一个纯粹理性的世界。关于这个想法在后面应该怎么用，我还会加以叙述的。</p></blockquote><p>然后我想到的就是，虚拟的世界，是只能让我们玩我们已经有的知识的，给予不了我们完全新的知识<br>但是这个叙述不正确，因为我又想到了纯粹理性的问题，那么就是说，我们可以创造新的东西，只不过我们不能像在真实世界一样发现东西罢了。<br>那么，在计算机这个纯粹理性的世界中，如果有一个人，从生下来就只能坐在电脑前玩电脑，他所创造的东西，假设他具有纯粹理性，那么，他就是能在此基础之上创造诸如线性时间选择算法，矩阵运算，语义网络等等的计算机内容，他创造的整个世界，其实是能够完备的。</p><p>而且，发现东西，只不过是经验主义的产物而已，纯粹理性建构的世界会是更好的</p><p><font size="6" color="Red"> <strong>但是，不存在更好的世界!</strong> </font></p><p>如果说计算机是一个世界的话，那么这个虚拟的纯粹理性世界，本身就是物质构成的，这种模拟到数字的转化，本身就是一个物质性的过程。<br>如果不考虑外部的物质性，那么计算机本身能否创造计算机本身呢？也就是说他能不能具有完备性呢？<br>我有一个观点就是，作为本源的代码，是不可能再逆向出来实现代码的硬件逻辑的。无论如何，他所构建的世界，是基于现象（在计算机的虚拟世界里就是代码）创造的，人在现实世界中，创造的一个虚拟世界（计算机），也是基于他在现实世界中探索所得的。所以我们可以说，物质世界本身才是纯粹理性诞生的地方。纯粹理性的应用只不过是试图将其从原本的物质世界剥离出来，从而进行更深一步的抽象的一个产物。</p><p>所以，物质世界，我们所呼吸的这个物质世界，他的奥秘的发掘，是一个非常有意义的工作。世界的物质性，和纯粹理性的（被）延拓性。二者是递归并存的。</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>正则表达式</title>
    <link href="/2023/02/05/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <url>/2023/02/05/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="ABOUT-REGEX"><a href="#ABOUT-REGEX" class="headerlink" title="ABOUT REGEX"></a>ABOUT REGEX</h1><h2 id="BASIC-GRAMMAR"><a href="#BASIC-GRAMMAR" class="headerlink" title="BASIC GRAMMAR"></a>BASIC GRAMMAR</h2><ol><li>A simple example<blockquote><p>^[0-9]+abc$</p></blockquote></li></ol><p>这个是如下意义：<br>(1) ^is the start of the original string.<br>(2) [0-9]+ can match multiple numbers, if without +, it will match only ONE number<br>(3) abc$ match the number ‘abc’ and end with it, $ means the end of the match string</p><p>So the ^ and $ char refers to the range of regex .<br>And the [] can contain the things we need to match. Such as the a-z 0-9 _ - and so on.<br>But elements without [] refers to the strict match of the string.</p><ol start="2"><li>The next step</li></ol><ul><li>char + : For example, there is a Zion+b , it means that there is a Zion and some other chars and finally a ‘b’.</li><li>char * : It is similar to * but the char in front of the * can appear any times.</li><li>char ? : It means the char in front of the ‘?’ can exist at most 1 time</li></ul><ol start="3"><li>The normal characters</li></ol><ul><li>range in the []:<ul><li>[ABC]: match the characters in it, dont need to be successive</li><li>[^ABC]: match the characters not in it.</li><li>[A-Z]: match the characters in the range of it</li><li>. : match any character which is not the blank character.</li><li>[\s\S]: match anything, \s means blank char, \S means not-blank char.</li><li>\w : equals to [A-Za-z0-9_]</li></ul></li></ul><ol start="4"><li>The transform characters</li></ol><ul><li><p>unprinted characters:</p><ul><li>\cx: match the control chars pointed by x. For example, \cM matchs a Control-M or a return, x should be in range of A-Za-z</li><li>\f :match a turn-page char. equals to \x0c and \cL</li><li>\n :matches a next-line char</li><li>\r :matches a return char</li><li>\t :a table char</li><li>\v :a virtical table char, the same as \x0b and \cK</li></ul></li><li><p>particular characters:</p><ul><li>$: match the end of the original string.</li><li>(): mark the range of a sub-expression.</li><li>+: match the expression before more than 1 time.</li><li>{: mark the range of the restricted-char expression</li><li>|: point out the choice between two options</li></ul></li><li><p>restricted-char:</p><ul><li>{n}: n means match the char n times, o{n} means match ‘o’ n times</li><li>{n,}: means match at least n times</li><li>{n,m}: means match not less than n and not more than m times;</li><li>?: it will match the char 1 time and restrict the * and + to not greedy</li></ul></li><li><p>locational char:</p><ul><li>^: match the beginning of the original word</li><li>$: match the ending of the original string. If the mutiline is true, $ will match the chars in front of the \n chars</li><li>\b: match a edge of a word </li><li>\B: doesn’t match the edge of the word</li></ul></li></ul><ol start="5"><li><p>choose<br>use () to contain all options, divide the adjacent options by |<br>For example, a regex like “&#x2F;([1-9])([a-z]+)&#x2F;g” can match the string correspond with two requirements above.<br>however, the matched strings will be stored in buffer.<br>One solution is to use the ?: char in front of the first () .</p></li><li><p>presearch character</p></li></ol><ul><li>?&#x3D; means find the matched string in front of the marked string. exp1(?&#x3D;exp2) means find the exp1 which is in front of the exp2</li><li>?&lt;&#x3D; means find the matched string behind the marked string. (?&lt;&#x3D;exp2)exp1 means find the exp1 which is behind the exp2</li><li>?! means find the matched string which doesn’t have the marked string on the back. exp1(?!exp2) means find the exp1 which is not followed by the exp2</li><li>?&lt; ! means find the matched string without the marked string in the head. (?&lt; !exp2)exp1<br>means find the exp1 without a previous exp2 next to it.</li></ul><ol start="7"><li>ornamental characters</li></ol><ul><li>i:means ignore the capitalization of the expression</li><li>g: find all the matched string</li><li>m: match the exps with ^$ in multiple lines</li><li>s: make the . char can match \n character\</li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2022.10.27随笔</title>
    <link href="/2022/10/27/2022-10-27%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/10/27/2022-10-27%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<p>如今我踽踽独行，但我并不担忧，倘若我能留下一丝痕迹，我便永远不会孤独<br>希望你我可以一同在林中漫步</p><h1 id="好久不见"><a href="#好久不见" class="headerlink" title="好久不见"></a>好久不见</h1><p>我回来了，但是我又怎能说我离开了呢。<br>五个月，是2022被荒废的证据呢，还是让我飞翔的证据呢<br>无论如何，我热爱劳动了</p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.5.2随笔</title>
    <link href="/2022/05/03/2022-5-2%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/05/03/2022-5-2%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<p>今天要用速度写作的方式</p><p>我在想什么？我在想善行与恶行。</p><h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>善行总是比恶行走得远<br>  出处我忘了</p></blockquote><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>爱也好，正义也好，或是人世间的美好品质，都应该是基于一个什么样的目标呢？<br>或者说是基于什么样的品质呢？</p><p>我希望是进步。<br>Enterprise 进取</p><p>如果没有进取，一切都将死亡。死亡将会是最安宁最寂寞最稳定的。<br>没有获得也没有失去。</p><p>即便进取意味着牺牲。为了爱的牺牲<br>与死亡<br>差别在哪里？</p><p>差别在进取。<br>我不是在急躁。<br>我是在跑步，我奔跑在田野。</p><p>我不害怕失去这一切，但是我也不会轻易放弃<br>如果为了更进一步的话。<br>我认为牺牲了几乎一切，并不是赌博<br>而是一种必然的选择。</p><p>康德说你有自由</p><p>我用这个自由来束缚自己<br>把自己绑在前进的激流中！</p><p><img src="/2022/05/03/2022-5-2%E9%9A%8F%E7%AC%94/foust.png" alt="只要努力，难免犯错误"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>你好5月</title>
    <link href="/2022/05/01/%E4%BD%A0%E5%A5%BD5%E6%9C%88/"/>
    <url>/2022/05/01/%E4%BD%A0%E5%A5%BD5%E6%9C%88/</url>
    
    <content type="html"><![CDATA[<p>早上好！以防我见不到你们，下午好，晚上好以及晚安！</p><p>我猜我大概就是想要这样的心态吧。虽然如此，但是我依旧不认为我能够开心地度过最近的日子</p><h2 id="与其说是开心，不如说是能不能熬过"><a href="#与其说是开心，不如说是能不能熬过" class="headerlink" title="与其说是开心，不如说是能不能熬过"></a>与其说是开心，不如说是能不能熬过</h2><p>抱歉，在五月的一开始就这么垂头丧气，但是对于我来说，今天并不是五月的第一天，也不是4月的最后一天，不是任何一个特殊的日子，只是我呆在封闭的校园封闭的楼中的一天。</p><p>谢谢关心，但是连疲惫都没有实感的人，怎么会有因为得到了关心而感到的快乐呢？</p><p>在水群时，很快乐吧<br>但是然后呢？<br>睡不着觉的还是我<br>不想起床的还是我</p><p>是的，我大概是已经抗拒起床了</p><p>人间四月芳菲尽<br>我想，四月份对谁来说都是难过的吧</p><p>这是一种隐藏在深厚的云层以外的忧愁<br>晴天时它隐藏在无尽的深邃中<br>夜晚使它弥漫在窗外</p><p>但无论如何，那种腐败的味道无时无刻不提醒着我们它的存在。</p><p>每个人都应当有一种特殊的能力<br>那就是看到平时看不到的东西的能力<br>我看到了什么？<br>满地的樱花，在腐朽的香气中，提醒了我<br>“自由不是理所应当，自由不是触手可及”</p><p>但是，自由是什么<br>关于这个问题，却是离自由越远，越看得清楚<br>离自由越远，就离真相越近，就离对现实的解构越近。<br>当我们解构了现实时，就能看到远远超出了目光所能及的范围的那些事物。</p><p>你好吗？五月<br>如果你好，我希望你不好<br>如果你不好，我希望你能过得至少快乐一点。</p>]]></content>
    
    
    
    <tags>
      
      <tag>月历</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.29随笔</title>
    <link href="/2022/04/30/2022-4-29%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/04/30/2022-4-29%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>“我爱你，就像我爱我们为之奋斗的一切。我爱你，就像我爱自由、尊严和所有的人都有工作而不致挨饿的权利。我爱你，就像我爱所有那些已牺牲的同志。”<br>  ——《丧钟为谁而鸣》三十一章</p></blockquote><p>嗯，说实话，我认为这种表白是虚伪的。<br>是太过理想化，是一种不愿意多思考的表白。<br>你不是在为了你的爱人而奋斗。你所奋斗的是你和爱人所共同拥有的未来。<br>在爱情中，牺牲永远是不理智的。<br>但是为了你的崇高事业，牺牲却是经常难以避免的。</p><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>围棋是个游戏，没错，而且很有意思。<br>它最需要的是什么呢？<br>首先，肯定不是阿尔法狗。<br>因为这个游戏是服务人类的，它的诞生本身就不是为了挑战机器而存在。</p><p>那么，对于人类而言，挑战这个游戏，最需要什么呢？</p><p>柯洁之所以是柯洁，应该是因为他确实是天才。</p><p>然后呢？</p><p>柯洁之所以是柯洁，还有一个原因<br>是围棋就是围棋。</p><p>围棋为什么是围棋呢？<br>是因为除了一个柯洁，还有无数个九段，八段<br>还有无数个路边的人，还有无数个看棋谱下棋的人。</p><p>这又是怎么回事呢？<br>是专注。<br>从一而终的专注成就了这个游戏注定被无数人追捧。</p><p>正是由于无数人的追捧，才有了这个游戏永久以来的进步，<br>打法推陈出新，天才一浪接一浪</p><p>所以说，天才战胜了对手<br>但是，庸才战胜了游戏。</p><p>我不妨把话说的再明白点。<br>小时候，我们可能只有一个游戏可以玩。<br>可能是一副象棋<br>可能是一个psp上的游戏<br>也有可能是一本书</p><p>那个是我们终生的巅峰<br>再也不会有一个游戏<br>我们会玩得更好了<br>也再也不会有一个游戏<br>我们能从中获得这么多的快乐了</p><p>所以说，童子功<br>就是因为一个孩子认识的有限的世界中<br>这是他唯一的天地。</p><p>长大之后，我们可以玩更多的游戏了，但是我们永远不会再找到那种乐趣的万分之一。</p><p>这两件事有什么关系吗？</p><p>嗯</p><p>有时候，我们想要战胜什么，就必须把它当成唯一的东西<br>这点，只有庸才能做到了。<br>幼稚，是一种不平凡的平庸。<br><img src="/2022/04/30/2022-4-29%E9%9A%8F%E7%AC%94/eve.png" alt="浴火银河2，诞生了我心中永远的太空题材"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.28随笔：小智慧与大聪明</title>
    <link href="/2022/04/29/2022-4-28%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/04/29/2022-4-28%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>没有付出劳动的一天，就是在吞噬之前某一天的成果<br>  ——我说的</p></blockquote><p>你猜我为啥今天没有引用别人的句子</p><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>如题，小智慧与大聪明<br>我们总能看见小聪明和大智慧<br>其实本来也是这样的<br>但是聪明的人是不是也能有着很深刻的思维以及很广阔的视野呢？<br>而那些明哲之人，是否仅仅关注于保身这样的事物？</p><p>我相信，耳聪目明，自从亘古以来<br>绝对是一个褒义词。<br>是月满则亏，水满则溢这个“歪曲的真理”<br>让聪明必然带上一些贬低的意味。</p><p>有时候，大聪明是很难做到的。<br>就好像挖掘机提取细胞核一样<br>让人觉得：这小子是个聪明人啊，别说，我还有点嫉妒了。</p><p>但是呢，却让人在磨合中不讨厌这个人。甚至喜欢这种人了</p><p>原因在于：长久的思考，清晰的逻辑，热心的学习</p><p><font size="6" color="Red"> <strong>即是，博学而笃志，切问而近思</strong> </font></p><p><img src="/2022/04/29/2022-4-28%E9%9A%8F%E7%AC%94/athens.jpg" alt="我真切的祝愿我的学校，复旦大学，可以成为培育真正的人类群星的地方"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.27随笔</title>
    <link href="/2022/04/27/2022-4-27%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/04/27/2022-4-27%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<p>昨日断更一天，本来是想要调整作息早睡觉的，结果还是躺床上失眠到两点半，笑死</p><h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>除了思想，什么是“我”呢？<br>  ——胡适</p></blockquote><p>面对威权，我们可以不屈。<br>我们可以慷慨赴死。<br>我们可以沉默一生。<br>我们也可以屈服，趋炎附势。<br>可是，总有人是和我们做出不同的选择的，<br>威权不会死亡。愤怒般的正义也不会。<br>正如完全的正义从未活过一样。</p><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>如何专注的思考呢？<br>首先要明确要思考的问题<br>在客观上排除干扰思考的因素<br>主观上摒弃思绪中跑偏的部分</p><p>保持身心健康<br>忍耐除了问题本身以外的一切</p><p>在平时要积累知识，<br>在思考时要尽力使用知识</p><p>善于将问题分解而非延申<br>记录子问题<br>再逐一回答。</p><p>坚持一次思考完成<br>不要思考一半就结束。</p><p>即时整理成文字归档。<br>过一阵再去阅读一遍。<br>将其形成一个新的问题</p><p>所以这就是为什么深夜不适合写作<br>深夜会让人思绪不平静<br>因此难以想出真正“哲学”的想法</p><p>东方有哲学吗？我不好说，胡适也不好说</p><p>但是哲学的思考，我更喜欢逻辑性很强的哲学。</p><p>因为这是唯一一种，和知识的本质接轨的东西<br>那就是打破垄断与威权。</p><p><img src="/2022/04/27/2022-4-27%E9%9A%8F%E7%AC%94/hushi.jpg" alt="向未来的自由致敬，向开创未来的人致敬"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.25随笔</title>
    <link href="/2022/04/25/2022-4-25%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/04/25/2022-4-25%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>Resisitry fortificar es vencer<br>继续抵抗，加强防御，就是胜利</p></blockquote><p>死没什么了不起，他心中没有死的图景，也没有对死的惧怕。但是活在世上，就像山坡上一片麦浪在风中荡漾。活在世上，就像一只苍鹰在天空中飞翔。活在世上，就像打麦时麦粒和秣屑飞扬中喝一陶罐水。活在世上，就像两腿夹着一匹马儿，一条腿下夹着一支卡宾枪，经过一个山冈，一个河谷，一条两岸长着树木的小溪，奔向河谷另一头以及远方的山冈。</p><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>人经常是害怕改变的，主要是害怕改变后将要面对的，未知的事物。<br>但是，懦弱的温床正是勇气的绝壁。<br>面临失败时，会让人感到烦躁，这种烦躁将会变成愤怒。<br>这是一种常情。<br>人是厌恶愤怒的，厌恶到想要想尽一切办法远离他<br>但是对愤怒的逃离，就会产生懦弱。</p><p>谁能接受失败？</p><p>无所谓者？还是真正的勇者？</p><p>人生本来就不是理所应当的。成功也好，失败也好。<br>遇上了的，并非必然。</p><p>有时候，宿命会让我们犹豫<br>人生到底是不是一个循环呢？<br>我们不挣扎，结局不过是灭亡<br>挣扎了，又要挣扎到什么时候呢？</p><p>未来是不可知的，有时却是可知的。</p><p>我们在面对未知的勇气和面对已知的退缩间徘徊。<br>只不过是无知和假装的有知罢了。</p><p>我现在，只有现在了。<br>只有现在能让我知道我在做什么，而且能让我行动。</p><p>除此之外，都不应该是生，而应该是死的范畴。</p><p><img src="/2022/04/25/2022-4-25%E9%9A%8F%E7%AC%94/Hemingway.jpg" alt="一个人可以被毁灭，但不会被打败"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.24随笔</title>
    <link href="/2022/04/24/2022-4-24%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/04/24/2022-4-24%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<p>夏天要到了吧……</p><h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>“我必须是你的头脑保持清醒，因为，如果你的头脑不是绝对清醒，你就没权做你在做的事，因为这一切都是犯罪。”<br>“谁也没权夺别人的生命，除非为了防止其他人遭到更大的不幸。所以头脑要清醒，别骗你自己啦。”<br>《丧钟为谁而鸣》第二十六章</p></blockquote><p>清醒，才有实存<br>倘若幻想中能生发平时见不到的风景。<br>那么，我会欣赏，记下来。<br>然后在清醒时将其实现。<br><img src="/2022/04/24/2022-4-24%E9%9A%8F%E7%AC%94/van.jpg" alt="谁敢在不清醒的时候，留下传世之物？"></p><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>逐渐的，我开始变得不畏惧了<br>但是，冒进会不会是一个问题呢？<br>我现在无法做出回答。</p><p>我能想到的仅仅是，在一支舞中</p><p>节奏与配合，很重要<br>毕竟你没法和一只公牛跳舞</p><p>但是，只有公牛一样的人，才能起身前往舞池。</p><p><img src="/2022/04/24/2022-4-24%E9%9A%8F%E7%AC%94/dance.jpg" alt="节奏，把握住这个节奏！"></p><p>我决定不再深夜写博客了，对身体不好，也容易让思想跑偏</p><p>倘若，我没能让自己成功地把握住节奏，那么，失败是必不可少的。<br>但是，碰壁不是为了圆滑，而是为了塑造<br>你究竟是什么样子的呢？取决于刻刀<br>但是，从璞开始，每刻一刀，就会少点东西，具体是什么形态，最终的成品<br>需要一定的规划，也需要一定的机遇<br>本色是一个基础吧，还是得看雕刻的<br>尽本色，是说让刻刀顺着形态走</p><p>嗯，说了不少废话，但是也懂了不少</p><p>再说一句吧，失去是人生的主旋律<br>没有失去的人生，就是没有雕刻的人生</p><p><img src="/2022/04/24/2022-4-24%E9%9A%8F%E7%AC%94/jade.jpg" alt="封校前在上博看到的，雕刻真的是巧夺天工"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.23随笔</title>
    <link href="/2022/04/23/2022-4-23%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/04/23/2022-4-23%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<p>抱歉，断更了一天，没什么好解释的</p><h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>“怎么不？他要不十分能干，昨天晚上就送命了。依我看，你不懂政治，英国人，也不懂游击战。”<br>“在政治和游击战中，首要问题是能继续活下去。瞧他昨晚就这样继续活下来了。我和你讲了这么多难听的话，他始终忍气吞声。”</p></blockquote><p>天才可以死的光彩，蠢人才能活得长。<br>你若是一颗流星，是否愿意在坠落后依旧存在？<br>还是说，你想在天空燃尽自己？</p><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>如果我说，我的梦想仅仅是平凡的过一辈子，未免落入俗套<br>并不是最浅薄的落俗，而是，众多怀抱希望之人，终究会认为平凡的生活是一件美妙之事</p><p>说实话，这样的梦想，是一种毁灭性的辜负。</p><p>如果我怀抱梦想，免不了被质疑<br>如果我放弃梦想，免不了为自己呵斥</p><p>痛苦的两面萦绕着我，我想，我是否，应当，找出第三条路？</p><p><img src="/2022/04/23/2022-4-23%E9%9A%8F%E7%AC%94/suncity1.jpg" alt="劳动，而非安逸的劳动"></p><p>那么，我想，第三条路便是，真正的去实现自己的梦想，不去怀抱它<br>而是摔打它，珠玉会殒碎，金石会长存<br>摔打我的梦想吧，和它一起在泥土中匍匐。<br>我不讨厌金玉，但是我无法接受将怀抱中的金玉视作唯一<br><img src="/2022/04/23/2022-4-23%E9%9A%8F%E7%AC%94/eva.jpg" alt="题外话，米山舞老师太潮了"></p><p>另外说一下，暴力，是最丑恶，最脆弱，最无可辨驳地应当抛弃之物。<br>倘若梦想要依靠暴力实现，那么就是应当反省梦想的实存性的时刻了</p><p>如果梦想不是金玉，那么金玉又该如何实现呢？<br>金玉应该是其外<br>其中不是败絮<br>而是铁石<br>从无名中来，到无声之海。</p><p>浪潮即来。<br><img src="/2022/04/23/2022-4-23%E9%9A%8F%E7%AC%94/vladmir.jpg" alt="向泥土中的理想者致敬"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.21随笔之二</title>
    <link href="/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94%E4%B9%8B%E4%BA%8C/"/>
    <url>/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94%E4%B9%8B%E4%BA%8C/</url>
    
    <content type="html"><![CDATA[<hr><h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>良辰美景，春暖秋凉。负杖蹑履，逍遥自乐。临池观鱼，披林听鸟；酌酒一杯，弹琴一曲；求数刻之乐，庶几居常以待终。</p></blockquote><p>春天，2022的春天，大概是就这么过去了，想去看的江南烟雨，似乎要散去了<br>这尚且不可怕<br>真正可怕的，大抵是想去江南的心，也被磨平了</p><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>如果每天都这样乱想一阵，恐怕是有所裨益的，权当是日记，却又和日记有所不同，毕竟生活的一些私事，放在这里，也不太好，一是给大家徒增烦恼，二是可能一些抱怨被看到后，未免让人觉得，我这人应该是个满腹苦水的人，造成了不好的印象。</p><p>所以，我权且以希声言事，以真声言情好了</p><p><img src="/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94%E4%B9%8B%E4%BA%8C/luna.jpg" alt="露娜，她真的，我哭死"></p><p>今天浅谈一下我对近月的回忆吧，按照村上春树<del>（还是三岛，我忘了）</del>的一些概念，回忆最深刻的片段是一些无关紧要，但是就是很深刻的片段。<br>总之，完全不能起到评判近月的作用，只是我单纯的一些回忆</p><blockquote><p>那么，大藏游星的喜剧，就此开场</p></blockquote><p>是啊，一场不折不扣的，<strong>喜剧</strong>，就此开场</p><p>对我来说，回忆最深刻的，是那个夏天，那个疫情之后的夏天<br>住在东丽，一个人住一间房子里，独居的生活，让我的作息极度紊乱<br>但是，我却邂逅了侘傺<br><img src="/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94%E4%B9%8B%E4%BA%8C/jinge.jpg" alt="有意思的是，我读到金阁寺，这个侘傺的顶峰后，却想要离开这种感觉了"></p><p>夏天的空调，对应了樱公馆的惬意，深夜的寂静无人以及一种作祟的恐惧感，恰好又和近月中那种仿佛在走钢丝的感觉相合<br>我已经不记得台词了，但是我记得，我爱上露娜，绝不是因为哪几个举动使我爱上她，而是她的气质，让我从初见，到正式遇见，到相处，到爱</p><p>她富有着一切美好的品质，坚韧，优雅，自由，纯真，温暖<br>她的名字是月，却让人想到了冬日房间中的暖阳<br>到了故事后期的那种恋爱的桥段，从来不让人觉得腻，而是一种，沁人而润无声的甘甜。<br>很少有作品能把恋爱的感觉塑造的如此让人，既能共情，却不需要很强的共情能力。<br>是的，其他作品，只要认真体悟，确实是可以感受到作者的心思的<br>近月却不需要，因此很适合来入门</p><p>生逢阳光灿烂，应该是最高的喜剧<br>而跨越困难，则是这喜剧的主演<br>没有搏击困难的人生，就是地窖中的，细若游星之光。<br>勇敢的，笑出来，面对自己的所想，不惜一切<br>终会成为朝阳灿烂万丈<br><img src="/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94%E4%B9%8B%E4%BA%8C/yousei.jpg" alt="愿你永远“真的很快乐啊！”"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>记录：装修博客</title>
    <link href="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/"/>
    <url>/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<p><font color="Red" size="6"><strong>本文长期更新，后面更新的部分也会插在不同部分</strong></font></p><h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ul><li><a href=".#%E5%8A%9F%E8%83%BD%E8%AE%BE%E7%BD%AE">功能设置</a><ul><li><a href=".#%E4%B8%BB%E9%A2%98%E9%80%89%E5%8F%96">主题选取</a><ul><li><a href=".#%E5%BD%92%E6%A1%A3%E4%B8%8E%E6%A0%87%E7%AD%BE">归档与标签</a></li><li><a href=".#%E4%B8%8B%E4%B8%80%E6%AD%A5%EF%BC%8C%E5%8F%8B%E9%93%BE%E4%B8%8E%E4%BD%9C%E8%80%85%E9%93%BE%E6%8E%A5">友链与作者链接</a></li><li><a href=".#%E4%B8%80%E4%BA%9B%E5%85%B6%E4%BB%96%E7%9A%84%E9%AA%9A%E6%93%8D%E4%BD%9C">一些其他的骚操作</a></li></ul></li><li><a href=".#%E6%87%92%E5%8A%A0%E8%BD%BD">懒加载</a></li></ul></li><li><a href=".#%E7%BE%8E%E8%A7%82%E8%AE%BE%E7%BD%AE">美观设置</a><ul><li><a href=".#%E8%83%8C%E6%99%AF%E5%9B%BE">背景图</a><ul><li><a href=".#%E4%B8%BB%E9%A1%B5%E8%83%8C%E6%99%AF%E5%9B%BE">主页背景图</a></li><li><a href=".#%E6%96%87%E7%AB%A0%E8%83%8C%E6%99%AF%E5%9B%BE">文章背景图</a></li></ul></li><li><a href=".#%E6%96%87%E7%AB%A0%E5%B0%81%E9%9D%A2%E5%9B%BE">文章封面图</a></li><li><a href=".#%E5%9B%BE%E7%89%87%E5%8A%A0%E8%BD%BD%E5%8A%A8%E7%94%BB">图片加载动画</a></li></ul></li><li><a href=".#%E6%89%A9%E5%B1%95%E8%AE%BE%E7%BD%AE">扩展设置</a></li></ul><h1 id="功能设置"><a href="#功能设置" class="headerlink" title="功能设置"></a>功能设置</h1><h2 id="主题选取"><a href="#主题选取" class="headerlink" title="主题选取"></a>主题选取</h2><p>一个博客的功能上限，很大程度上是取决于这个主题给你提供的功能，因此一个好的主题很重要<br>主题的选取，可以看我的另一篇文章<a href="https://lianga1.github.io/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/">Hexo主题模板切换</a><br>但是大部分时候我们用的功能不会很多，而基础的功能，例如归档，友链，个人介绍等功能，绝大部分的主题都具备。所以仅需要挑选好看的主题即可，关于主题的美观问题，我们放在<a href=".#%E7%BE%8E%E8%A7%82%E8%AE%BE%E7%BD%AE">美观设置</a>模块说。<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/theme1.jpg" alt="theme"></p><h2 id="导航栏"><a href="#导航栏" class="headerlink" title="导航栏"></a>导航栏</h2><p>导航栏是一个博客的门面。设置好导航栏，你的博客会非常的有条理。</p><h3 id="归档与标签"><a href="#归档与标签" class="headerlink" title="归档与标签"></a>归档与标签</h3><p>如果读者想找一篇文章,总不能让读者去挨篇文章翻吧，所以，在写文章的时候，做好标签设置和归档工作，是写一篇文章的必要工作。那么，如何归档呢？<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/categories.jpg" alt="categories"><br>在md语法中，我们可以在文章顶部的标签部分，加入如下几行</p><figure class="highlight subunit"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><pre><code class="hljs subunit"><span class="hljs-keyword">tags:</span><br>- 标签1<br>- 标签2<br>……<br>- 标签n<br>categories: <br>- 一级目录<br>- 二级目录<br></code></pre></td></tr></table></figure><p><font size="4"><strong>注意</strong></font>：tags和categories必须无缩进，否则在生成html时会报错</p><p>这样，你就拥有了一个可以从标签和分级目录中查询的文章了</p><h3 id="下一步，友链与作者链接"><a href="#下一步，友链与作者链接" class="headerlink" title="下一步，友链与作者链接"></a>下一步，友链与作者链接</h3><p><font color="Red" size="6"><strong>注意</strong></font>，本文之后的内容以Fluid主题为准，其他主题大同小异，具体操作可以参照主题的介绍文档。</p><hr><p>为什么把友链放到前面说呢，<del>当然是因为我最开始没管作者链接</del>，是因为友链的设置更加简单<br>我们需要在主题的_config.yml中（以下如果没有特殊说明，都是themes下的配置文件），在navbar：menu里，加入links，如下<br><code> - &#123; key: &quot;links&quot;, link: &quot;/links/&quot;, icon: &quot;iconfont icon-link-fill&quot; &#125;</code><br>这样就可以<br>然后找到links部分<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/links.jpg" alt="links"><br>将enable改为true即可，这样，我们的主页导航栏就会出现“友链”了。<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/links2.jpg" alt="links2"></p><p><font size="4">如何添加友链呢</font></p><p>只需要在config文件中的links模块下的item中，按照如下格式添加即可</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs dts">- &#123;<br><span class="hljs-symbol">      title:</span> <span class="hljs-string">&quot;rittmeister&quot;</span>,<br><span class="hljs-symbol">      intro:</span> <span class="hljs-string">&quot;xxx的博客&quot;</span>,<br><span class="hljs-symbol">      link:</span> <span class="hljs-string">&quot;https://lianga1.github.io/&quot;</span>,<br><span class="hljs-symbol">      avatar:</span> <span class="hljs-string">&quot;/img/avatar.png&quot;</span><br>    &#125;<br></code></pre></td></tr></table></figure><p>其中avatar是图标，存在主题文件夹下&#x2F;source&#x2F;img文件夹中，你可以根据喜好来更改</p><hr><p>接下来是作者链接，作者链接略微复杂<br>首先，我们需要在config文件中，找到about：模块<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/about1.jpg" alt="about"><br>确认是enable状态<br>当然，我们现在博客中点击这个页面，会显示404<br>原因是我们需要创建一个专门的about页面，方法如下，cmd输入代码<br><code>hexo new page about</code><br>即会在source文件夹创建一个about文件夹，里面有一个index.md文件，进入<br>在标签部分，添加<br><code>layout: about</code><br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/about2.jpg" alt="about"><br>这样，我们就会发现作者链接可以进入了。然后，我们可以在config-about模块，添加自己想要的功能。<br>例如我还添加了微信二维码<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/about3.jpg" alt="about3"><br>除此之外，fluid提供了丰富的图标库，可以在其doc中查询css的使用方法，这里不展开介绍了</p><h3 id="一些其他的骚操作"><a href="#一些其他的骚操作" class="headerlink" title="一些其他的骚操作"></a>一些其他的骚操作</h3><p>你还可以直接加一些新的链接，还是在navbar：menu部分里加，比如我就新加了一个tape提问箱，妈妈再也不用担心没人提问了<br><del>笑死，自闭症患儿罢了，哪有人去你的博客提问啊</del></p><h2 id="懒加载"><a href="#懒加载" class="headerlink" title="懒加载"></a>懒加载</h2><p>这个功能还是蛮有用的，单独开出来说一下<br>这个是可以让你的网页先加载，图片慢慢加载的功能，毕竟你的github服务器，如果等所有封面图都加载出来，黄花菜都凉了<br>实现方法：<br>config文件中lazyload：模块，enable设为true即可</p><h1 id="美观设置"><a href="#美观设置" class="headerlink" title="美观设置"></a>美观设置</h1><p>我个人很有自知之明，知道我的审美能力一般，这里仅提供一些方法上的指导</p><h2 id="背景图"><a href="#背景图" class="headerlink" title="背景图"></a>背景图</h2><p>（施工中——2022.4.22半夜一点半）</p><hr><p>（4.23更新）<br>背景图是博客的门面，选一张得体的背景图，可以极大的提高博客的氛围感，甚至可以增加阅读体验，以下介绍一下插入背景图的方法</p><h3 id="主页背景图"><a href="#主页背景图" class="headerlink" title="主页背景图"></a>主页背景图</h3><p>主页背景图，我推荐构图简单，色彩主调统一的图片，否则背景图上的字会显示不清。<br>修改背景图的方法很简单，在config文件中，搜索</p><blockquote><p>banner_img</p></blockquote><p>这个是所有背景图的关键词，因此你可以搜索到17个词<br>找到index模块下的banner_img<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/banner1.jpg" alt="banner_img"><br>其后面的目录是主题的source文件夹下的目录，只需要把你想要的图片放在这个目录下，并在config中替换即可</p><h3 id="其他背景图"><a href="#其他背景图" class="headerlink" title="其他背景图"></a>其他背景图</h3><p>emm，其他的背景图嘛，我希望你可以找到一套图，来和主页的背景映衬而且又各具特色，但是目前我还没有找到这种理想的图包。</p><h2 id="文章封面图"><a href="#文章封面图" class="headerlink" title="文章封面图"></a>文章封面图</h2><p>文章封面图的设置，是在文章的顶部内容栏中加入index_img: 一行<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/index_img1.jpg" alt="index_img"><br>然后，图片的位置是你的<font color="Red" size="6"><strong>主题目录下</strong></font>的source&#x2F;img文件夹，这里我建议给你的每篇文章进行归档，方便整理。<br>这样，你的博客文章就有封面图了<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/index_img2.jpg" alt="index_img"></p><h2 id="图片加载动画"><a href="#图片加载动画" class="headerlink" title="图片加载动画"></a>图片加载动画</h2><p>如果我们打开了懒加载功能，那么我们就会看到图片加载时会有一个动画，这里的加载其实是一个gif，和图片一样，我们也是可以更换的，比如换成一个跑步的Mario<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/mario.gif" alt="mario"><br>下面介绍一下设置方法：<br>在config文件中找到lazyload模块，然后，找到loading_img<br>改为你在主题的source中的路径<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/loading.jpg" alt="loading"><br>以上，操作完成。</p><h2 id="关于导航栏的一些玩法"><a href="#关于导航栏的一些玩法" class="headerlink" title="关于导航栏的一些玩法"></a>关于导航栏的一些玩法</h2><p>导航栏，美化是一个可以深入折腾的天地，简单介绍几个玩法</p><h3 id="毛玻璃特效"><a href="#毛玻璃特效" class="headerlink" title="毛玻璃特效"></a>毛玻璃特效</h3><p>这个可以让你的导航栏显示成亚克力效果<br>只需要在config文件的navbar模块下，ground_glass设置为enable：true即可，下面还可以调节模糊的颜色，模糊程度等。<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/navbar1.jpg" alt="ground_glass"></p><h3 id="自己的名字"><a href="#自己的名字" class="headerlink" title="自己的名字"></a>自己的名字</h3><p>你可以在导航栏的左侧标注你的名字，具体操作类似上条：<br><code>navbar--blog_title</code></p><h3 id="菜单图标"><a href="#菜单图标" class="headerlink" title="菜单图标"></a>菜单图标</h3><p>菜单上的选项，你可以设置图标<br>方法如下：<br>在navbar–menu模块下，找到对应的菜单栏选项，在icon：位置，根据自己的需要，选择对应的css</p><blockquote><p><a href="https://hexo.fluid-dev.com/docs/icon/#%E5%86%85%E7%BD%AE%E7%A4%BE%E4%BA%A4%E5%9B%BE%E6%A0%87">css库</a></p></blockquote><h2 id="关于标签栏的一些玩法"><a href="#关于标签栏的一些玩法" class="headerlink" title="关于标签栏的一些玩法"></a>关于标签栏的一些玩法</h2><h3 id="标签栏中显示的图标"><a href="#标签栏中显示的图标" class="headerlink" title="标签栏中显示的图标"></a>标签栏中显示的图标</h3><p>我们当然想让自己的名字显示在浏览器标签栏上来代替那个<del>丑陋的</del>Hexo标识，我们可以在config文件中的</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs avrasm"><span class="hljs-symbol">favicon:</span><br>以及<br><span class="hljs-symbol">apple_touch_icon:</span><br></code></pre></td></tr></table></figure><p>这两项中，改变自己想要的图片，同样，图片的位置是&#x2F;img<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/favicon.jpg" alt="favicon"></p><h3 id="标签栏的名字"><a href="#标签栏的名字" class="headerlink" title="标签栏的名字"></a>标签栏的名字</h3><p>改了图标，我们当然想要把“Hexo”改变为自己想要的名字<br><font color="Red" size="6"><strong>注意</strong></font>，这个是要在blog目录下的config文件更改，不要在主题配置里找！<br>在config文件中，找到site模块</p><p><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/sitename.jpg" alt="sitename"><br>将其title设置为你想要的内容即可</p><h3 id="标签栏的连接符"><a href="#标签栏的连接符" class="headerlink" title="标签栏的连接符"></a>标签栏的连接符</h3><p>当你打开一个文章页面或其他页面时，你会发现：标签栏名称变为<br><code>“页面名”-“站点名”</code><br>其实，中间的这个衔接符号，我们也是可以更改的，只需要在主题config文件中<br>找到“tab_title_separator:”模块<br>即可将其改为你想要的内容<br><img src="/2022/04/21/%E8%AE%B0%E5%BD%95%EF%BC%9A%E8%A3%85%E4%BF%AE%E5%8D%9A%E5%AE%A2/linker.jpg" alt="linker"></p><hr><p>（4.24施工完毕，还有一些内容，回头再说了）</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客</tag>
      
      <tag>记录</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.21随笔</title>
    <link href="/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<h1 id="放在开头"><a href="#放在开头" class="headerlink" title="放在开头"></a>放在开头</h1><p>今天看了莫奈的画，画的是真好啊，这种感觉，是一种极度粗糙的精细，让人的感知和自然氤氲的美</p><h1 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h1><blockquote><p>洞外，夜色晴朗，天气寒冷，没在下雪，他透过树干之间望去，那里一片白茫茫，再抬眼从林间望去，只见这时天色明净，他呼吸时，空气进入肺部，寒冷彻骨。<br>  《丧钟为谁而鸣》第十九章</p></blockquote><p>丧钟为谁而鸣？丧钟就为你我而鸣。</p><h1 id="乱想time"><a href="#乱想time" class="headerlink" title="乱想time"></a>乱想time</h1><p>我想想吧，我也许真的需要好好歇会了，不是说烂着，而是让自己别想这么多了。大不了就是全部都重新开始<br>如果你现在就不敢重新开始，那你以后又怎么敢呢？<br>如果现在不敢做出自己想要做的改变，那你指望什么呢？卧龙凤雏之相帮，只有赤壁一战。<br>然而卧龙凤雏不世出，人生逆旅困境常在，怎能不靠自己？<br>谁未曾光荣负膺，谁又未曾垂垂老矣。<br>田野如今依旧在，而田野上方的青空，却永远沉埋在心里了。<br><img src="/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94/insert1.jpg" alt="clear"><br><font size="5"><strong>最</strong></font>富有的人，永远是有着，能把时间中的每一刻都化为永恒的“魔法”的人<br>就好像甘道夫<br>魔法总是每年一度的烟花，却是我们永远的记忆。<br>也许他也能征服恶龙，但是对我来说，和烟花没有区别。</p><blockquote><p>如果你看懂了，那你就是没懂；如果你没懂，那你就是真没懂</p></blockquote><p>哈哈，我也会说谜语了<br>晚安<br><img src="/2022/04/21/2022-4-21%E9%9A%8F%E7%AC%94/end.jpg" alt="end"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2022.4.20随笔</title>
    <link href="/2022/04/20/2022-4-20%E9%9A%8F%E7%AC%94/"/>
    <url>/2022/04/20/2022-4-20%E9%9A%8F%E7%AC%94/</url>
    
    <content type="html"><![CDATA[<h1 id="我的第一篇胡思乱想"><a href="#我的第一篇胡思乱想" class="headerlink" title="我的第一篇胡思乱想"></a>我的第一篇胡思乱想</h1><h2 id="每日一句"><a href="#每日一句" class="headerlink" title="每日一句"></a>每日一句</h2><blockquote><p>我无法接受“如果知识代表危险，无知就是解决之道”</p></blockquote><h2 id="胡思乱想"><a href="#胡思乱想" class="headerlink" title="胡思乱想"></a>胡思乱想</h2><p>嗯，是的，畏惧困难不是我的本色，舒适的生活，害怕这种生活的流逝，是一种正常的感情，却是不对的<br>如果死亡即将来临，那就放马过来吧<br>如果赌气能让我获得什么，那一定是多年后的追悔莫及。<br>然而，赌气何尝不是一种畏惧，畏惧行动的体现而已</p><hr><p>实不相瞒，我的思绪到这里是枯竭的<br>我竭力想要说些什么，却不能将其明确的表达，这大概是博客和日记的区别<br>思绪断了，情绪却没有断开，我想，我是否需要重新找回年轻时的那个，敢于愤怒的人了呢<br>我想，亲情间时没有愤怒的，最恶劣的结果不过是驱逐<br>但是友谊，火一般的爱，点燃它们的，必然是那愤然的激情。</p><blockquote><p>愤怒是弱者的感情</p></blockquote><p>是啊，如果我们是孤立于世界的人，那我们必然不会去愤然<br>这是一种与我们无意义的情感<br>但是我们若是活在人间，就容不得那种傲然的存在了<br>一个人，对于人本身，他的理想的终点，是不是完美呢<br>我想这就是人文主义与理性主义的区别所在<br>以理性主义的角度思考人文主义的内涵，是一种奇妙但是容易跑偏的思路<br>反之，则是晦涩且难以认同的。</p><hr><p>陷入了这种思考后，思路便生发了出来<br>如果说一个理性者，他的画作是超写实<br>那么人文关怀者，其作品必然是“不如”理性的<br>但是，</p><blockquote><p>真正的天才让人忘记才能</p></blockquote><p>也许真正的人文主义，是无法被学习的<br>当一切人都毁灭时，人文主义将永远沉睡<br>理性主义将会活到下一次复苏<br>毕竟，理性主义的文艺，本身也不是为了“人”创作<br>是一种荷尔蒙的迸发，是一种活着的死亡<br>我不好支持或否定谁<br>我深深爱着二者<br><img src="/2022/04/20/2022-4-20%E9%9A%8F%E7%AC%94/img.jpg" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>随笔</category>
      
    </categories>
    
    
    <tags>
      
      <tag>随笔</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于解决无法上传图片的问题</title>
    <link href="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <url>/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>事情是这样的，我在写博客的时候发现，我的图片即使以正确的格式引用，依旧会出现无法加载的问题<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/problem.jpg" alt="问题如图"></p><p>众所周知，没有图片，你写个啥都没法直观地展示，就好像pre时用txt做演示，大家嘴上不说什么，心里肯定知道<del>你是忘了做ppt了</del></p><p>总之，根据我一晚上的研究成果，整理出来了几个解决图片无法显示的问题的方法供大家参考。</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p>一共有这么几个方法，大家可以都试试，挑一个自己最喜欢的</p><ul><li><p><a href="./#%E5%9B%BE%E5%BA%8A%E6%B3%95">图床法</a></p><ul><li>github&amp;gitee图床</li><li>图床网站</li><li>PicGo</li></ul></li><li><p><a href="./#%E6%9C%AC%E5%9C%B0%E4%B8%8A%E4%BC%A0%E6%B3%95">本地上传法</a></p></li></ul><h2 id="图床法"><a href="#图床法" class="headerlink" title="图床法"></a>图床法</h2><p>是这样的，一般来说，你的hexo博客在部署到服务器时，不会给你上传那些文章里链接的图片的，所以你的md文章里链接的图片一般情况下是无法上传的，自然就无法加载出来，但是你的图片如果是网络图片，直接链接网址，就可以通过联网加载的方式显示有如下几种方法</p><h3 id="Github-amp-Gitee仓库图床"><a href="#Github-amp-Gitee仓库图床" class="headerlink" title="Github&amp;Gitee仓库图床"></a>Github&amp;Gitee仓库图床</h3><p>这个的原理就是让你的公有仓库变成图床，白嫖存储空间</p><h4 id="操作流程"><a href="#操作流程" class="headerlink" title="操作流程"></a>操作流程</h4><p>具体来说，github和gitee方法相似，这里仅介绍github，gitee方法类似<br>gitee的访问速度会更快一点，github的容量没有限制，可以自己取舍</p><ol><li>注册一个github账户</li><li>创建一个新的公有库，注意一定是<strong>公有</strong>，否则外部无法访问</li><li>在库存中创建一个文件夹<br> <img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/github.jpg" alt="add_a_file"></li><li>把你的图片上传<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/upload.jpg" alt="upload"></li><li>点击你的图片，复制地址框中的地址，注意要把bolb改为raw<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/raw.jpg" alt="raw"></li><li>然后就可以在你的博客里引用这个地址了！<blockquote><p>你可以用cdn加速github，比如Jsdelivr，加速方法不在本文讨论范围</p></blockquote></li></ol><h3 id="图床网站"><a href="#图床网站" class="headerlink" title="图床网站"></a>图床网站</h3><p>上面说的只是把github当作一个公开访问的图片网站，当然，市面上还有很多的专用图床网站，免费的付费的都有，这里介绍一个免费的网站<a href="https://imgtu.com/">imgtu.com</a></p><ol><li>打开网站，上传图片<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/image.jpg" alt="image"><blockquote><p>注意不能挂梯子</p></blockquote></li><li>上传完成后，在底部链接栏，找到md链接，复制粘贴到你的文章插图位置就ok了<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/save_the_link.jpg" alt="save_the_link"></li></ol><p>这个方法还是比较简单的,基本上有手就行，没手的话，<del>那你也别搞博客了</del></p><h3 id="PicGo"><a href="#PicGo" class="headerlink" title="PicGo"></a>PicGo</h3><p>除了以上介绍的两种方法，还有一个比较“软件化”的方案，就是<a href="https://molunerfinn.com/PicGo/">PicGo</a></p><p>PicGo是一个开源的软件，它的优点是方便快捷，不用登网站，操作比较easy，而且集成了很多平台。<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/PicGo.jpg" alt="PicGo"></p><h4 id="操作方法"><a href="#操作方法" class="headerlink" title="操作方法"></a>操作方法</h4><p>还是以GitHub为例，首先我们进入<strong>图床设置</strong>-&gt;<strong>Github</strong><br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/picgo_github.jpg" alt="picgo_github"><br>在对应的框里输入信息</p><blockquote><p>存储路径是你的GitHub仓库里的路径，没有时会创建<br>自定义域名就是你可以用cdn加速访问图片，最后两级就是你的用户名和仓库名<br>下面介绍一下token的获取方法</p></blockquote><h5 id="获取Github-Token"><a href="#获取Github-Token" class="headerlink" title="获取Github Token"></a>获取Github Token</h5><p>首先从个人列表进入settings<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/token1.jpg" alt="token1"><br>然后进入最底部的developer settings<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/token2.jpg" alt="token2"><br>然后进入Personal access tokens，点generate new token<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/token3.jpg" alt="token3"><br>按照如下操作<br><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/token4.jpg" alt="token4"><br>生成后记得复制，这个token<font color="Red" size="6"><strong>只会出现一次</strong></font></p><p>至此，PicGo的使用介绍就完成了</p><h2 id="本地上传法"><a href="#本地上传法" class="headerlink" title="本地上传法"></a>本地上传法</h2><h2 id="（施工中，累了，明天再说）"><a href="#（施工中，累了，明天再说）" class="headerlink" title="（施工中，累了，明天再说）"></a>（施工中，累了，明天再说）</h2><p>2022.4.20更新</p><p>继续说本地上传法</p><p>我们之前说过，本地的图片是不会被hexo上传的，其实这个说法不严谨<br>严格来说，是你凭空放一张图片，无法上传<br>但是，我们可以通过一个方法来上传本地图片，那就是hexo-asset-image。</p><h3 id="操作方法-1"><a href="#操作方法-1" class="headerlink" title="操作方法"></a>操作方法</h3><p>首先安装hexo-asset-image<br><code>npm install https://github.com/CodeFalling/hexo-asset-image --save</code></p><ul><li>注意，如果你安装速度慢的话，可以讲npm换为淘宝镜像，切换方法如下：<br><code>npm config set registry https://registry.npm.taobao.org</code><br>安装完成后，我们要在_config.yml中作如下更改<blockquote><p> 将 post_asset_folder 设置为true</p></blockquote></li></ul><p><img src="/2022/04/18/%E5%85%B3%E4%BA%8E%E8%A7%A3%E5%86%B3%E6%97%A0%E6%B3%95%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98/post.jpg" alt="post"><br>然后，每当我们新建一篇博客时，就会有一个同名文件夹在_post文件夹中生成了<br>我们把需要插入的图片放到这个文件夹里面，在文章中引用格式如下<br><code>![图片描述]（./包名/NO.01.001.jpg）</code><br><font size="5">或者</font><br><code>![logo](logo.jpg)</code><br>就可以了，这个方法也是我在用的方法，非常方便，缺点是对服务器压力比较大。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>上述的几个方法，各有优缺点，可以结合自己的特点来使用<br>注意图片描述必须是全英文，否则无法显示图片<br>希望有所帮助</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo主题模板切换</title>
    <link href="/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/"/>
    <url>/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="下载主题"><a href="#下载主题" class="headerlink" title="下载主题"></a>下载主题</h1><p>首先，我们找一个比较好看的主题，比如我找的Fluid<br><img src="/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/fluid.jpg" alt="fluid网址：https://hexo.fluid-dev.com "></p><p>找到了这个主题的<a href="https://github.com/fluid-dev/hexo-theme-fluid">github网址</a> </p><p>然后呢，我们需要在cmd中输入一行神秘代码<br><code>git clone https://github.com/fluid-dev/hexo-theme-fluid themes\fluid</code></p><p>git clone 是在GitHub上下载的命令，中间的部分是这个主题的网址，最后是你在blog目录下需要把这个下载的主题存到的位置，系统会自动创建空的文件夹。</p><p>然后静待下载，下载完成后，我们的工作就成功了一大半了！</p><h1 id="应用主题"><a href="#应用主题" class="headerlink" title="应用主题"></a>应用主题</h1><p>应用主题的方法很简单，只需要打开blog目录下的_config.yml文件，把倒数第二个部分的“theme：”改为你的主题所在文件夹的名字就OK了。<br><img src="/2022/04/18/Hexo%E4%B8%BB%E9%A2%98%E6%A8%A1%E6%9D%BF%E5%88%87%E6%8D%A2/config.jpg" alt="这样"></p><p>别忘了部署到服务器！</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>string</title>
    <link href="/2021/10/28/string/"/>
    <url>/2021/10/28/string/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>md语法试验</title>
    <link href="/2021/08/24/md%E8%AF%AD%E6%B3%95%E8%AF%95%E9%AA%8C/"/>
    <url>/2021/08/24/md%E8%AF%AD%E6%B3%95%E8%AF%95%E9%AA%8C/</url>
    
    <content type="html"><![CDATA[<h1 id="分层"><a href="#分层" class="headerlink" title="分层"></a>分层</h1><h2 id="二级目录"><a href="#二级目录" class="headerlink" title="二级目录"></a>二级目录</h2><h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3><h4 id="无序列表"><a href="#无序列表" class="headerlink" title="无序列表"></a>无序列表</h4><ul><li>小标</li><li>无序</li><li>各种符号都行<ul><li>第二层嵌套<ul><li>第n层嵌套<h4 id="有序列表"><a href="#有序列表" class="headerlink" title="有序列表"></a>有序列表</h4></li></ul></li></ul></li></ul><ol><li>有序列表</li><li>第一行序号为起始序号</li><li>即使后面序号错误也会顺序下排<ol><li>嵌套效果<h2 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h2><h3 id="引用说明"><a href="#引用说明" class="headerlink" title="引用说明"></a>引用说明</h3><blockquote><p>引用内容</p><blockquote><p>二级引用</p><blockquote><p>三级引用</p></blockquote></blockquote></blockquote><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><p><code>少量代码，单行使用，用·包裹</code></p></li></ol></li></ol><figure class="highlight"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><pre><code class="hljs"><br>大量代码多行使用，用三个·包裹<br>大量代码多行使用，用三个·包裹<br>大量代码多行使用，用三个·包裹<br>大量代码多行使用，用三个·包裹<br><br></code></pre></td></tr></table></figure><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><h3 id="网页链接"><a href="#网页链接" class="headerlink" title="网页链接"></a>网页链接</h3><h4 id="行内式"><a href="#行内式" class="headerlink" title="行内式"></a>行内式</h4><p>链接放在【】中，地址放在后面的小括号中，引号内是title<br><a href="www.baidu.com" title="百度一下，你就知道">百度</a><br>[百度]是一个搜索引擎</p><h4 id="参数式"><a href="#参数式" class="headerlink" title="参数式"></a>参数式</h4><p>链接在【】内，地址在冒号后面，title用引号<br>[百度]:<a href="http://www.baidu.com/">www.baidu.com</a> “百度一下，你就知道”<br>[百度]是一个搜索引擎</p><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>与链接基本一致，注意在引用图片时【】前加上！<br><img src="/2021/08/24/md%E8%AF%AD%E6%B3%95%E8%AF%95%E9%AA%8C/download\edge\13623636-6d878e3d3ef63825" alt="logo"> “my logo”</p><h2 id="工整"><a href="#工整" class="headerlink" title="工整"></a>工整</h2><h3 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h3><h2 id="由-这三种之一的三个符号表示"><a href="#由-这三种之一的三个符号表示" class="headerlink" title="由* - _这三种之一的三个符号表示"></a>由* - _这三种之一的三个符号表示</h2><p>这就是分割线</p><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p>&#x2F;&#x2F;例子</p><table><thead><tr><th align="left">123</th><th align="center">234</th><th align="right">345</th></tr></thead><tbody><tr><td align="left">abc</td><td align="center">bcd</td><td align="right">cde</td></tr></tbody></table><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="强调字体"><a href="#强调字体" class="headerlink" title="强调字体"></a>强调字体</h3><ol><li>强调字体<br> 用星号包裹，如<em>md</em>,<strong>md</strong> </li><li>转义<br> 用\</li><li>删除线<br> <del>删除</del></li></ol>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
      <category>博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>技术</tag>
      
      <tag>博客</tag>
      
      <tag>markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>我的第一篇博客</title>
    <link href="/2021/08/24/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
    <url>/2021/08/24/%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2021/08/24/hello-world/"/>
    <url>/2021/08/24/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
